{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hyperparams to paper's numbers\n",
    "N = int(1e7)\n",
    "epsilon_generator = (1 - (i * .9/1e6) for i in range(int(1e6)))\n",
    "# mini-batch size = 32\n",
    "# optimizer RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize replay memory to capacity N\n",
    "replay_memory = ReplayMemory(N)\n",
    "# initialize action-value function with random weights\n",
    "Q = make_q_net()\n",
    "\n",
    "for episode in range(M): # loop over episodes\n",
    "    s_seq = []\n",
    "    phi_seq = []\n",
    "    \n",
    "    for t in range(T): # loop over steps in episode\n",
    "        # with probability epsilon select random action a_t\n",
    "        delta = uniform_random(0, 1)\n",
    "        if delta < epsilon:\n",
    "            a_t = sample(action_space)\n",
    "        # otherwise select argmax(a, Q(s,a))\n",
    "        else:\n",
    "            a_t = argmax(Q(phi[t]))\n",
    "        \n",
    "        # execute action and record transition\n",
    "        r_t, x_tp1 = env.step(a_t)\n",
    "        \n",
    "        # add action and observation to trajectory\n",
    "        tau.append((a_t, x_tp1))\n",
    "        # prepare next input to the Q network\n",
    "        phi.append(preprocess(tau))\n",
    "        \n",
    "        # store transition\n",
    "        replay_memory.append((phi[t], a_t, rk_t, phi[t+1]))\n",
    "        \n",
    "        # sample minibatch of transitions\n",
    "        mini_batch = sample(replay_memory, K)\n",
    "        \n",
    "        grad = 0\n",
    "        for transition in mini_batch:\n",
    "            phi_j, a_j, r_j, phi_jp1 = transition\n",
    "            \n",
    "            # calculate TD error for each transition\n",
    "            if phi_jp1 is terminal:\n",
    "                y_j = r_j\n",
    "            else:\n",
    "                y_j = r_j + lam * argmax(Q(phi_jp1))\n",
    "            # calculate the gradient from transition\n",
    "            grad += get_grad(y_j, Q, phi_j, a_j)\n",
    "            \n",
    "        grad = 1/K * grad\n",
    "        Q.gradient_descent(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.s_seq = []\n",
    "        self.phi_seq = []\n",
    "        self.replay_mem = ReplayMemory()\n",
    "\n",
    "        self.q_net = QNet()\n",
    "        self.epsilon = .9\n",
    "        \n",
    "        self.env = gym.envs.make('PongNoFrameskip-v4')\n",
    "        \n",
    "    \n",
    "    \n",
    "    def act(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def _train(self):\n",
    "        pass\n",
    "    \n",
    "    def _update_epsilon(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, N, sample_size):\n",
    "        self.N = N\n",
    "        self.sample_size = sample_size\n",
    "        self.transitions = deque()\n",
    "        \n",
    "    def sample(self, k=None):\n",
    "        if k is None:\n",
    "            k = self.sample_size\n",
    "        return np.random.choice(self.transitions, k)\n",
    "\n",
    "    def add(e):\n",
    "        if len(self.transitions >= self.N):\n",
    "            self.transitions.popleft()\n",
    "        self.transitions.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test random agent on Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "env = gym.envs.make('PongNoFrameskip-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obss = []\n",
    "obss.append(env.reset())\n",
    "\n",
    "for _ in range(1000):\n",
    "    a = np.random.choice(env.action_space.n)\n",
    "    obs, rew, done, _ = env.step(a)\n",
    "    obss.append(obs)\n",
    "    \n",
    "    if done:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess frames\n",
    "\n",
    "1. Make images grayscale.\n",
    "2. Downsample images by a factor of 4.\n",
    "3. Crop images into squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def process_frame(frame):\n",
    "    \"\"\"Turn game frame into small, square, grayscale image.\"\"\"\n",
    "    pipeline = transforms.Compose([\n",
    "        transforms.ToPILImage(), # turn numpy ndarray into PIL image\n",
    "        transforms.Grayscale(), # convert image to grayscale\n",
    "        transforms.Resize((110, 84)), # resize image to 110 x 84\n",
    "        transforms.CenterCrop(84), # crop at the center into 84 x 84 image\n",
    "        transforms.ToTensor() # convert PIL image to torch tensor\n",
    "    ])\n",
    "    \n",
    "    return pipeline(frame)\n",
    "\n",
    "\n",
    "def make_input(frames):\n",
    "    assert len(frames) == 4 # must have 4 frames\n",
    "    \n",
    "    x = [process_frame(fr) for fr in frames]\n",
    "    return torch.cat(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Q network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(QNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, \n",
    "                               kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(16, 32, \n",
    "                               kernel_size=4, stride=2)\n",
    "        self.fc1 = nn.Linear(2592, 256)\n",
    "        self.fc2 = nn.Linear(256, env.action_space.n)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view((x.shape[0], -1))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Q network on 1000 frames of Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_net = QNet()\n",
    "\n",
    "x = [process_frame(fr) for fr in obss[0:4]]\n",
    "x = torch.cat(x)\n",
    "x = torch.unsqueeze(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = q_net(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.argmax(d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tau):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad(Q, y, a, phi):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
