{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Algo Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from src import agent, train, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect 10 random frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_mem_size = int(1e6)\n",
    "batch_size = 32\n",
    "num_episodes = int(1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_to_phi(frames):\n",
    "    frames = [utils.process_frame(s) \n",
    "              for s in frames]\n",
    "    phi = torch.cat(frames)\n",
    "    \n",
    "    return phi\n",
    "\n",
    "def get_rand_phis(k, n):\n",
    "    frames = []\n",
    "    env = gym.envs.make('Pong-v4')\n",
    "    env.reset()\n",
    "    \n",
    "    for i in range(n):\n",
    "        a = random.randrange(env.action_space.n)\n",
    "        s_t1, r_t, done, _ = env.step(a)\n",
    "        frames.append(s_t1)\n",
    "\n",
    "        if done:\n",
    "            s_t = env.reset()\n",
    "    \n",
    "    idxs = random.sample(range(3, n), k)\n",
    "    phis = [frames_to_phi(frames[i-3:i+1]) for i in idxs]\n",
    "    \n",
    "    return phis\n",
    "\n",
    "def get_frames_avg_qval(phis, agt):\n",
    "    x = torch.stack(phis)\n",
    "    qvals = agt.get_best_values(x)\n",
    "    \n",
    "    return torch.mean(qvals).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(replay_mem_size, batch_size):\n",
    "    agt = agent.DQNAgent()\n",
    "    replay_mem = utils.ReplayMemory(replay_mem_size, batch_size)\n",
    "    obs_history = utils.ObsHistory()\n",
    "    env = gym.envs.make('Pong-v4')\n",
    "    train_stats = TrainingStats()\n",
    "    \n",
    "    return agt, replay_mem, obs_history, env, train_stats\n",
    "\n",
    "def act_step(obs_history, agt, env):\n",
    "    phi_t = obs_history.get_phi()\n",
    "    a_t = agt.act(phi_t)\n",
    "    s_t1, r_t, done, _ = env.step(a_t)\n",
    "    \n",
    "    return a_t, s_t1, r_t, done\n",
    "\n",
    "def store_step(s_t, a_t, r_t, done, s_t1, obs_history, replay_mem):\n",
    "    obs_history.store(s_t1)\n",
    "    replay_mem.store(s_t, a_t, r_t, done)\n",
    "\n",
    "def gradient_step(replay_mem, agt):\n",
    "    if replay_mem.size > replay_mem.sample_size + 3:\n",
    "        mini_batch = replay_mem.sample()\n",
    "\n",
    "        agt.optimizer.zero_grad()\n",
    "        loss = train.mini_batch_loss(mini_batch, agt)\n",
    "        loss.backward()\n",
    "        agt.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "def save_params(agt, episodes, save_path):\n",
    "    torch.save({\n",
    "        'model_state_dict': agt.qnet.state_dict(),\n",
    "        'optimizer_state_dict': agt.optimizer.state_dict(),\n",
    "        'episodes': episodes\n",
    "    }, save_path)\n",
    "\n",
    "def load_params(agt, load_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    agt.qnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    agt.opimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    return chekpoint['episodes']\n",
    "\n",
    "def reset_episode(env, obs_history):\n",
    "    s_t = env.reset()\n",
    "    obs_history.reset(s_t)\n",
    "    done = False\n",
    "    \n",
    "    return s_t, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_to_phi(frames):\n",
    "    frames = [utils.process_frame(s) for s in frames]\n",
    "    phi = torch.cat(frames)\n",
    "\n",
    "    return phi\n",
    "\n",
    "def get_rand_phis(k, n):\n",
    "    frames = []\n",
    "    env = gym.envs.make('Pong-v4')\n",
    "    env.reset()\n",
    "\n",
    "    for i in range(n):\n",
    "        a = random.randrange(env.action_space.n)\n",
    "        s_t1, r_t, done, _ = env.step(a)\n",
    "        frames.append(s_t1)\n",
    "\n",
    "        if done:\n",
    "            s_t = env.reset()\n",
    "\n",
    "    idxs = random.sample(range(3, n), k)\n",
    "    phis = [frames_to_phi(frames[i-3:i+1]) for i in idxs]\n",
    "\n",
    "    return phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingStats:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ep_rewards = []\n",
    "        self.ep_avg_train_losses = []\n",
    "        self.steps_per_ep = []\n",
    "        self.benchmark_qvals = []\n",
    "        self.benchmark_frames = torch.stack(get_rand_phis(10, 10000))\n",
    "        \n",
    "    def store(self, agt, ep_reward, ep_steps, ep_loss, episode_num):\n",
    "        self.ep_rewards.append(ep_reward)\n",
    "        self.steps_per_ep.append(ep_steps)\n",
    "        \n",
    "        avg_ep_loss = ep_loss / ep_steps\n",
    "        self.ep_avg_train_losses.append(avg_ep_loss)\n",
    "        \n",
    "        avg_qvals = self.get_frames_avg_qval(agt)\n",
    "        self.benchmark_qvals.append(avg_qvals)\n",
    "        \n",
    "        print('Episode {}:'.format(episode_num))\n",
    "        print('Reward: {}'.format(ep_reward))\n",
    "        print('Steps: {}'.format(ep_steps))\n",
    "        print('Avg loss: {:.5f}'.format(avg_ep_loss))\n",
    "        print('Avg qvals: {:.5f}'.format(avg_qvals))\n",
    "        print('===========================================')\n",
    "        \n",
    "\n",
    "    def get_frames_avg_qval(self, agt):\n",
    "        qvals = agt.get_best_values(self.benchmark_frames)\n",
    "\n",
    "        return torch.mean(qvals).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_rewards = []\n",
    "ep_avg_train_losses = []\n",
    "steps_per_ep = []\n",
    "benchmark_qvals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0:\n",
      "Reward: -21.0\n",
      "Steps: 1166\n",
      "Avg loss: 0.01169\n",
      "Avg qvals: -0.67752\n",
      "===========================================\n",
      "Episode 1:\n",
      "Reward: -21.0\n",
      "Steps: 1163\n",
      "Avg loss: 0.01747\n",
      "Avg qvals: -1.73713\n",
      "===========================================\n",
      "Episode 2:\n",
      "Reward: -21.0\n",
      "Steps: 1084\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -2.48010\n",
      "===========================================\n",
      "Episode 3:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01802\n",
      "Avg qvals: -1.26754\n",
      "===========================================\n",
      "Episode 4:\n",
      "Reward: -21.0\n",
      "Steps: 1146\n",
      "Avg loss: 0.01635\n",
      "Avg qvals: -1.31768\n",
      "===========================================\n",
      "Episode 5:\n",
      "Reward: -19.0\n",
      "Steps: 1249\n",
      "Avg loss: 0.01854\n",
      "Avg qvals: -1.03654\n",
      "===========================================\n",
      "Episode 6:\n",
      "Reward: -21.0\n",
      "Steps: 1182\n",
      "Avg loss: 0.01664\n",
      "Avg qvals: -1.44374\n",
      "===========================================\n",
      "Episode 7:\n",
      "Reward: -20.0\n",
      "Steps: 1199\n",
      "Avg loss: 0.01664\n",
      "Avg qvals: -1.61514\n",
      "===========================================\n",
      "Episode 8:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01696\n",
      "Avg qvals: -1.65590\n",
      "===========================================\n",
      "Episode 9:\n",
      "Reward: -21.0\n",
      "Steps: 1093\n",
      "Avg loss: 0.01862\n",
      "Avg qvals: -2.41460\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 10:\n",
      "Reward: -20.0\n",
      "Steps: 1308\n",
      "Avg loss: 0.01718\n",
      "Avg qvals: -1.54633\n",
      "===========================================\n",
      "Episode 11:\n",
      "Reward: -21.0\n",
      "Steps: 1227\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.73531\n",
      "===========================================\n",
      "Episode 12:\n",
      "Reward: -20.0\n",
      "Steps: 1252\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -2.01598\n",
      "===========================================\n",
      "Episode 13:\n",
      "Reward: -18.0\n",
      "Steps: 1560\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.81314\n",
      "===========================================\n",
      "Episode 14:\n",
      "Reward: -21.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01719\n",
      "Avg qvals: -1.37276\n",
      "===========================================\n",
      "Episode 15:\n",
      "Reward: -19.0\n",
      "Steps: 1341\n",
      "Avg loss: 0.01640\n",
      "Avg qvals: -1.55691\n",
      "===========================================\n",
      "Episode 16:\n",
      "Reward: -17.0\n",
      "Steps: 1547\n",
      "Avg loss: 0.01657\n",
      "Avg qvals: -1.35592\n",
      "===========================================\n",
      "Episode 17:\n",
      "Reward: -21.0\n",
      "Steps: 1173\n",
      "Avg loss: 0.01785\n",
      "Avg qvals: -1.08326\n",
      "===========================================\n",
      "Episode 18:\n",
      "Reward: -21.0\n",
      "Steps: 1047\n",
      "Avg loss: 0.01700\n",
      "Avg qvals: -1.67078\n",
      "===========================================\n",
      "Episode 19:\n",
      "Reward: -20.0\n",
      "Steps: 1207\n",
      "Avg loss: 0.01762\n",
      "Avg qvals: -1.48959\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 20:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01709\n",
      "Avg qvals: -1.78605\n",
      "===========================================\n",
      "Episode 21:\n",
      "Reward: -21.0\n",
      "Steps: 1264\n",
      "Avg loss: 0.01711\n",
      "Avg qvals: -1.57164\n",
      "===========================================\n",
      "Episode 22:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01714\n",
      "Avg qvals: -1.87660\n",
      "===========================================\n",
      "Episode 23:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.60930\n",
      "===========================================\n",
      "Episode 24:\n",
      "Reward: -20.0\n",
      "Steps: 1237\n",
      "Avg loss: 0.01602\n",
      "Avg qvals: -1.19824\n",
      "===========================================\n",
      "Episode 25:\n",
      "Reward: -17.0\n",
      "Steps: 1528\n",
      "Avg loss: 0.01825\n",
      "Avg qvals: -1.57653\n",
      "===========================================\n",
      "Episode 26:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01514\n",
      "Avg qvals: -1.18666\n",
      "===========================================\n",
      "Episode 27:\n",
      "Reward: -21.0\n",
      "Steps: 1128\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.68912\n",
      "===========================================\n",
      "Episode 28:\n",
      "Reward: -21.0\n",
      "Steps: 1112\n",
      "Avg loss: 0.01726\n",
      "Avg qvals: -1.95662\n",
      "===========================================\n",
      "Episode 29:\n",
      "Reward: -20.0\n",
      "Steps: 1332\n",
      "Avg loss: 0.01672\n",
      "Avg qvals: -1.74955\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 30:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01755\n",
      "Avg qvals: -1.46627\n",
      "===========================================\n",
      "Episode 31:\n",
      "Reward: -21.0\n",
      "Steps: 1189\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.69953\n",
      "===========================================\n",
      "Episode 32:\n",
      "Reward: -21.0\n",
      "Steps: 1093\n",
      "Avg loss: 0.01725\n",
      "Avg qvals: -1.73574\n",
      "===========================================\n",
      "Episode 33:\n",
      "Reward: -20.0\n",
      "Steps: 1227\n",
      "Avg loss: 0.01730\n",
      "Avg qvals: -1.43367\n",
      "===========================================\n",
      "Episode 34:\n",
      "Reward: -20.0\n",
      "Steps: 1441\n",
      "Avg loss: 0.01717\n",
      "Avg qvals: -1.45731\n",
      "===========================================\n",
      "Episode 35:\n",
      "Reward: -21.0\n",
      "Steps: 1195\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.48675\n",
      "===========================================\n",
      "Episode 36:\n",
      "Reward: -21.0\n",
      "Steps: 1303\n",
      "Avg loss: 0.01577\n",
      "Avg qvals: -1.42032\n",
      "===========================================\n",
      "Episode 37:\n",
      "Reward: -21.0\n",
      "Steps: 1084\n",
      "Avg loss: 0.01718\n",
      "Avg qvals: -1.63561\n",
      "===========================================\n",
      "Episode 38:\n",
      "Reward: -21.0\n",
      "Steps: 1103\n",
      "Avg loss: 0.01869\n",
      "Avg qvals: -1.71524\n",
      "===========================================\n",
      "Episode 39:\n",
      "Reward: -20.0\n",
      "Steps: 1227\n",
      "Avg loss: 0.01822\n",
      "Avg qvals: -1.79200\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 40:\n",
      "Reward: -18.0\n",
      "Steps: 1425\n",
      "Avg loss: 0.01785\n",
      "Avg qvals: -1.52973\n",
      "===========================================\n",
      "Episode 41:\n",
      "Reward: -20.0\n",
      "Steps: 1348\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.54609\n",
      "===========================================\n",
      "Episode 42:\n",
      "Reward: -20.0\n",
      "Steps: 1188\n",
      "Avg loss: 0.01673\n",
      "Avg qvals: -1.77859\n",
      "===========================================\n",
      "Episode 43:\n",
      "Reward: -20.0\n",
      "Steps: 1192\n",
      "Avg loss: 0.01622\n",
      "Avg qvals: -1.32165\n",
      "===========================================\n",
      "Episode 44:\n",
      "Reward: -21.0\n",
      "Steps: 1151\n",
      "Avg loss: 0.01631\n",
      "Avg qvals: -1.34584\n",
      "===========================================\n",
      "Episode 45:\n",
      "Reward: -20.0\n",
      "Steps: 1308\n",
      "Avg loss: 0.01729\n",
      "Avg qvals: -1.49305\n",
      "===========================================\n",
      "Episode 46:\n",
      "Reward: -20.0\n",
      "Steps: 1122\n",
      "Avg loss: 0.01873\n",
      "Avg qvals: -1.58406\n",
      "===========================================\n",
      "Episode 47:\n",
      "Reward: -20.0\n",
      "Steps: 1134\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -1.82780\n",
      "===========================================\n",
      "Episode 48:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01591\n",
      "Avg qvals: -1.32310\n",
      "===========================================\n",
      "Episode 49:\n",
      "Reward: -21.0\n",
      "Steps: 1086\n",
      "Avg loss: 0.01819\n",
      "Avg qvals: -1.74284\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 50:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01802\n",
      "Avg qvals: -1.65193\n",
      "===========================================\n",
      "Episode 51:\n",
      "Reward: -20.0\n",
      "Steps: 1291\n",
      "Avg loss: 0.01842\n",
      "Avg qvals: -1.95480\n",
      "===========================================\n",
      "Episode 52:\n",
      "Reward: -21.0\n",
      "Steps: 1107\n",
      "Avg loss: 0.01792\n",
      "Avg qvals: -1.21186\n",
      "===========================================\n",
      "Episode 53:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01668\n",
      "Avg qvals: -1.36007\n",
      "===========================================\n",
      "Episode 54:\n",
      "Reward: -21.0\n",
      "Steps: 1062\n",
      "Avg loss: 0.01651\n",
      "Avg qvals: -1.38205\n",
      "===========================================\n",
      "Episode 55:\n",
      "Reward: -19.0\n",
      "Steps: 1255\n",
      "Avg loss: 0.01846\n",
      "Avg qvals: -1.38182\n",
      "===========================================\n",
      "Episode 56:\n",
      "Reward: -21.0\n",
      "Steps: 1101\n",
      "Avg loss: 0.01694\n",
      "Avg qvals: -1.65523\n",
      "===========================================\n",
      "Episode 57:\n",
      "Reward: -19.0\n",
      "Steps: 1265\n",
      "Avg loss: 0.01662\n",
      "Avg qvals: -1.32378\n",
      "===========================================\n",
      "Episode 58:\n",
      "Reward: -21.0\n",
      "Steps: 1095\n",
      "Avg loss: 0.01805\n",
      "Avg qvals: -1.75296\n",
      "===========================================\n",
      "Episode 59:\n",
      "Reward: -20.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01709\n",
      "Avg qvals: -1.63812\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 60:\n",
      "Reward: -20.0\n",
      "Steps: 1115\n",
      "Avg loss: 0.01789\n",
      "Avg qvals: -1.47145\n",
      "===========================================\n",
      "Episode 61:\n",
      "Reward: -20.0\n",
      "Steps: 1197\n",
      "Avg loss: 0.01878\n",
      "Avg qvals: -1.70814\n",
      "===========================================\n",
      "Episode 62:\n",
      "Reward: -21.0\n",
      "Steps: 1267\n",
      "Avg loss: 0.01672\n",
      "Avg qvals: -1.61719\n",
      "===========================================\n",
      "Episode 63:\n",
      "Reward: -21.0\n",
      "Steps: 1086\n",
      "Avg loss: 0.01757\n",
      "Avg qvals: -1.57529\n",
      "===========================================\n",
      "Episode 64:\n",
      "Reward: -20.0\n",
      "Steps: 1122\n",
      "Avg loss: 0.01666\n",
      "Avg qvals: -1.62852\n",
      "===========================================\n",
      "Episode 65:\n",
      "Reward: -20.0\n",
      "Steps: 1376\n",
      "Avg loss: 0.01719\n",
      "Avg qvals: -1.64222\n",
      "===========================================\n",
      "Episode 66:\n",
      "Reward: -19.0\n",
      "Steps: 1284\n",
      "Avg loss: 0.01748\n",
      "Avg qvals: -1.55844\n",
      "===========================================\n",
      "Episode 67:\n",
      "Reward: -20.0\n",
      "Steps: 1114\n",
      "Avg loss: 0.01764\n",
      "Avg qvals: -1.61603\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 68:\n",
      "Reward: -21.0\n",
      "Steps: 1035\n",
      "Avg loss: 0.01713\n",
      "Avg qvals: -1.61855\n",
      "===========================================\n",
      "Episode 69:\n",
      "Reward: -21.0\n",
      "Steps: 1076\n",
      "Avg loss: 0.01767\n",
      "Avg qvals: -1.27528\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 70:\n",
      "Reward: -21.0\n",
      "Steps: 1164\n",
      "Avg loss: 0.01743\n",
      "Avg qvals: -1.48893\n",
      "===========================================\n",
      "Episode 71:\n",
      "Reward: -21.0\n",
      "Steps: 1039\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.79250\n",
      "===========================================\n",
      "Episode 72:\n",
      "Reward: -21.0\n",
      "Steps: 1061\n",
      "Avg loss: 0.01779\n",
      "Avg qvals: -1.55489\n",
      "===========================================\n",
      "Episode 73:\n",
      "Reward: -20.0\n",
      "Steps: 1557\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.76433\n",
      "===========================================\n",
      "Episode 74:\n",
      "Reward: -21.0\n",
      "Steps: 1131\n",
      "Avg loss: 0.01727\n",
      "Avg qvals: -1.71705\n",
      "===========================================\n",
      "Episode 75:\n",
      "Reward: -19.0\n",
      "Steps: 1363\n",
      "Avg loss: 0.01661\n",
      "Avg qvals: -1.68427\n",
      "===========================================\n",
      "Episode 76:\n",
      "Reward: -19.0\n",
      "Steps: 1348\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.59744\n",
      "===========================================\n",
      "Episode 77:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01760\n",
      "Avg qvals: -1.44396\n",
      "===========================================\n",
      "Episode 78:\n",
      "Reward: -20.0\n",
      "Steps: 1451\n",
      "Avg loss: 0.01795\n",
      "Avg qvals: -1.55679\n",
      "===========================================\n",
      "Episode 79:\n",
      "Reward: -21.0\n",
      "Steps: 1272\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.46793\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 80:\n",
      "Reward: -21.0\n",
      "Steps: 1048\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.55215\n",
      "===========================================\n",
      "Episode 81:\n",
      "Reward: -18.0\n",
      "Steps: 1525\n",
      "Avg loss: 0.01728\n",
      "Avg qvals: -1.39636\n",
      "===========================================\n",
      "Episode 82:\n",
      "Reward: -20.0\n",
      "Steps: 1150\n",
      "Avg loss: 0.01749\n",
      "Avg qvals: -1.33487\n",
      "===========================================\n",
      "Episode 83:\n",
      "Reward: -20.0\n",
      "Steps: 1153\n",
      "Avg loss: 0.01764\n",
      "Avg qvals: -1.66795\n",
      "===========================================\n",
      "Episode 84:\n",
      "Reward: -20.0\n",
      "Steps: 1114\n",
      "Avg loss: 0.01750\n",
      "Avg qvals: -1.55702\n",
      "===========================================\n",
      "Episode 85:\n",
      "Reward: -21.0\n",
      "Steps: 1143\n",
      "Avg loss: 0.01831\n",
      "Avg qvals: -1.48849\n",
      "===========================================\n",
      "Episode 86:\n",
      "Reward: -21.0\n",
      "Steps: 1045\n",
      "Avg loss: 0.01705\n",
      "Avg qvals: -1.56009\n",
      "===========================================\n",
      "Episode 87:\n",
      "Reward: -21.0\n",
      "Steps: 1422\n",
      "Avg loss: 0.01844\n",
      "Avg qvals: -1.66569\n",
      "===========================================\n",
      "Episode 88:\n",
      "Reward: -21.0\n",
      "Steps: 1057\n",
      "Avg loss: 0.01739\n",
      "Avg qvals: -1.83027\n",
      "===========================================\n",
      "Episode 89:\n",
      "Reward: -20.0\n",
      "Steps: 1300\n",
      "Avg loss: 0.01759\n",
      "Avg qvals: -1.81714\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 90:\n",
      "Reward: -20.0\n",
      "Steps: 1370\n",
      "Avg loss: 0.01738\n",
      "Avg qvals: -1.89887\n",
      "===========================================\n",
      "Episode 91:\n",
      "Reward: -20.0\n",
      "Steps: 1225\n",
      "Avg loss: 0.01814\n",
      "Avg qvals: -1.63102\n",
      "===========================================\n",
      "Episode 92:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01722\n",
      "Avg qvals: -1.49397\n",
      "===========================================\n",
      "Episode 93:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01590\n",
      "Avg qvals: -1.10986\n",
      "===========================================\n",
      "Episode 94:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01656\n",
      "Avg qvals: -1.54702\n",
      "===========================================\n",
      "Episode 95:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01760\n",
      "Avg qvals: -1.76390\n",
      "===========================================\n",
      "Episode 96:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01810\n",
      "Avg qvals: -1.72851\n",
      "===========================================\n",
      "Episode 97:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01710\n",
      "Avg qvals: -1.73441\n",
      "===========================================\n",
      "Episode 98:\n",
      "Reward: -21.0\n",
      "Steps: 1054\n",
      "Avg loss: 0.01755\n",
      "Avg qvals: -1.78638\n",
      "===========================================\n",
      "Episode 99:\n",
      "Reward: -21.0\n",
      "Steps: 1040\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.55634\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 100:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01816\n",
      "Avg qvals: -1.80584\n",
      "===========================================\n",
      "Episode 101:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01599\n",
      "Avg qvals: -1.45825\n",
      "===========================================\n",
      "Episode 102:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01663\n",
      "Avg qvals: -1.40273\n",
      "===========================================\n",
      "Episode 103:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01671\n",
      "Avg qvals: -1.64107\n",
      "===========================================\n",
      "Episode 104:\n",
      "Reward: -21.0\n",
      "Steps: 1006\n",
      "Avg loss: 0.01692\n",
      "Avg qvals: -1.66940\n",
      "===========================================\n",
      "Episode 105:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01713\n",
      "Avg qvals: -1.47553\n",
      "===========================================\n",
      "Episode 106:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01767\n",
      "Avg qvals: -1.50883\n",
      "===========================================\n",
      "Episode 107:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01753\n",
      "Avg qvals: -1.62083\n",
      "===========================================\n",
      "Episode 108:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.59286\n",
      "===========================================\n",
      "Episode 109:\n",
      "Reward: -21.0\n",
      "Steps: 1006\n",
      "Avg loss: 0.01731\n",
      "Avg qvals: -1.51477\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 110:\n",
      "Reward: -20.0\n",
      "Steps: 1233\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.77527\n",
      "===========================================\n",
      "Episode 111:\n",
      "Reward: -21.0\n",
      "Steps: 1152\n",
      "Avg loss: 0.01734\n",
      "Avg qvals: -1.42538\n",
      "===========================================\n",
      "Episode 112:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01895\n",
      "Avg qvals: -1.71442\n",
      "===========================================\n",
      "Episode 113:\n",
      "Reward: -21.0\n",
      "Steps: 1034\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.60250\n",
      "===========================================\n",
      "Episode 114:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01666\n",
      "Avg qvals: -1.42063\n",
      "===========================================\n",
      "Episode 115:\n",
      "Reward: -21.0\n",
      "Steps: 999\n",
      "Avg loss: 0.01713\n",
      "Avg qvals: -1.63420\n",
      "===========================================\n",
      "Episode 116:\n",
      "Reward: -21.0\n",
      "Steps: 1032\n",
      "Avg loss: 0.01721\n",
      "Avg qvals: -1.51285\n",
      "===========================================\n",
      "Episode 117:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01770\n",
      "Avg qvals: -1.71527\n",
      "===========================================\n",
      "Episode 118:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01830\n",
      "Avg qvals: -1.55207\n",
      "===========================================\n",
      "Episode 119:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01845\n",
      "Avg qvals: -1.41147\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 120:\n",
      "Reward: -21.0\n",
      "Steps: 1001\n",
      "Avg loss: 0.01747\n",
      "Avg qvals: -1.80583\n",
      "===========================================\n",
      "Episode 121:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01801\n",
      "Avg qvals: -1.69044\n",
      "===========================================\n",
      "Episode 122:\n",
      "Reward: -20.0\n",
      "Steps: 1207\n",
      "Avg loss: 0.01675\n",
      "Avg qvals: -1.49813\n",
      "===========================================\n",
      "Episode 123:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01750\n",
      "Avg qvals: -1.81679\n",
      "===========================================\n",
      "Episode 124:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01717\n",
      "Avg qvals: -1.43410\n",
      "===========================================\n",
      "Episode 125:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.59776\n",
      "===========================================\n",
      "Episode 126:\n",
      "Reward: -21.0\n",
      "Steps: 1135\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.72432\n",
      "===========================================\n",
      "Episode 127:\n",
      "Reward: -21.0\n",
      "Steps: 1103\n",
      "Avg loss: 0.01880\n",
      "Avg qvals: -1.79163\n",
      "===========================================\n",
      "Episode 128:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01928\n",
      "Avg qvals: -1.90635\n",
      "===========================================\n",
      "Episode 129:\n",
      "Reward: -21.0\n",
      "Steps: 1301\n",
      "Avg loss: 0.01775\n",
      "Avg qvals: -1.46649\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 130:\n",
      "Reward: -20.0\n",
      "Steps: 1275\n",
      "Avg loss: 0.01881\n",
      "Avg qvals: -2.05444\n",
      "===========================================\n",
      "Episode 131:\n",
      "Reward: -21.0\n",
      "Steps: 1180\n",
      "Avg loss: 0.01800\n",
      "Avg qvals: -1.47717\n",
      "===========================================\n",
      "Episode 132:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01643\n",
      "Avg qvals: -1.31848\n",
      "===========================================\n",
      "Episode 133:\n",
      "Reward: -21.0\n",
      "Steps: 1140\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -1.57902\n",
      "===========================================\n",
      "Episode 134:\n",
      "Reward: -21.0\n",
      "Steps: 1181\n",
      "Avg loss: 0.01855\n",
      "Avg qvals: -1.33944\n",
      "===========================================\n",
      "Episode 135:\n",
      "Reward: -20.0\n",
      "Steps: 1229\n",
      "Avg loss: 0.01916\n",
      "Avg qvals: -1.61603\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 136:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01722\n",
      "Avg qvals: -1.34071\n",
      "===========================================\n",
      "Episode 137:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01679\n",
      "Avg qvals: -1.42551\n",
      "===========================================\n",
      "Episode 138:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01667\n",
      "Avg qvals: -1.53372\n",
      "===========================================\n",
      "Episode 139:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01776\n",
      "Avg qvals: -1.75186\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 140:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.58880\n",
      "===========================================\n",
      "Episode 141:\n",
      "Reward: -21.0\n",
      "Steps: 1171\n",
      "Avg loss: 0.01793\n",
      "Avg qvals: -1.68215\n",
      "===========================================\n",
      "Episode 142:\n",
      "Reward: -21.0\n",
      "Steps: 1105\n",
      "Avg loss: 0.01841\n",
      "Avg qvals: -1.57791\n",
      "===========================================\n",
      "Episode 143:\n",
      "Reward: -21.0\n",
      "Steps: 1342\n",
      "Avg loss: 0.01846\n",
      "Avg qvals: -1.57415\n",
      "===========================================\n",
      "Episode 144:\n",
      "Reward: -20.0\n",
      "Steps: 1250\n",
      "Avg loss: 0.01700\n",
      "Avg qvals: -1.62093\n",
      "===========================================\n",
      "Episode 145:\n",
      "Reward: -21.0\n",
      "Steps: 1136\n",
      "Avg loss: 0.01826\n",
      "Avg qvals: -1.60971\n",
      "===========================================\n",
      "Episode 146:\n",
      "Reward: -20.0\n",
      "Steps: 1171\n",
      "Avg loss: 0.01764\n",
      "Avg qvals: -1.79169\n",
      "===========================================\n",
      "Episode 147:\n",
      "Reward: -21.0\n",
      "Steps: 1218\n",
      "Avg loss: 0.01914\n",
      "Avg qvals: -1.81584\n",
      "===========================================\n",
      "Episode 148:\n",
      "Reward: -18.0\n",
      "Steps: 1385\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.65167\n",
      "===========================================\n",
      "Episode 149:\n",
      "Reward: -21.0\n",
      "Steps: 1247\n",
      "Avg loss: 0.01822\n",
      "Avg qvals: -1.96786\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 150:\n",
      "Reward: -21.0\n",
      "Steps: 1273\n",
      "Avg loss: 0.01837\n",
      "Avg qvals: -1.53842\n",
      "===========================================\n",
      "Episode 151:\n",
      "Reward: -21.0\n",
      "Steps: 1148\n",
      "Avg loss: 0.01676\n",
      "Avg qvals: -1.70464\n",
      "===========================================\n",
      "Episode 152:\n",
      "Reward: -21.0\n",
      "Steps: 1104\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.58398\n",
      "===========================================\n",
      "Episode 153:\n",
      "Reward: -20.0\n",
      "Steps: 1188\n",
      "Avg loss: 0.01660\n",
      "Avg qvals: -1.74164\n",
      "===========================================\n",
      "Episode 154:\n",
      "Reward: -20.0\n",
      "Steps: 1355\n",
      "Avg loss: 0.01822\n",
      "Avg qvals: -1.67710\n",
      "===========================================\n",
      "Episode 155:\n",
      "Reward: -20.0\n",
      "Steps: 1200\n",
      "Avg loss: 0.01759\n",
      "Avg qvals: -1.75564\n",
      "===========================================\n",
      "Episode 156:\n",
      "Reward: -21.0\n",
      "Steps: 1151\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.92462\n",
      "===========================================\n",
      "Episode 157:\n",
      "Reward: -18.0\n",
      "Steps: 1567\n",
      "Avg loss: 0.01828\n",
      "Avg qvals: -1.55188\n",
      "===========================================\n",
      "Episode 158:\n",
      "Reward: -21.0\n",
      "Steps: 1145\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.65085\n",
      "===========================================\n",
      "Episode 159:\n",
      "Reward: -21.0\n",
      "Steps: 1181\n",
      "Avg loss: 0.01745\n",
      "Avg qvals: -1.62662\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 160:\n",
      "Reward: -19.0\n",
      "Steps: 1402\n",
      "Avg loss: 0.01729\n",
      "Avg qvals: -1.58841\n",
      "===========================================\n",
      "Episode 161:\n",
      "Reward: -21.0\n",
      "Steps: 1180\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.24528\n",
      "===========================================\n",
      "Episode 162:\n",
      "Reward: -20.0\n",
      "Steps: 1329\n",
      "Avg loss: 0.01765\n",
      "Avg qvals: -1.62165\n",
      "===========================================\n",
      "Episode 163:\n",
      "Reward: -20.0\n",
      "Steps: 1210\n",
      "Avg loss: 0.01751\n",
      "Avg qvals: -1.46944\n",
      "===========================================\n",
      "Episode 164:\n",
      "Reward: -20.0\n",
      "Steps: 1334\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.59397\n",
      "===========================================\n",
      "Episode 165:\n",
      "Reward: -20.0\n",
      "Steps: 1246\n",
      "Avg loss: 0.01766\n",
      "Avg qvals: -1.44087\n",
      "===========================================\n",
      "Episode 166:\n",
      "Reward: -21.0\n",
      "Steps: 1187\n",
      "Avg loss: 0.01961\n",
      "Avg qvals: -1.75762\n",
      "===========================================\n",
      "Episode 167:\n",
      "Reward: -20.0\n",
      "Steps: 1138\n",
      "Avg loss: 0.01704\n",
      "Avg qvals: -1.63984\n",
      "===========================================\n",
      "Episode 168:\n",
      "Reward: -20.0\n",
      "Steps: 1163\n",
      "Avg loss: 0.01727\n",
      "Avg qvals: -1.50420\n",
      "===========================================\n",
      "Episode 169:\n",
      "Reward: -18.0\n",
      "Steps: 1432\n",
      "Avg loss: 0.01786\n",
      "Avg qvals: -1.63780\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 170:\n",
      "Reward: -20.0\n",
      "Steps: 1115\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.82343\n",
      "===========================================\n",
      "Episode 171:\n",
      "Reward: -20.0\n",
      "Steps: 1150\n",
      "Avg loss: 0.01806\n",
      "Avg qvals: -1.71475\n",
      "===========================================\n",
      "Episode 172:\n",
      "Reward: -21.0\n",
      "Steps: 1101\n",
      "Avg loss: 0.01900\n",
      "Avg qvals: -1.75239\n",
      "===========================================\n",
      "Episode 173:\n",
      "Reward: -21.0\n",
      "Steps: 1199\n",
      "Avg loss: 0.01852\n",
      "Avg qvals: -1.61673\n",
      "===========================================\n",
      "Episode 174:\n",
      "Reward: -21.0\n",
      "Steps: 1035\n",
      "Avg loss: 0.01826\n",
      "Avg qvals: -1.44271\n",
      "===========================================\n",
      "Episode 175:\n",
      "Reward: -21.0\n",
      "Steps: 1275\n",
      "Avg loss: 0.01718\n",
      "Avg qvals: -1.78559\n",
      "===========================================\n",
      "Episode 176:\n",
      "Reward: -20.0\n",
      "Steps: 1103\n",
      "Avg loss: 0.01725\n",
      "Avg qvals: -1.70811\n",
      "===========================================\n",
      "Episode 177:\n",
      "Reward: -20.0\n",
      "Steps: 1118\n",
      "Avg loss: 0.01743\n",
      "Avg qvals: -1.79791\n",
      "===========================================\n",
      "Episode 178:\n",
      "Reward: -21.0\n",
      "Steps: 1062\n",
      "Avg loss: 0.01816\n",
      "Avg qvals: -1.65639\n",
      "===========================================\n",
      "Episode 179:\n",
      "Reward: -21.0\n",
      "Steps: 1263\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.80046\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 180:\n",
      "Reward: -21.0\n",
      "Steps: 1093\n",
      "Avg loss: 0.01883\n",
      "Avg qvals: -1.50108\n",
      "===========================================\n",
      "Episode 181:\n",
      "Reward: -21.0\n",
      "Steps: 1098\n",
      "Avg loss: 0.01676\n",
      "Avg qvals: -1.44874\n",
      "===========================================\n",
      "Episode 182:\n",
      "Reward: -21.0\n",
      "Steps: 1079\n",
      "Avg loss: 0.01854\n",
      "Avg qvals: -1.83272\n",
      "===========================================\n",
      "Episode 183:\n",
      "Reward: -20.0\n",
      "Steps: 1154\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.66845\n",
      "===========================================\n",
      "Episode 184:\n",
      "Reward: -21.0\n",
      "Steps: 1165\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.59731\n",
      "===========================================\n",
      "Episode 185:\n",
      "Reward: -20.0\n",
      "Steps: 1102\n",
      "Avg loss: 0.01650\n",
      "Avg qvals: -1.50691\n",
      "===========================================\n",
      "Episode 186:\n",
      "Reward: -21.0\n",
      "Steps: 1105\n",
      "Avg loss: 0.01745\n",
      "Avg qvals: -1.56991\n",
      "===========================================\n",
      "Episode 187:\n",
      "Reward: -21.0\n",
      "Steps: 1292\n",
      "Avg loss: 0.01715\n",
      "Avg qvals: -1.64129\n",
      "===========================================\n",
      "Episode 188:\n",
      "Reward: -21.0\n",
      "Steps: 1240\n",
      "Avg loss: 0.01889\n",
      "Avg qvals: -1.65229\n",
      "===========================================\n",
      "Episode 189:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01807\n",
      "Avg qvals: -1.61455\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 190:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01731\n",
      "Avg qvals: -1.66389\n",
      "===========================================\n",
      "Episode 191:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01642\n",
      "Avg qvals: -1.44645\n",
      "===========================================\n",
      "Episode 192:\n",
      "Reward: -21.0\n",
      "Steps: 1105\n",
      "Avg loss: 0.01840\n",
      "Avg qvals: -1.71430\n",
      "===========================================\n",
      "Episode 193:\n",
      "Reward: -20.0\n",
      "Steps: 1232\n",
      "Avg loss: 0.01833\n",
      "Avg qvals: -1.73065\n",
      "===========================================\n",
      "Episode 194:\n",
      "Reward: -20.0\n",
      "Steps: 1196\n",
      "Avg loss: 0.01798\n",
      "Avg qvals: -1.69080\n",
      "===========================================\n",
      "Episode 195:\n",
      "Reward: -20.0\n",
      "Steps: 1102\n",
      "Avg loss: 0.01730\n",
      "Avg qvals: -1.54637\n",
      "===========================================\n",
      "Episode 196:\n",
      "Reward: -21.0\n",
      "Steps: 1164\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.52114\n",
      "===========================================\n",
      "Episode 197:\n",
      "Reward: -21.0\n",
      "Steps: 1039\n",
      "Avg loss: 0.01709\n",
      "Avg qvals: -1.58940\n",
      "===========================================\n",
      "Episode 198:\n",
      "Reward: -21.0\n",
      "Steps: 1058\n",
      "Avg loss: 0.01628\n",
      "Avg qvals: -1.52868\n",
      "===========================================\n",
      "Episode 199:\n",
      "Reward: -21.0\n",
      "Steps: 1051\n",
      "Avg loss: 0.01814\n",
      "Avg qvals: -1.48823\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 200:\n",
      "Reward: -20.0\n",
      "Steps: 1197\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.75110\n",
      "===========================================\n",
      "Episode 201:\n",
      "Reward: -21.0\n",
      "Steps: 1130\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.55830\n",
      "===========================================\n",
      "Episode 202:\n",
      "Reward: -21.0\n",
      "Steps: 1110\n",
      "Avg loss: 0.01897\n",
      "Avg qvals: -1.63753\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 203:\n",
      "Reward: -20.0\n",
      "Steps: 1112\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.47908\n",
      "===========================================\n",
      "Episode 204:\n",
      "Reward: -20.0\n",
      "Steps: 1128\n",
      "Avg loss: 0.01588\n",
      "Avg qvals: -1.54764\n",
      "===========================================\n",
      "Episode 205:\n",
      "Reward: -21.0\n",
      "Steps: 1195\n",
      "Avg loss: 0.01782\n",
      "Avg qvals: -1.65002\n",
      "===========================================\n",
      "Episode 206:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01706\n",
      "Avg qvals: -1.67360\n",
      "===========================================\n",
      "Episode 207:\n",
      "Reward: -21.0\n",
      "Steps: 1088\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.56666\n",
      "===========================================\n",
      "Episode 208:\n",
      "Reward: -20.0\n",
      "Steps: 1219\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.56931\n",
      "===========================================\n",
      "Episode 209:\n",
      "Reward: -20.0\n",
      "Steps: 1139\n",
      "Avg loss: 0.01779\n",
      "Avg qvals: -1.71384\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 210:\n",
      "Reward: -21.0\n",
      "Steps: 1103\n",
      "Avg loss: 0.01608\n",
      "Avg qvals: -1.48564\n",
      "===========================================\n",
      "Episode 211:\n",
      "Reward: -20.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.01656\n",
      "Avg qvals: -1.63207\n",
      "===========================================\n",
      "Episode 212:\n",
      "Reward: -21.0\n",
      "Steps: 1094\n",
      "Avg loss: 0.01877\n",
      "Avg qvals: -1.72821\n",
      "===========================================\n",
      "Episode 213:\n",
      "Reward: -20.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01676\n",
      "Avg qvals: -1.50630\n",
      "===========================================\n",
      "Episode 214:\n",
      "Reward: -21.0\n",
      "Steps: 1174\n",
      "Avg loss: 0.01710\n",
      "Avg qvals: -1.44992\n",
      "===========================================\n",
      "Episode 215:\n",
      "Reward: -21.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01888\n",
      "Avg qvals: -1.80401\n",
      "===========================================\n",
      "Episode 216:\n",
      "Reward: -21.0\n",
      "Steps: 1074\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.42623\n",
      "===========================================\n",
      "Episode 217:\n",
      "Reward: -20.0\n",
      "Steps: 1119\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.62448\n",
      "===========================================\n",
      "Episode 218:\n",
      "Reward: -20.0\n",
      "Steps: 1344\n",
      "Avg loss: 0.01926\n",
      "Avg qvals: -1.85991\n",
      "===========================================\n",
      "Episode 219:\n",
      "Reward: -21.0\n",
      "Steps: 1084\n",
      "Avg loss: 0.01712\n",
      "Avg qvals: -1.56440\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 220:\n",
      "Reward: -21.0\n",
      "Steps: 1099\n",
      "Avg loss: 0.01595\n",
      "Avg qvals: -1.41878\n",
      "===========================================\n",
      "Episode 221:\n",
      "Reward: -21.0\n",
      "Steps: 1166\n",
      "Avg loss: 0.01802\n",
      "Avg qvals: -1.80976\n",
      "===========================================\n",
      "Episode 222:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01802\n",
      "Avg qvals: -1.67830\n",
      "===========================================\n",
      "Episode 223:\n",
      "Reward: -20.0\n",
      "Steps: 1221\n",
      "Avg loss: 0.01808\n",
      "Avg qvals: -1.54185\n",
      "===========================================\n",
      "Episode 224:\n",
      "Reward: -17.0\n",
      "Steps: 1642\n",
      "Avg loss: 0.01749\n",
      "Avg qvals: -1.54838\n",
      "===========================================\n",
      "Episode 225:\n",
      "Reward: -21.0\n",
      "Steps: 1107\n",
      "Avg loss: 0.01845\n",
      "Avg qvals: -1.68842\n",
      "===========================================\n",
      "Episode 226:\n",
      "Reward: -20.0\n",
      "Steps: 1339\n",
      "Avg loss: 0.01824\n",
      "Avg qvals: -1.57142\n",
      "===========================================\n",
      "Episode 227:\n",
      "Reward: -21.0\n",
      "Steps: 1003\n",
      "Avg loss: 0.01807\n",
      "Avg qvals: -1.72935\n",
      "===========================================\n",
      "Episode 228:\n",
      "Reward: -20.0\n",
      "Steps: 1290\n",
      "Avg loss: 0.01761\n",
      "Avg qvals: -1.65933\n",
      "===========================================\n",
      "Episode 229:\n",
      "Reward: -17.0\n",
      "Steps: 1645\n",
      "Avg loss: 0.01682\n",
      "Avg qvals: -1.66642\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 230:\n",
      "Reward: -20.0\n",
      "Steps: 1157\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.55930\n",
      "===========================================\n",
      "Episode 231:\n",
      "Reward: -19.0\n",
      "Steps: 1322\n",
      "Avg loss: 0.01697\n",
      "Avg qvals: -1.40028\n",
      "===========================================\n",
      "Episode 232:\n",
      "Reward: -19.0\n",
      "Steps: 1365\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.65919\n",
      "===========================================\n",
      "Episode 233:\n",
      "Reward: -21.0\n",
      "Steps: 1142\n",
      "Avg loss: 0.01816\n",
      "Avg qvals: -1.80225\n",
      "===========================================\n",
      "Episode 234:\n",
      "Reward: -18.0\n",
      "Steps: 1402\n",
      "Avg loss: 0.01602\n",
      "Avg qvals: -1.49789\n",
      "===========================================\n",
      "Episode 235:\n",
      "Reward: -21.0\n",
      "Steps: 1483\n",
      "Avg loss: 0.01699\n",
      "Avg qvals: -1.53507\n",
      "===========================================\n",
      "Episode 236:\n",
      "Reward: -20.0\n",
      "Steps: 1252\n",
      "Avg loss: 0.01749\n",
      "Avg qvals: -1.75575\n",
      "===========================================\n",
      "Episode 237:\n",
      "Reward: -19.0\n",
      "Steps: 1360\n",
      "Avg loss: 0.01861\n",
      "Avg qvals: -1.74526\n",
      "===========================================\n",
      "Episode 238:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01836\n",
      "Avg qvals: -1.59264\n",
      "===========================================\n",
      "Episode 239:\n",
      "Reward: -21.0\n",
      "Steps: 1209\n",
      "Avg loss: 0.01635\n",
      "Avg qvals: -1.63745\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 240:\n",
      "Reward: -21.0\n",
      "Steps: 1215\n",
      "Avg loss: 0.01699\n",
      "Avg qvals: -1.42196\n",
      "===========================================\n",
      "Episode 241:\n",
      "Reward: -21.0\n",
      "Steps: 1117\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.66128\n",
      "===========================================\n",
      "Episode 242:\n",
      "Reward: -18.0\n",
      "Steps: 1384\n",
      "Avg loss: 0.01678\n",
      "Avg qvals: -1.54600\n",
      "===========================================\n",
      "Episode 243:\n",
      "Reward: -19.0\n",
      "Steps: 1512\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.46030\n",
      "===========================================\n",
      "Episode 244:\n",
      "Reward: -19.0\n",
      "Steps: 1335\n",
      "Avg loss: 0.01793\n",
      "Avg qvals: -1.64787\n",
      "===========================================\n",
      "Episode 245:\n",
      "Reward: -19.0\n",
      "Steps: 1324\n",
      "Avg loss: 0.01724\n",
      "Avg qvals: -1.55781\n",
      "===========================================\n",
      "Episode 246:\n",
      "Reward: -19.0\n",
      "Steps: 1347\n",
      "Avg loss: 0.01812\n",
      "Avg qvals: -1.59870\n",
      "===========================================\n",
      "Episode 247:\n",
      "Reward: -19.0\n",
      "Steps: 1379\n",
      "Avg loss: 0.01727\n",
      "Avg qvals: -1.64963\n",
      "===========================================\n",
      "Episode 248:\n",
      "Reward: -21.0\n",
      "Steps: 1046\n",
      "Avg loss: 0.01660\n",
      "Avg qvals: -1.55481\n",
      "===========================================\n",
      "Episode 249:\n",
      "Reward: -21.0\n",
      "Steps: 1165\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.73568\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 250:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01660\n",
      "Avg qvals: -1.55391\n",
      "===========================================\n",
      "Episode 251:\n",
      "Reward: -21.0\n",
      "Steps: 1179\n",
      "Avg loss: 0.01872\n",
      "Avg qvals: -1.75006\n",
      "===========================================\n",
      "Episode 252:\n",
      "Reward: -21.0\n",
      "Steps: 1245\n",
      "Avg loss: 0.01726\n",
      "Avg qvals: -1.59922\n",
      "===========================================\n",
      "Episode 253:\n",
      "Reward: -20.0\n",
      "Steps: 1233\n",
      "Avg loss: 0.01634\n",
      "Avg qvals: -1.55969\n",
      "===========================================\n",
      "Episode 254:\n",
      "Reward: -20.0\n",
      "Steps: 1296\n",
      "Avg loss: 0.01697\n",
      "Avg qvals: -1.57698\n",
      "===========================================\n",
      "Episode 255:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01645\n",
      "Avg qvals: -1.60181\n",
      "===========================================\n",
      "Episode 256:\n",
      "Reward: -20.0\n",
      "Steps: 1198\n",
      "Avg loss: 0.01727\n",
      "Avg qvals: -1.47404\n",
      "===========================================\n",
      "Episode 257:\n",
      "Reward: -21.0\n",
      "Steps: 1205\n",
      "Avg loss: 0.01708\n",
      "Avg qvals: -1.55390\n",
      "===========================================\n",
      "Episode 258:\n",
      "Reward: -21.0\n",
      "Steps: 1069\n",
      "Avg loss: 0.01679\n",
      "Avg qvals: -1.49258\n",
      "===========================================\n",
      "Episode 259:\n",
      "Reward: -18.0\n",
      "Steps: 1362\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.69059\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 260:\n",
      "Reward: -21.0\n",
      "Steps: 1149\n",
      "Avg loss: 0.01700\n",
      "Avg qvals: -1.70432\n",
      "===========================================\n",
      "Episode 261:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01762\n",
      "Avg qvals: -1.55123\n",
      "===========================================\n",
      "Episode 262:\n",
      "Reward: -19.0\n",
      "Steps: 1413\n",
      "Avg loss: 0.01823\n",
      "Avg qvals: -1.53807\n",
      "===========================================\n",
      "Episode 263:\n",
      "Reward: -20.0\n",
      "Steps: 1246\n",
      "Avg loss: 0.01786\n",
      "Avg qvals: -1.80982\n",
      "===========================================\n",
      "Episode 264:\n",
      "Reward: -20.0\n",
      "Steps: 1319\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.55118\n",
      "===========================================\n",
      "Episode 265:\n",
      "Reward: -19.0\n",
      "Steps: 1411\n",
      "Avg loss: 0.01735\n",
      "Avg qvals: -1.67766\n",
      "===========================================\n",
      "Episode 266:\n",
      "Reward: -20.0\n",
      "Steps: 1273\n",
      "Avg loss: 0.01705\n",
      "Avg qvals: -1.49237\n",
      "===========================================\n",
      "Episode 267:\n",
      "Reward: -20.0\n",
      "Steps: 1117\n",
      "Avg loss: 0.01665\n",
      "Avg qvals: -1.50807\n",
      "===========================================\n",
      "Episode 268:\n",
      "Reward: -19.0\n",
      "Steps: 1500\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.60957\n",
      "===========================================\n",
      "Episode 269:\n",
      "Reward: -21.0\n",
      "Steps: 1174\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.52557\n",
      "===========================================\n",
      "Model saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 270:\n",
      "Reward: -20.0\n",
      "Steps: 1122\n",
      "Avg loss: 0.01805\n",
      "Avg qvals: -1.47548\n",
      "===========================================\n",
      "Episode 271:\n",
      "Reward: -20.0\n",
      "Steps: 1387\n",
      "Avg loss: 0.01758\n",
      "Avg qvals: -1.53755\n",
      "===========================================\n",
      "Episode 272:\n",
      "Reward: -20.0\n",
      "Steps: 1360\n",
      "Avg loss: 0.01753\n",
      "Avg qvals: -1.49485\n",
      "===========================================\n",
      "Episode 273:\n",
      "Reward: -20.0\n",
      "Steps: 1352\n",
      "Avg loss: 0.01745\n",
      "Avg qvals: -1.53560\n",
      "===========================================\n",
      "Episode 274:\n",
      "Reward: -20.0\n",
      "Steps: 1119\n",
      "Avg loss: 0.01843\n",
      "Avg qvals: -1.68706\n",
      "===========================================\n",
      "Episode 275:\n",
      "Reward: -21.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.76823\n",
      "===========================================\n",
      "Episode 276:\n",
      "Reward: -20.0\n",
      "Steps: 1175\n",
      "Avg loss: 0.01735\n",
      "Avg qvals: -1.82115\n",
      "===========================================\n",
      "Episode 277:\n",
      "Reward: -19.0\n",
      "Steps: 1261\n",
      "Avg loss: 0.01776\n",
      "Avg qvals: -1.51873\n",
      "===========================================\n",
      "Episode 278:\n",
      "Reward: -20.0\n",
      "Steps: 1259\n",
      "Avg loss: 0.01806\n",
      "Avg qvals: -1.70976\n",
      "===========================================\n",
      "Episode 279:\n",
      "Reward: -21.0\n",
      "Steps: 1107\n",
      "Avg loss: 0.01796\n",
      "Avg qvals: -1.50011\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 280:\n",
      "Reward: -20.0\n",
      "Steps: 1277\n",
      "Avg loss: 0.01760\n",
      "Avg qvals: -1.60981\n",
      "===========================================\n",
      "Episode 281:\n",
      "Reward: -18.0\n",
      "Steps: 1359\n",
      "Avg loss: 0.01765\n",
      "Avg qvals: -1.72821\n",
      "===========================================\n",
      "Episode 282:\n",
      "Reward: -20.0\n",
      "Steps: 1397\n",
      "Avg loss: 0.01802\n",
      "Avg qvals: -1.63258\n",
      "===========================================\n",
      "Episode 283:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01674\n",
      "Avg qvals: -1.60578\n",
      "===========================================\n",
      "Episode 284:\n",
      "Reward: -19.0\n",
      "Steps: 1356\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.69907\n",
      "===========================================\n",
      "Episode 285:\n",
      "Reward: -21.0\n",
      "Steps: 1079\n",
      "Avg loss: 0.01678\n",
      "Avg qvals: -1.50110\n",
      "===========================================\n",
      "Episode 286:\n",
      "Reward: -19.0\n",
      "Steps: 1416\n",
      "Avg loss: 0.01721\n",
      "Avg qvals: -1.65956\n",
      "===========================================\n",
      "Episode 287:\n",
      "Reward: -20.0\n",
      "Steps: 1264\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.60349\n",
      "===========================================\n",
      "Episode 288:\n",
      "Reward: -21.0\n",
      "Steps: 1084\n",
      "Avg loss: 0.01688\n",
      "Avg qvals: -1.60741\n",
      "===========================================\n",
      "Episode 289:\n",
      "Reward: -21.0\n",
      "Steps: 1083\n",
      "Avg loss: 0.01782\n",
      "Avg qvals: -1.60265\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 290:\n",
      "Reward: -21.0\n",
      "Steps: 1094\n",
      "Avg loss: 0.01757\n",
      "Avg qvals: -1.71634\n",
      "===========================================\n",
      "Episode 291:\n",
      "Reward: -21.0\n",
      "Steps: 1147\n",
      "Avg loss: 0.01761\n",
      "Avg qvals: -1.79044\n",
      "===========================================\n",
      "Episode 292:\n",
      "Reward: -19.0\n",
      "Steps: 1403\n",
      "Avg loss: 0.01695\n",
      "Avg qvals: -1.64696\n",
      "===========================================\n",
      "Episode 293:\n",
      "Reward: -21.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01776\n",
      "Avg qvals: -1.75032\n",
      "===========================================\n",
      "Episode 294:\n",
      "Reward: -20.0\n",
      "Steps: 1285\n",
      "Avg loss: 0.01762\n",
      "Avg qvals: -1.75011\n",
      "===========================================\n",
      "Episode 295:\n",
      "Reward: -20.0\n",
      "Steps: 1196\n",
      "Avg loss: 0.01718\n",
      "Avg qvals: -1.54993\n",
      "===========================================\n",
      "Episode 296:\n",
      "Reward: -21.0\n",
      "Steps: 1072\n",
      "Avg loss: 0.01639\n",
      "Avg qvals: -1.35061\n",
      "===========================================\n",
      "Episode 297:\n",
      "Reward: -20.0\n",
      "Steps: 1151\n",
      "Avg loss: 0.01690\n",
      "Avg qvals: -1.47658\n",
      "===========================================\n",
      "Episode 298:\n",
      "Reward: -19.0\n",
      "Steps: 1422\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -1.70185\n",
      "===========================================\n",
      "Episode 299:\n",
      "Reward: -20.0\n",
      "Steps: 1148\n",
      "Avg loss: 0.01649\n",
      "Avg qvals: -1.42049\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 300:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01766\n",
      "Avg qvals: -1.64042\n",
      "===========================================\n",
      "Episode 301:\n",
      "Reward: -21.0\n",
      "Steps: 1131\n",
      "Avg loss: 0.01693\n",
      "Avg qvals: -1.52641\n",
      "===========================================\n",
      "Episode 302:\n",
      "Reward: -21.0\n",
      "Steps: 1186\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.75382\n",
      "===========================================\n",
      "Episode 303:\n",
      "Reward: -21.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01760\n",
      "Avg qvals: -1.66899\n",
      "===========================================\n",
      "Episode 304:\n",
      "Reward: -19.0\n",
      "Steps: 1445\n",
      "Avg loss: 0.01779\n",
      "Avg qvals: -1.59516\n",
      "===========================================\n",
      "Episode 305:\n",
      "Reward: -21.0\n",
      "Steps: 1049\n",
      "Avg loss: 0.01806\n",
      "Avg qvals: -1.67080\n",
      "===========================================\n",
      "Episode 306:\n",
      "Reward: -20.0\n",
      "Steps: 1191\n",
      "Avg loss: 0.01890\n",
      "Avg qvals: -1.75561\n",
      "===========================================\n",
      "Episode 307:\n",
      "Reward: -18.0\n",
      "Steps: 1429\n",
      "Avg loss: 0.01714\n",
      "Avg qvals: -1.57198\n",
      "===========================================\n",
      "Episode 308:\n",
      "Reward: -20.0\n",
      "Steps: 1157\n",
      "Avg loss: 0.01872\n",
      "Avg qvals: -1.66194\n",
      "===========================================\n",
      "Episode 309:\n",
      "Reward: -21.0\n",
      "Steps: 1109\n",
      "Avg loss: 0.01773\n",
      "Avg qvals: -1.56218\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 310:\n",
      "Reward: -19.0\n",
      "Steps: 1390\n",
      "Avg loss: 0.01710\n",
      "Avg qvals: -1.51121\n",
      "===========================================\n",
      "Episode 311:\n",
      "Reward: -20.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.64556\n",
      "===========================================\n",
      "Episode 312:\n",
      "Reward: -21.0\n",
      "Steps: 1050\n",
      "Avg loss: 0.01664\n",
      "Avg qvals: -1.61255\n",
      "===========================================\n",
      "Episode 313:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01639\n",
      "Avg qvals: -1.44979\n",
      "===========================================\n",
      "Episode 314:\n",
      "Reward: -21.0\n",
      "Steps: 1039\n",
      "Avg loss: 0.01721\n",
      "Avg qvals: -1.55174\n",
      "===========================================\n",
      "Episode 315:\n",
      "Reward: -20.0\n",
      "Steps: 1238\n",
      "Avg loss: 0.01831\n",
      "Avg qvals: -1.60560\n",
      "===========================================\n",
      "Episode 316:\n",
      "Reward: -21.0\n",
      "Steps: 1062\n",
      "Avg loss: 0.01698\n",
      "Avg qvals: -1.58098\n",
      "===========================================\n",
      "Episode 317:\n",
      "Reward: -21.0\n",
      "Steps: 1065\n",
      "Avg loss: 0.01710\n",
      "Avg qvals: -1.53155\n",
      "===========================================\n",
      "Episode 318:\n",
      "Reward: -21.0\n",
      "Steps: 1176\n",
      "Avg loss: 0.01693\n",
      "Avg qvals: -1.57056\n",
      "===========================================\n",
      "Episode 319:\n",
      "Reward: -20.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01748\n",
      "Avg qvals: -1.63711\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 320:\n",
      "Reward: -18.0\n",
      "Steps: 1432\n",
      "Avg loss: 0.01656\n",
      "Avg qvals: -1.60593\n",
      "===========================================\n",
      "Episode 321:\n",
      "Reward: -20.0\n",
      "Steps: 1347\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -1.57039\n",
      "===========================================\n",
      "Episode 322:\n",
      "Reward: -20.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.54669\n",
      "===========================================\n",
      "Episode 323:\n",
      "Reward: -19.0\n",
      "Steps: 1538\n",
      "Avg loss: 0.01692\n",
      "Avg qvals: -1.48397\n",
      "===========================================\n",
      "Episode 324:\n",
      "Reward: -20.0\n",
      "Steps: 1117\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.48790\n",
      "===========================================\n",
      "Episode 325:\n",
      "Reward: -20.0\n",
      "Steps: 1309\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.64087\n",
      "===========================================\n",
      "Episode 326:\n",
      "Reward: -21.0\n",
      "Steps: 1123\n",
      "Avg loss: 0.01766\n",
      "Avg qvals: -1.69873\n",
      "===========================================\n",
      "Episode 327:\n",
      "Reward: -21.0\n",
      "Steps: 1146\n",
      "Avg loss: 0.01707\n",
      "Avg qvals: -1.52708\n",
      "===========================================\n",
      "Episode 328:\n",
      "Reward: -21.0\n",
      "Steps: 1113\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.80122\n",
      "===========================================\n",
      "Episode 329:\n",
      "Reward: -19.0\n",
      "Steps: 1265\n",
      "Avg loss: 0.01716\n",
      "Avg qvals: -1.55654\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 330:\n",
      "Reward: -21.0\n",
      "Steps: 1129\n",
      "Avg loss: 0.01861\n",
      "Avg qvals: -1.82318\n",
      "===========================================\n",
      "Episode 331:\n",
      "Reward: -21.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01689\n",
      "Avg qvals: -1.57790\n",
      "===========================================\n",
      "Episode 332:\n",
      "Reward: -20.0\n",
      "Steps: 1430\n",
      "Avg loss: 0.01717\n",
      "Avg qvals: -1.61517\n",
      "===========================================\n",
      "Episode 333:\n",
      "Reward: -21.0\n",
      "Steps: 1139\n",
      "Avg loss: 0.01798\n",
      "Avg qvals: -1.69512\n",
      "===========================================\n",
      "Episode 334:\n",
      "Reward: -21.0\n",
      "Steps: 1000\n",
      "Avg loss: 0.01824\n",
      "Avg qvals: -1.65096\n",
      "===========================================\n",
      "Episode 335:\n",
      "Reward: -20.0\n",
      "Steps: 1166\n",
      "Avg loss: 0.01739\n",
      "Avg qvals: -1.58847\n",
      "===========================================\n",
      "Episode 336:\n",
      "Reward: -21.0\n",
      "Steps: 1134\n",
      "Avg loss: 0.01696\n",
      "Avg qvals: -1.60751\n",
      "===========================================\n",
      "Episode 337:\n",
      "Reward: -21.0\n",
      "Steps: 1003\n",
      "Avg loss: 0.01611\n",
      "Avg qvals: -1.55398\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 338:\n",
      "Reward: -20.0\n",
      "Steps: 1226\n",
      "Avg loss: 0.01658\n",
      "Avg qvals: -1.50799\n",
      "===========================================\n",
      "Episode 339:\n",
      "Reward: -20.0\n",
      "Steps: 1128\n",
      "Avg loss: 0.01700\n",
      "Avg qvals: -1.54687\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 340:\n",
      "Reward: -21.0\n",
      "Steps: 1175\n",
      "Avg loss: 0.01849\n",
      "Avg qvals: -1.80079\n",
      "===========================================\n",
      "Episode 341:\n",
      "Reward: -20.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.62542\n",
      "===========================================\n",
      "Episode 342:\n",
      "Reward: -18.0\n",
      "Steps: 1453\n",
      "Avg loss: 0.01750\n",
      "Avg qvals: -1.70388\n",
      "===========================================\n",
      "Episode 343:\n",
      "Reward: -21.0\n",
      "Steps: 1050\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.75215\n",
      "===========================================\n",
      "Episode 344:\n",
      "Reward: -21.0\n",
      "Steps: 1082\n",
      "Avg loss: 0.01754\n",
      "Avg qvals: -1.56492\n",
      "===========================================\n",
      "Episode 345:\n",
      "Reward: -21.0\n",
      "Steps: 1055\n",
      "Avg loss: 0.01913\n",
      "Avg qvals: -1.80896\n",
      "===========================================\n",
      "Episode 346:\n",
      "Reward: -21.0\n",
      "Steps: 1129\n",
      "Avg loss: 0.01842\n",
      "Avg qvals: -1.68906\n",
      "===========================================\n",
      "Episode 347:\n",
      "Reward: -19.0\n",
      "Steps: 1357\n",
      "Avg loss: 0.01647\n",
      "Avg qvals: -1.52050\n",
      "===========================================\n",
      "Episode 348:\n",
      "Reward: -21.0\n",
      "Steps: 1099\n",
      "Avg loss: 0.01694\n",
      "Avg qvals: -1.58179\n",
      "===========================================\n",
      "Episode 349:\n",
      "Reward: -21.0\n",
      "Steps: 1177\n",
      "Avg loss: 0.01860\n",
      "Avg qvals: -1.70238\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 350:\n",
      "Reward: -20.0\n",
      "Steps: 1232\n",
      "Avg loss: 0.01754\n",
      "Avg qvals: -1.57382\n",
      "===========================================\n",
      "Episode 351:\n",
      "Reward: -20.0\n",
      "Steps: 1310\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.58316\n",
      "===========================================\n",
      "Episode 352:\n",
      "Reward: -19.0\n",
      "Steps: 1361\n",
      "Avg loss: 0.01678\n",
      "Avg qvals: -1.50596\n",
      "===========================================\n",
      "Episode 353:\n",
      "Reward: -20.0\n",
      "Steps: 1158\n",
      "Avg loss: 0.01848\n",
      "Avg qvals: -1.76795\n",
      "===========================================\n",
      "Episode 354:\n",
      "Reward: -20.0\n",
      "Steps: 1184\n",
      "Avg loss: 0.01764\n",
      "Avg qvals: -1.59817\n",
      "===========================================\n",
      "Episode 355:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01719\n",
      "Avg qvals: -1.61468\n",
      "===========================================\n",
      "Episode 356:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01718\n",
      "Avg qvals: -1.42919\n",
      "===========================================\n",
      "Episode 357:\n",
      "Reward: -21.0\n",
      "Steps: 1238\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.64132\n",
      "===========================================\n",
      "Episode 358:\n",
      "Reward: -20.0\n",
      "Steps: 1170\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.57410\n",
      "===========================================\n",
      "Episode 359:\n",
      "Reward: -20.0\n",
      "Steps: 1218\n",
      "Avg loss: 0.01712\n",
      "Avg qvals: -1.51122\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 360:\n",
      "Reward: -20.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01603\n",
      "Avg qvals: -1.36162\n",
      "===========================================\n",
      "Episode 361:\n",
      "Reward: -20.0\n",
      "Steps: 1188\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.74961\n",
      "===========================================\n",
      "Episode 362:\n",
      "Reward: -20.0\n",
      "Steps: 1193\n",
      "Avg loss: 0.01647\n",
      "Avg qvals: -1.48566\n",
      "===========================================\n",
      "Episode 363:\n",
      "Reward: -20.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.01674\n",
      "Avg qvals: -1.53559\n",
      "===========================================\n",
      "Episode 364:\n",
      "Reward: -20.0\n",
      "Steps: 1199\n",
      "Avg loss: 0.01671\n",
      "Avg qvals: -1.41722\n",
      "===========================================\n",
      "Episode 365:\n",
      "Reward: -19.0\n",
      "Steps: 1238\n",
      "Avg loss: 0.01844\n",
      "Avg qvals: -1.75394\n",
      "===========================================\n",
      "Episode 366:\n",
      "Reward: -19.0\n",
      "Steps: 1281\n",
      "Avg loss: 0.01672\n",
      "Avg qvals: -1.53118\n",
      "===========================================\n",
      "Episode 367:\n",
      "Reward: -21.0\n",
      "Steps: 1098\n",
      "Avg loss: 0.01876\n",
      "Avg qvals: -1.67455\n",
      "===========================================\n",
      "Episode 368:\n",
      "Reward: -21.0\n",
      "Steps: 1142\n",
      "Avg loss: 0.01707\n",
      "Avg qvals: -1.59965\n",
      "===========================================\n",
      "Episode 369:\n",
      "Reward: -21.0\n",
      "Steps: 1035\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.66350\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 370:\n",
      "Reward: -21.0\n",
      "Steps: 1110\n",
      "Avg loss: 0.01640\n",
      "Avg qvals: -1.45199\n",
      "===========================================\n",
      "Episode 371:\n",
      "Reward: -20.0\n",
      "Steps: 1112\n",
      "Avg loss: 0.01832\n",
      "Avg qvals: -1.64994\n",
      "===========================================\n",
      "Episode 372:\n",
      "Reward: -21.0\n",
      "Steps: 1167\n",
      "Avg loss: 0.01685\n",
      "Avg qvals: -1.49006\n",
      "===========================================\n",
      "Episode 373:\n",
      "Reward: -21.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01690\n",
      "Avg qvals: -1.55703\n",
      "===========================================\n",
      "Episode 374:\n",
      "Reward: -21.0\n",
      "Steps: 1234\n",
      "Avg loss: 0.01732\n",
      "Avg qvals: -1.58631\n",
      "===========================================\n",
      "Episode 375:\n",
      "Reward: -20.0\n",
      "Steps: 1159\n",
      "Avg loss: 0.01608\n",
      "Avg qvals: -1.50862\n",
      "===========================================\n",
      "Episode 376:\n",
      "Reward: -21.0\n",
      "Steps: 1071\n",
      "Avg loss: 0.01765\n",
      "Avg qvals: -1.45201\n",
      "===========================================\n",
      "Episode 377:\n",
      "Reward: -20.0\n",
      "Steps: 1220\n",
      "Avg loss: 0.01738\n",
      "Avg qvals: -1.54503\n",
      "===========================================\n",
      "Episode 378:\n",
      "Reward: -20.0\n",
      "Steps: 1200\n",
      "Avg loss: 0.01750\n",
      "Avg qvals: -1.52599\n",
      "===========================================\n",
      "Episode 379:\n",
      "Reward: -20.0\n",
      "Steps: 1335\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.56015\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 380:\n",
      "Reward: -20.0\n",
      "Steps: 1193\n",
      "Avg loss: 0.01681\n",
      "Avg qvals: -1.44750\n",
      "===========================================\n",
      "Episode 381:\n",
      "Reward: -20.0\n",
      "Steps: 1304\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.66909\n",
      "===========================================\n",
      "Episode 382:\n",
      "Reward: -19.0\n",
      "Steps: 1373\n",
      "Avg loss: 0.01840\n",
      "Avg qvals: -1.65061\n",
      "===========================================\n",
      "Episode 383:\n",
      "Reward: -21.0\n",
      "Steps: 1211\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.70295\n",
      "===========================================\n",
      "Episode 384:\n",
      "Reward: -21.0\n",
      "Steps: 1071\n",
      "Avg loss: 0.01825\n",
      "Avg qvals: -1.75516\n",
      "===========================================\n",
      "Episode 385:\n",
      "Reward: -21.0\n",
      "Steps: 1041\n",
      "Avg loss: 0.01653\n",
      "Avg qvals: -1.52958\n",
      "===========================================\n",
      "Episode 386:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01632\n",
      "Avg qvals: -1.43952\n",
      "===========================================\n",
      "Episode 387:\n",
      "Reward: -20.0\n",
      "Steps: 1229\n",
      "Avg loss: 0.01853\n",
      "Avg qvals: -1.70935\n",
      "===========================================\n",
      "Episode 388:\n",
      "Reward: -21.0\n",
      "Steps: 1063\n",
      "Avg loss: 0.01692\n",
      "Avg qvals: -1.47629\n",
      "===========================================\n",
      "Episode 389:\n",
      "Reward: -18.0\n",
      "Steps: 1454\n",
      "Avg loss: 0.01830\n",
      "Avg qvals: -1.70374\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 390:\n",
      "Reward: -20.0\n",
      "Steps: 1205\n",
      "Avg loss: 0.01730\n",
      "Avg qvals: -1.76834\n",
      "===========================================\n",
      "Episode 391:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01754\n",
      "Avg qvals: -1.59940\n",
      "===========================================\n",
      "Episode 392:\n",
      "Reward: -19.0\n",
      "Steps: 1253\n",
      "Avg loss: 0.01725\n",
      "Avg qvals: -1.59818\n",
      "===========================================\n",
      "Episode 393:\n",
      "Reward: -19.0\n",
      "Steps: 1437\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.67411\n",
      "===========================================\n",
      "Episode 394:\n",
      "Reward: -19.0\n",
      "Steps: 1465\n",
      "Avg loss: 0.01738\n",
      "Avg qvals: -1.62553\n",
      "===========================================\n",
      "Episode 395:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01854\n",
      "Avg qvals: -1.62148\n",
      "===========================================\n",
      "Episode 396:\n",
      "Reward: -20.0\n",
      "Steps: 1202\n",
      "Avg loss: 0.01918\n",
      "Avg qvals: -1.76457\n",
      "===========================================\n",
      "Episode 397:\n",
      "Reward: -20.0\n",
      "Steps: 1355\n",
      "Avg loss: 0.01816\n",
      "Avg qvals: -1.80006\n",
      "===========================================\n",
      "Episode 398:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.67270\n",
      "===========================================\n",
      "Episode 399:\n",
      "Reward: -20.0\n",
      "Steps: 1259\n",
      "Avg loss: 0.01725\n",
      "Avg qvals: -1.56954\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 400:\n",
      "Reward: -20.0\n",
      "Steps: 1153\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.54291\n",
      "===========================================\n",
      "Episode 401:\n",
      "Reward: -19.0\n",
      "Steps: 1380\n",
      "Avg loss: 0.01842\n",
      "Avg qvals: -1.66088\n",
      "===========================================\n",
      "Episode 402:\n",
      "Reward: -20.0\n",
      "Steps: 1171\n",
      "Avg loss: 0.01759\n",
      "Avg qvals: -1.53272\n",
      "===========================================\n",
      "Episode 403:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01762\n",
      "Avg qvals: -1.68060\n",
      "===========================================\n",
      "Episode 404:\n",
      "Reward: -19.0\n",
      "Steps: 1495\n",
      "Avg loss: 0.01710\n",
      "Avg qvals: -1.56827\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 405:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01875\n",
      "Avg qvals: -1.87985\n",
      "===========================================\n",
      "Episode 406:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01808\n",
      "Avg qvals: -1.65883\n",
      "===========================================\n",
      "Episode 407:\n",
      "Reward: -21.0\n",
      "Steps: 1125\n",
      "Avg loss: 0.01676\n",
      "Avg qvals: -1.50316\n",
      "===========================================\n",
      "Episode 408:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01738\n",
      "Avg qvals: -1.67359\n",
      "===========================================\n",
      "Episode 409:\n",
      "Reward: -20.0\n",
      "Steps: 1202\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.71049\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 410:\n",
      "Reward: -20.0\n",
      "Steps: 1183\n",
      "Avg loss: 0.01727\n",
      "Avg qvals: -1.56065\n",
      "===========================================\n",
      "Episode 411:\n",
      "Reward: -21.0\n",
      "Steps: 1155\n",
      "Avg loss: 0.01758\n",
      "Avg qvals: -1.62897\n",
      "===========================================\n",
      "Episode 412:\n",
      "Reward: -21.0\n",
      "Steps: 1224\n",
      "Avg loss: 0.01845\n",
      "Avg qvals: -1.55316\n",
      "===========================================\n",
      "Episode 413:\n",
      "Reward: -20.0\n",
      "Steps: 1227\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.58188\n",
      "===========================================\n",
      "Episode 414:\n",
      "Reward: -21.0\n",
      "Steps: 1142\n",
      "Avg loss: 0.01842\n",
      "Avg qvals: -1.83179\n",
      "===========================================\n",
      "Episode 415:\n",
      "Reward: -20.0\n",
      "Steps: 1164\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.52078\n",
      "===========================================\n",
      "Episode 416:\n",
      "Reward: -19.0\n",
      "Steps: 1210\n",
      "Avg loss: 0.01664\n",
      "Avg qvals: -1.47969\n",
      "===========================================\n",
      "Episode 417:\n",
      "Reward: -21.0\n",
      "Steps: 1049\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.52357\n",
      "===========================================\n",
      "Episode 418:\n",
      "Reward: -20.0\n",
      "Steps: 1243\n",
      "Avg loss: 0.01679\n",
      "Avg qvals: -1.41990\n",
      "===========================================\n",
      "Episode 419:\n",
      "Reward: -21.0\n",
      "Steps: 1211\n",
      "Avg loss: 0.01705\n",
      "Avg qvals: -1.61296\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 420:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01642\n",
      "Avg qvals: -1.50910\n",
      "===========================================\n",
      "Episode 421:\n",
      "Reward: -21.0\n",
      "Steps: 1120\n",
      "Avg loss: 0.01761\n",
      "Avg qvals: -1.68172\n",
      "===========================================\n",
      "Episode 422:\n",
      "Reward: -20.0\n",
      "Steps: 1194\n",
      "Avg loss: 0.01746\n",
      "Avg qvals: -1.45524\n",
      "===========================================\n",
      "Episode 423:\n",
      "Reward: -21.0\n",
      "Steps: 1178\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.52623\n",
      "===========================================\n",
      "Episode 424:\n",
      "Reward: -20.0\n",
      "Steps: 1128\n",
      "Avg loss: 0.01611\n",
      "Avg qvals: -1.63333\n",
      "===========================================\n",
      "Episode 425:\n",
      "Reward: -21.0\n",
      "Steps: 1152\n",
      "Avg loss: 0.01789\n",
      "Avg qvals: -1.50286\n",
      "===========================================\n",
      "Episode 426:\n",
      "Reward: -21.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01724\n",
      "Avg qvals: -1.39588\n",
      "===========================================\n",
      "Episode 427:\n",
      "Reward: -20.0\n",
      "Steps: 1235\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.59863\n",
      "===========================================\n",
      "Episode 428:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01795\n",
      "Avg qvals: -1.67223\n",
      "===========================================\n",
      "Episode 429:\n",
      "Reward: -21.0\n",
      "Steps: 1054\n",
      "Avg loss: 0.01738\n",
      "Avg qvals: -1.60375\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 430:\n",
      "Reward: -20.0\n",
      "Steps: 1122\n",
      "Avg loss: 0.01868\n",
      "Avg qvals: -1.71820\n",
      "===========================================\n",
      "Episode 431:\n",
      "Reward: -20.0\n",
      "Steps: 1343\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.46248\n",
      "===========================================\n",
      "Episode 432:\n",
      "Reward: -21.0\n",
      "Steps: 1108\n",
      "Avg loss: 0.01739\n",
      "Avg qvals: -1.69161\n",
      "===========================================\n",
      "Episode 433:\n",
      "Reward: -21.0\n",
      "Steps: 1053\n",
      "Avg loss: 0.01939\n",
      "Avg qvals: -1.86278\n",
      "===========================================\n",
      "Episode 434:\n",
      "Reward: -21.0\n",
      "Steps: 1170\n",
      "Avg loss: 0.01586\n",
      "Avg qvals: -1.45274\n",
      "===========================================\n",
      "Episode 435:\n",
      "Reward: -19.0\n",
      "Steps: 1246\n",
      "Avg loss: 0.01767\n",
      "Avg qvals: -1.54151\n",
      "===========================================\n",
      "Episode 436:\n",
      "Reward: -21.0\n",
      "Steps: 1103\n",
      "Avg loss: 0.01789\n",
      "Avg qvals: -1.58329\n",
      "===========================================\n",
      "Episode 437:\n",
      "Reward: -21.0\n",
      "Steps: 1109\n",
      "Avg loss: 0.01655\n",
      "Avg qvals: -1.58850\n",
      "===========================================\n",
      "Episode 438:\n",
      "Reward: -20.0\n",
      "Steps: 1157\n",
      "Avg loss: 0.01676\n",
      "Avg qvals: -1.49132\n",
      "===========================================\n",
      "Episode 439:\n",
      "Reward: -20.0\n",
      "Steps: 1219\n",
      "Avg loss: 0.01826\n",
      "Avg qvals: -1.83777\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 440:\n",
      "Reward: -21.0\n",
      "Steps: 1161\n",
      "Avg loss: 0.01661\n",
      "Avg qvals: -1.53636\n",
      "===========================================\n",
      "Episode 441:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01738\n",
      "Avg qvals: -1.62639\n",
      "===========================================\n",
      "Episode 442:\n",
      "Reward: -20.0\n",
      "Steps: 1184\n",
      "Avg loss: 0.01616\n",
      "Avg qvals: -1.57342\n",
      "===========================================\n",
      "Episode 443:\n",
      "Reward: -21.0\n",
      "Steps: 1285\n",
      "Avg loss: 0.01816\n",
      "Avg qvals: -1.72904\n",
      "===========================================\n",
      "Episode 444:\n",
      "Reward: -16.0\n",
      "Steps: 1669\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.71142\n",
      "===========================================\n",
      "Episode 445:\n",
      "Reward: -21.0\n",
      "Steps: 1057\n",
      "Avg loss: 0.01757\n",
      "Avg qvals: -1.61611\n",
      "===========================================\n",
      "Episode 446:\n",
      "Reward: -21.0\n",
      "Steps: 1043\n",
      "Avg loss: 0.01838\n",
      "Avg qvals: -1.71084\n",
      "===========================================\n",
      "Episode 447:\n",
      "Reward: -18.0\n",
      "Steps: 1615\n",
      "Avg loss: 0.01729\n",
      "Avg qvals: -1.46194\n",
      "===========================================\n",
      "Episode 448:\n",
      "Reward: -21.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01703\n",
      "Avg qvals: -1.57249\n",
      "===========================================\n",
      "Episode 449:\n",
      "Reward: -19.0\n",
      "Steps: 1234\n",
      "Avg loss: 0.01623\n",
      "Avg qvals: -1.50165\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 450:\n",
      "Reward: -17.0\n",
      "Steps: 1465\n",
      "Avg loss: 0.01810\n",
      "Avg qvals: -1.73804\n",
      "===========================================\n",
      "Episode 451:\n",
      "Reward: -21.0\n",
      "Steps: 1138\n",
      "Avg loss: 0.01700\n",
      "Avg qvals: -1.59022\n",
      "===========================================\n",
      "Episode 452:\n",
      "Reward: -21.0\n",
      "Steps: 1081\n",
      "Avg loss: 0.01743\n",
      "Avg qvals: -1.59094\n",
      "===========================================\n",
      "Episode 453:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01672\n",
      "Avg qvals: -1.54101\n",
      "===========================================\n",
      "Episode 454:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01708\n",
      "Avg qvals: -1.45215\n",
      "===========================================\n",
      "Episode 455:\n",
      "Reward: -20.0\n",
      "Steps: 1231\n",
      "Avg loss: 0.01759\n",
      "Avg qvals: -1.55444\n",
      "===========================================\n",
      "Episode 456:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.57964\n",
      "===========================================\n",
      "Episode 457:\n",
      "Reward: -20.0\n",
      "Steps: 1166\n",
      "Avg loss: 0.01637\n",
      "Avg qvals: -1.47380\n",
      "===========================================\n",
      "Episode 458:\n",
      "Reward: -21.0\n",
      "Steps: 1214\n",
      "Avg loss: 0.01703\n",
      "Avg qvals: -1.53017\n",
      "===========================================\n",
      "Episode 459:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01745\n",
      "Avg qvals: -1.62941\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 460:\n",
      "Reward: -20.0\n",
      "Steps: 1256\n",
      "Avg loss: 0.01750\n",
      "Avg qvals: -1.67131\n",
      "===========================================\n",
      "Episode 461:\n",
      "Reward: -20.0\n",
      "Steps: 1169\n",
      "Avg loss: 0.01832\n",
      "Avg qvals: -1.77991\n",
      "===========================================\n",
      "Episode 462:\n",
      "Reward: -20.0\n",
      "Steps: 1120\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.56561\n",
      "===========================================\n",
      "Episode 463:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01798\n",
      "Avg qvals: -1.61606\n",
      "===========================================\n",
      "Episode 464:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01753\n",
      "Avg qvals: -1.66451\n",
      "===========================================\n",
      "Episode 465:\n",
      "Reward: -21.0\n",
      "Steps: 1033\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.61416\n",
      "===========================================\n",
      "Episode 466:\n",
      "Reward: -20.0\n",
      "Steps: 1319\n",
      "Avg loss: 0.01736\n",
      "Avg qvals: -1.50708\n",
      "===========================================\n",
      "Episode 467:\n",
      "Reward: -21.0\n",
      "Steps: 1143\n",
      "Avg loss: 0.01845\n",
      "Avg qvals: -1.66779\n",
      "===========================================\n",
      "Episode 468:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01880\n",
      "Avg qvals: -1.74879\n",
      "===========================================\n",
      "Episode 469:\n",
      "Reward: -21.0\n",
      "Steps: 1178\n",
      "Avg loss: 0.01742\n",
      "Avg qvals: -1.50439\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 470:\n",
      "Reward: -20.0\n",
      "Steps: 1321\n",
      "Avg loss: 0.01672\n",
      "Avg qvals: -1.43004\n",
      "===========================================\n",
      "Episode 471:\n",
      "Reward: -20.0\n",
      "Steps: 1296\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.73794\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 472:\n",
      "Reward: -20.0\n",
      "Steps: 1225\n",
      "Avg loss: 0.01860\n",
      "Avg qvals: -1.62356\n",
      "===========================================\n",
      "Episode 473:\n",
      "Reward: -20.0\n",
      "Steps: 1200\n",
      "Avg loss: 0.01601\n",
      "Avg qvals: -1.42880\n",
      "===========================================\n",
      "Episode 474:\n",
      "Reward: -21.0\n",
      "Steps: 1181\n",
      "Avg loss: 0.01721\n",
      "Avg qvals: -1.55026\n",
      "===========================================\n",
      "Episode 475:\n",
      "Reward: -20.0\n",
      "Steps: 1163\n",
      "Avg loss: 0.01743\n",
      "Avg qvals: -1.55295\n",
      "===========================================\n",
      "Episode 476:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01860\n",
      "Avg qvals: -1.75678\n",
      "===========================================\n",
      "Episode 477:\n",
      "Reward: -20.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.57479\n",
      "===========================================\n",
      "Episode 478:\n",
      "Reward: -20.0\n",
      "Steps: 1332\n",
      "Avg loss: 0.01729\n",
      "Avg qvals: -1.65608\n",
      "===========================================\n",
      "Episode 479:\n",
      "Reward: -20.0\n",
      "Steps: 1279\n",
      "Avg loss: 0.01796\n",
      "Avg qvals: -1.75801\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 480:\n",
      "Reward: -21.0\n",
      "Steps: 1061\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.58509\n",
      "===========================================\n",
      "Episode 481:\n",
      "Reward: -21.0\n",
      "Steps: 1146\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.66157\n",
      "===========================================\n",
      "Episode 482:\n",
      "Reward: -20.0\n",
      "Steps: 1133\n",
      "Avg loss: 0.01697\n",
      "Avg qvals: -1.60994\n",
      "===========================================\n",
      "Episode 483:\n",
      "Reward: -20.0\n",
      "Steps: 1160\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.71887\n",
      "===========================================\n",
      "Episode 484:\n",
      "Reward: -20.0\n",
      "Steps: 1174\n",
      "Avg loss: 0.01785\n",
      "Avg qvals: -1.62560\n",
      "===========================================\n",
      "Episode 485:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01758\n",
      "Avg qvals: -1.56851\n",
      "===========================================\n",
      "Episode 486:\n",
      "Reward: -21.0\n",
      "Steps: 1139\n",
      "Avg loss: 0.01828\n",
      "Avg qvals: -1.63742\n",
      "===========================================\n",
      "Episode 487:\n",
      "Reward: -19.0\n",
      "Steps: 1406\n",
      "Avg loss: 0.01798\n",
      "Avg qvals: -1.73228\n",
      "===========================================\n",
      "Episode 488:\n",
      "Reward: -20.0\n",
      "Steps: 1218\n",
      "Avg loss: 0.01773\n",
      "Avg qvals: -1.66045\n",
      "===========================================\n",
      "Episode 489:\n",
      "Reward: -19.0\n",
      "Steps: 1540\n",
      "Avg loss: 0.01835\n",
      "Avg qvals: -1.73573\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 490:\n",
      "Reward: -20.0\n",
      "Steps: 1119\n",
      "Avg loss: 0.01645\n",
      "Avg qvals: -1.52554\n",
      "===========================================\n",
      "Episode 491:\n",
      "Reward: -21.0\n",
      "Steps: 1159\n",
      "Avg loss: 0.01805\n",
      "Avg qvals: -1.60504\n",
      "===========================================\n",
      "Episode 492:\n",
      "Reward: -20.0\n",
      "Steps: 1258\n",
      "Avg loss: 0.01705\n",
      "Avg qvals: -1.56343\n",
      "===========================================\n",
      "Episode 493:\n",
      "Reward: -20.0\n",
      "Steps: 1250\n",
      "Avg loss: 0.01791\n",
      "Avg qvals: -1.64148\n",
      "===========================================\n",
      "Episode 494:\n",
      "Reward: -20.0\n",
      "Steps: 1193\n",
      "Avg loss: 0.01809\n",
      "Avg qvals: -1.62500\n",
      "===========================================\n",
      "Episode 495:\n",
      "Reward: -21.0\n",
      "Steps: 1155\n",
      "Avg loss: 0.01783\n",
      "Avg qvals: -1.61864\n",
      "===========================================\n",
      "Episode 496:\n",
      "Reward: -19.0\n",
      "Steps: 1244\n",
      "Avg loss: 0.01885\n",
      "Avg qvals: -1.65145\n",
      "===========================================\n",
      "Episode 497:\n",
      "Reward: -20.0\n",
      "Steps: 1269\n",
      "Avg loss: 0.01655\n",
      "Avg qvals: -1.62449\n",
      "===========================================\n",
      "Episode 498:\n",
      "Reward: -21.0\n",
      "Steps: 1123\n",
      "Avg loss: 0.01657\n",
      "Avg qvals: -1.71395\n",
      "===========================================\n",
      "Episode 499:\n",
      "Reward: -21.0\n",
      "Steps: 1065\n",
      "Avg loss: 0.01820\n",
      "Avg qvals: -1.63497\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 500:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01766\n",
      "Avg qvals: -1.56850\n",
      "===========================================\n",
      "Episode 501:\n",
      "Reward: -20.0\n",
      "Steps: 1173\n",
      "Avg loss: 0.01759\n",
      "Avg qvals: -1.72259\n",
      "===========================================\n",
      "Episode 502:\n",
      "Reward: -21.0\n",
      "Steps: 1100\n",
      "Avg loss: 0.01775\n",
      "Avg qvals: -1.71134\n",
      "===========================================\n",
      "Episode 503:\n",
      "Reward: -21.0\n",
      "Steps: 1087\n",
      "Avg loss: 0.01694\n",
      "Avg qvals: -1.31724\n",
      "===========================================\n",
      "Episode 504:\n",
      "Reward: -21.0\n",
      "Steps: 1184\n",
      "Avg loss: 0.01904\n",
      "Avg qvals: -1.68088\n",
      "===========================================\n",
      "Episode 505:\n",
      "Reward: -20.0\n",
      "Steps: 1212\n",
      "Avg loss: 0.01765\n",
      "Avg qvals: -1.68186\n",
      "===========================================\n",
      "Episode 506:\n",
      "Reward: -20.0\n",
      "Steps: 1325\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.68235\n",
      "===========================================\n",
      "Episode 507:\n",
      "Reward: -19.0\n",
      "Steps: 1345\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.47187\n",
      "===========================================\n",
      "Episode 508:\n",
      "Reward: -21.0\n",
      "Steps: 1003\n",
      "Avg loss: 0.01665\n",
      "Avg qvals: -1.52294\n",
      "===========================================\n",
      "Episode 509:\n",
      "Reward: -20.0\n",
      "Steps: 1242\n",
      "Avg loss: 0.01751\n",
      "Avg qvals: -1.62475\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 510:\n",
      "Reward: -19.0\n",
      "Steps: 1229\n",
      "Avg loss: 0.01637\n",
      "Avg qvals: -1.61772\n",
      "===========================================\n",
      "Episode 511:\n",
      "Reward: -20.0\n",
      "Steps: 1192\n",
      "Avg loss: 0.01893\n",
      "Avg qvals: -1.78316\n",
      "===========================================\n",
      "Episode 512:\n",
      "Reward: -20.0\n",
      "Steps: 1176\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.81776\n",
      "===========================================\n",
      "Episode 513:\n",
      "Reward: -20.0\n",
      "Steps: 1238\n",
      "Avg loss: 0.01890\n",
      "Avg qvals: -1.69503\n",
      "===========================================\n",
      "Episode 514:\n",
      "Reward: -20.0\n",
      "Steps: 1146\n",
      "Avg loss: 0.01705\n",
      "Avg qvals: -1.49760\n",
      "===========================================\n",
      "Episode 515:\n",
      "Reward: -21.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.60516\n",
      "===========================================\n",
      "Episode 516:\n",
      "Reward: -19.0\n",
      "Steps: 1389\n",
      "Avg loss: 0.01658\n",
      "Avg qvals: -1.50685\n",
      "===========================================\n",
      "Episode 517:\n",
      "Reward: -21.0\n",
      "Steps: 1050\n",
      "Avg loss: 0.01623\n",
      "Avg qvals: -1.52377\n",
      "===========================================\n",
      "Episode 518:\n",
      "Reward: -20.0\n",
      "Steps: 1279\n",
      "Avg loss: 0.01747\n",
      "Avg qvals: -1.44397\n",
      "===========================================\n",
      "Episode 519:\n",
      "Reward: -20.0\n",
      "Steps: 1213\n",
      "Avg loss: 0.01765\n",
      "Avg qvals: -1.54114\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 520:\n",
      "Reward: -21.0\n",
      "Steps: 1093\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.65449\n",
      "===========================================\n",
      "Episode 521:\n",
      "Reward: -21.0\n",
      "Steps: 1106\n",
      "Avg loss: 0.01698\n",
      "Avg qvals: -1.69044\n",
      "===========================================\n",
      "Episode 522:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.64488\n",
      "===========================================\n",
      "Episode 523:\n",
      "Reward: -21.0\n",
      "Steps: 1284\n",
      "Avg loss: 0.01687\n",
      "Avg qvals: -1.54921\n",
      "===========================================\n",
      "Episode 524:\n",
      "Reward: -21.0\n",
      "Steps: 1061\n",
      "Avg loss: 0.01823\n",
      "Avg qvals: -1.70383\n",
      "===========================================\n",
      "Episode 525:\n",
      "Reward: -20.0\n",
      "Steps: 1155\n",
      "Avg loss: 0.01650\n",
      "Avg qvals: -1.58482\n",
      "===========================================\n",
      "Episode 526:\n",
      "Reward: -20.0\n",
      "Steps: 1205\n",
      "Avg loss: 0.01749\n",
      "Avg qvals: -1.64483\n",
      "===========================================\n",
      "Episode 527:\n",
      "Reward: -21.0\n",
      "Steps: 1105\n",
      "Avg loss: 0.01637\n",
      "Avg qvals: -1.47340\n",
      "===========================================\n",
      "Episode 528:\n",
      "Reward: -19.0\n",
      "Steps: 1272\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.51806\n",
      "===========================================\n",
      "Episode 529:\n",
      "Reward: -21.0\n",
      "Steps: 1114\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.62668\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 530:\n",
      "Reward: -21.0\n",
      "Steps: 1162\n",
      "Avg loss: 0.01759\n",
      "Avg qvals: -1.61937\n",
      "===========================================\n",
      "Episode 531:\n",
      "Reward: -20.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.01693\n",
      "Avg qvals: -1.71881\n",
      "===========================================\n",
      "Episode 532:\n",
      "Reward: -21.0\n",
      "Steps: 1065\n",
      "Avg loss: 0.01743\n",
      "Avg qvals: -1.56316\n",
      "===========================================\n",
      "Episode 533:\n",
      "Reward: -21.0\n",
      "Steps: 1164\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.56611\n",
      "===========================================\n",
      "Episode 534:\n",
      "Reward: -20.0\n",
      "Steps: 1118\n",
      "Avg loss: 0.01652\n",
      "Avg qvals: -1.42349\n",
      "===========================================\n",
      "Episode 535:\n",
      "Reward: -20.0\n",
      "Steps: 1269\n",
      "Avg loss: 0.01830\n",
      "Avg qvals: -1.80137\n",
      "===========================================\n",
      "Episode 536:\n",
      "Reward: -20.0\n",
      "Steps: 1231\n",
      "Avg loss: 0.01677\n",
      "Avg qvals: -1.47662\n",
      "===========================================\n",
      "Episode 537:\n",
      "Reward: -21.0\n",
      "Steps: 1154\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.66650\n",
      "===========================================\n",
      "Episode 538:\n",
      "Reward: -19.0\n",
      "Steps: 1276\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.68206\n",
      "===========================================\n",
      "Episode 539:\n",
      "Reward: -19.0\n",
      "Steps: 1292\n",
      "Avg loss: 0.01756\n",
      "Avg qvals: -1.54070\n",
      "===========================================\n",
      "Model saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 540:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01894\n",
      "Avg qvals: -1.86918\n",
      "===========================================\n",
      "Episode 541:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01713\n",
      "Avg qvals: -1.52135\n",
      "===========================================\n",
      "Episode 542:\n",
      "Reward: -20.0\n",
      "Steps: 1168\n",
      "Avg loss: 0.01746\n",
      "Avg qvals: -1.54582\n",
      "===========================================\n",
      "Episode 543:\n",
      "Reward: -21.0\n",
      "Steps: 1046\n",
      "Avg loss: 0.01703\n",
      "Avg qvals: -1.55187\n",
      "===========================================\n",
      "Episode 544:\n",
      "Reward: -21.0\n",
      "Steps: 1108\n",
      "Avg loss: 0.01688\n",
      "Avg qvals: -1.53449\n",
      "===========================================\n",
      "Episode 545:\n",
      "Reward: -20.0\n",
      "Steps: 1138\n",
      "Avg loss: 0.01676\n",
      "Avg qvals: -1.63531\n",
      "===========================================\n",
      "Episode 546:\n",
      "Reward: -20.0\n",
      "Steps: 1159\n",
      "Avg loss: 0.01721\n",
      "Avg qvals: -1.73066\n",
      "===========================================\n",
      "Episode 547:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01773\n",
      "Avg qvals: -1.63765\n",
      "===========================================\n",
      "Episode 548:\n",
      "Reward: -18.0\n",
      "Steps: 1513\n",
      "Avg loss: 0.01721\n",
      "Avg qvals: -1.51638\n",
      "===========================================\n",
      "Episode 549:\n",
      "Reward: -21.0\n",
      "Steps: 1174\n",
      "Avg loss: 0.01719\n",
      "Avg qvals: -1.56676\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 550:\n",
      "Reward: -20.0\n",
      "Steps: 1192\n",
      "Avg loss: 0.01594\n",
      "Avg qvals: -1.46168\n",
      "===========================================\n",
      "Episode 551:\n",
      "Reward: -20.0\n",
      "Steps: 1216\n",
      "Avg loss: 0.01863\n",
      "Avg qvals: -1.77602\n",
      "===========================================\n",
      "Episode 552:\n",
      "Reward: -20.0\n",
      "Steps: 1186\n",
      "Avg loss: 0.01813\n",
      "Avg qvals: -1.51727\n",
      "===========================================\n",
      "Episode 553:\n",
      "Reward: -20.0\n",
      "Steps: 1248\n",
      "Avg loss: 0.01658\n",
      "Avg qvals: -1.60282\n",
      "===========================================\n",
      "Episode 554:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.49277\n",
      "===========================================\n",
      "Episode 555:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01833\n",
      "Avg qvals: -1.84955\n",
      "===========================================\n",
      "Episode 556:\n",
      "Reward: -21.0\n",
      "Steps: 1058\n",
      "Avg loss: 0.01727\n",
      "Avg qvals: -1.49479\n",
      "===========================================\n",
      "Episode 557:\n",
      "Reward: -20.0\n",
      "Steps: 1205\n",
      "Avg loss: 0.01727\n",
      "Avg qvals: -1.64169\n",
      "===========================================\n",
      "Episode 558:\n",
      "Reward: -20.0\n",
      "Steps: 1189\n",
      "Avg loss: 0.01758\n",
      "Avg qvals: -1.79831\n",
      "===========================================\n",
      "Episode 559:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01781\n",
      "Avg qvals: -1.57367\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 560:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01906\n",
      "Avg qvals: -1.72674\n",
      "===========================================\n",
      "Episode 561:\n",
      "Reward: -21.0\n",
      "Steps: 1091\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.71467\n",
      "===========================================\n",
      "Episode 562:\n",
      "Reward: -18.0\n",
      "Steps: 1436\n",
      "Avg loss: 0.01842\n",
      "Avg qvals: -1.75181\n",
      "===========================================\n",
      "Episode 563:\n",
      "Reward: -20.0\n",
      "Steps: 1230\n",
      "Avg loss: 0.01663\n",
      "Avg qvals: -1.50948\n",
      "===========================================\n",
      "Episode 564:\n",
      "Reward: -20.0\n",
      "Steps: 1279\n",
      "Avg loss: 0.01606\n",
      "Avg qvals: -1.40318\n",
      "===========================================\n",
      "Episode 565:\n",
      "Reward: -20.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01731\n",
      "Avg qvals: -1.51482\n",
      "===========================================\n",
      "Episode 566:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01786\n",
      "Avg qvals: -1.70129\n",
      "===========================================\n",
      "Episode 567:\n",
      "Reward: -21.0\n",
      "Steps: 1175\n",
      "Avg loss: 0.01752\n",
      "Avg qvals: -1.34085\n",
      "===========================================\n",
      "Episode 568:\n",
      "Reward: -21.0\n",
      "Steps: 1046\n",
      "Avg loss: 0.01678\n",
      "Avg qvals: -1.53198\n",
      "===========================================\n",
      "Episode 569:\n",
      "Reward: -21.0\n",
      "Steps: 1037\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.59752\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 570:\n",
      "Reward: -21.0\n",
      "Steps: 1098\n",
      "Avg loss: 0.01679\n",
      "Avg qvals: -1.54563\n",
      "===========================================\n",
      "Episode 571:\n",
      "Reward: -21.0\n",
      "Steps: 1053\n",
      "Avg loss: 0.01810\n",
      "Avg qvals: -1.54739\n",
      "===========================================\n",
      "Episode 572:\n",
      "Reward: -21.0\n",
      "Steps: 1091\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.59316\n",
      "===========================================\n",
      "Episode 573:\n",
      "Reward: -20.0\n",
      "Steps: 1122\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.59701\n",
      "===========================================\n",
      "Episode 574:\n",
      "Reward: -21.0\n",
      "Steps: 1089\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.59611\n",
      "===========================================\n",
      "Episode 575:\n",
      "Reward: -21.0\n",
      "Steps: 1125\n",
      "Avg loss: 0.01684\n",
      "Avg qvals: -1.47143\n",
      "===========================================\n",
      "Episode 576:\n",
      "Reward: -21.0\n",
      "Steps: 1120\n",
      "Avg loss: 0.01885\n",
      "Avg qvals: -1.64692\n",
      "===========================================\n",
      "Episode 577:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01756\n",
      "Avg qvals: -1.58032\n",
      "===========================================\n",
      "Episode 578:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.67334\n",
      "===========================================\n",
      "Episode 579:\n",
      "Reward: -21.0\n",
      "Steps: 1104\n",
      "Avg loss: 0.01753\n",
      "Avg qvals: -1.55332\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 580:\n",
      "Reward: -21.0\n",
      "Steps: 1114\n",
      "Avg loss: 0.01741\n",
      "Avg qvals: -1.61899\n",
      "===========================================\n",
      "Episode 581:\n",
      "Reward: -19.0\n",
      "Steps: 1232\n",
      "Avg loss: 0.01872\n",
      "Avg qvals: -1.61157\n",
      "===========================================\n",
      "Episode 582:\n",
      "Reward: -20.0\n",
      "Steps: 1155\n",
      "Avg loss: 0.01852\n",
      "Avg qvals: -1.53957\n",
      "===========================================\n",
      "Episode 583:\n",
      "Reward: -21.0\n",
      "Steps: 1305\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.62691\n",
      "===========================================\n",
      "Episode 584:\n",
      "Reward: -21.0\n",
      "Steps: 1085\n",
      "Avg loss: 0.01715\n",
      "Avg qvals: -1.55598\n",
      "===========================================\n",
      "Episode 585:\n",
      "Reward: -20.0\n",
      "Steps: 1133\n",
      "Avg loss: 0.01677\n",
      "Avg qvals: -1.47332\n",
      "===========================================\n",
      "Episode 586:\n",
      "Reward: -20.0\n",
      "Steps: 1142\n",
      "Avg loss: 0.01742\n",
      "Avg qvals: -1.53696\n",
      "===========================================\n",
      "Episode 587:\n",
      "Reward: -21.0\n",
      "Steps: 1098\n",
      "Avg loss: 0.01716\n",
      "Avg qvals: -1.54065\n",
      "===========================================\n",
      "Episode 588:\n",
      "Reward: -19.0\n",
      "Steps: 1333\n",
      "Avg loss: 0.01840\n",
      "Avg qvals: -1.71111\n",
      "===========================================\n",
      "Episode 589:\n",
      "Reward: -21.0\n",
      "Steps: 997\n",
      "Avg loss: 0.01602\n",
      "Avg qvals: -1.41891\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 590:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01812\n",
      "Avg qvals: -1.63243\n",
      "===========================================\n",
      "Episode 591:\n",
      "Reward: -20.0\n",
      "Steps: 1412\n",
      "Avg loss: 0.01804\n",
      "Avg qvals: -1.70072\n",
      "===========================================\n",
      "Episode 592:\n",
      "Reward: -20.0\n",
      "Steps: 1131\n",
      "Avg loss: 0.01725\n",
      "Avg qvals: -1.70397\n",
      "===========================================\n",
      "Episode 593:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.47792\n",
      "===========================================\n",
      "Episode 594:\n",
      "Reward: -21.0\n",
      "Steps: 1095\n",
      "Avg loss: 0.01772\n",
      "Avg qvals: -1.55696\n",
      "===========================================\n",
      "Episode 595:\n",
      "Reward: -19.0\n",
      "Steps: 1271\n",
      "Avg loss: 0.01779\n",
      "Avg qvals: -1.56066\n",
      "===========================================\n",
      "Episode 596:\n",
      "Reward: -18.0\n",
      "Steps: 1479\n",
      "Avg loss: 0.01761\n",
      "Avg qvals: -1.54785\n",
      "===========================================\n",
      "Episode 597:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01696\n",
      "Avg qvals: -1.67746\n",
      "===========================================\n",
      "Episode 598:\n",
      "Reward: -20.0\n",
      "Steps: 1248\n",
      "Avg loss: 0.01710\n",
      "Avg qvals: -1.39196\n",
      "===========================================\n",
      "Episode 599:\n",
      "Reward: -20.0\n",
      "Steps: 1174\n",
      "Avg loss: 0.01603\n",
      "Avg qvals: -1.53730\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 600:\n",
      "Reward: -20.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01678\n",
      "Avg qvals: -1.49096\n",
      "===========================================\n",
      "Episode 601:\n",
      "Reward: -21.0\n",
      "Steps: 1130\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.72581\n",
      "===========================================\n",
      "Episode 602:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01739\n",
      "Avg qvals: -1.72564\n",
      "===========================================\n",
      "Episode 603:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01753\n",
      "Avg qvals: -1.39197\n",
      "===========================================\n",
      "Episode 604:\n",
      "Reward: -19.0\n",
      "Steps: 1342\n",
      "Avg loss: 0.01796\n",
      "Avg qvals: -1.65770\n",
      "===========================================\n",
      "Episode 605:\n",
      "Reward: -20.0\n",
      "Steps: 1161\n",
      "Avg loss: 0.01661\n",
      "Avg qvals: -1.51806\n",
      "===========================================\n",
      "Episode 606:\n",
      "Reward: -20.0\n",
      "Steps: 1231\n",
      "Avg loss: 0.01834\n",
      "Avg qvals: -1.74579\n",
      "===========================================\n",
      "Episode 607:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01824\n",
      "Avg qvals: -1.65748\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 608:\n",
      "Reward: -20.0\n",
      "Steps: 1211\n",
      "Avg loss: 0.01740\n",
      "Avg qvals: -1.55346\n",
      "===========================================\n",
      "Episode 609:\n",
      "Reward: -21.0\n",
      "Steps: 1072\n",
      "Avg loss: 0.01711\n",
      "Avg qvals: -1.65059\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 610:\n",
      "Reward: -21.0\n",
      "Steps: 1169\n",
      "Avg loss: 0.01666\n",
      "Avg qvals: -1.53726\n",
      "===========================================\n",
      "Episode 611:\n",
      "Reward: -21.0\n",
      "Steps: 1106\n",
      "Avg loss: 0.01728\n",
      "Avg qvals: -1.54913\n",
      "===========================================\n",
      "Episode 612:\n",
      "Reward: -20.0\n",
      "Steps: 1167\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -1.53392\n",
      "===========================================\n",
      "Episode 613:\n",
      "Reward: -20.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01897\n",
      "Avg qvals: -1.71038\n",
      "===========================================\n",
      "Episode 614:\n",
      "Reward: -20.0\n",
      "Steps: 1133\n",
      "Avg loss: 0.01897\n",
      "Avg qvals: -1.69055\n",
      "===========================================\n",
      "Episode 615:\n",
      "Reward: -20.0\n",
      "Steps: 1165\n",
      "Avg loss: 0.01703\n",
      "Avg qvals: -1.49065\n",
      "===========================================\n",
      "Episode 616:\n",
      "Reward: -21.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01708\n",
      "Avg qvals: -1.57371\n",
      "===========================================\n",
      "Episode 617:\n",
      "Reward: -20.0\n",
      "Steps: 1117\n",
      "Avg loss: 0.01689\n",
      "Avg qvals: -1.65468\n",
      "===========================================\n",
      "Episode 618:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01687\n",
      "Avg qvals: -1.56187\n",
      "===========================================\n",
      "Episode 619:\n",
      "Reward: -21.0\n",
      "Steps: 1062\n",
      "Avg loss: 0.01838\n",
      "Avg qvals: -1.64035\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 620:\n",
      "Reward: -19.0\n",
      "Steps: 1410\n",
      "Avg loss: 0.01767\n",
      "Avg qvals: -1.76822\n",
      "===========================================\n",
      "Episode 621:\n",
      "Reward: -21.0\n",
      "Steps: 1086\n",
      "Avg loss: 0.01603\n",
      "Avg qvals: -1.42714\n",
      "===========================================\n",
      "Episode 622:\n",
      "Reward: -21.0\n",
      "Steps: 1101\n",
      "Avg loss: 0.01721\n",
      "Avg qvals: -1.59494\n",
      "===========================================\n",
      "Episode 623:\n",
      "Reward: -20.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01710\n",
      "Avg qvals: -1.60289\n",
      "===========================================\n",
      "Episode 624:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01715\n",
      "Avg qvals: -1.56464\n",
      "===========================================\n",
      "Episode 625:\n",
      "Reward: -21.0\n",
      "Steps: 1072\n",
      "Avg loss: 0.01846\n",
      "Avg qvals: -1.80665\n",
      "===========================================\n",
      "Episode 626:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.57162\n",
      "===========================================\n",
      "Episode 627:\n",
      "Reward: -19.0\n",
      "Steps: 1251\n",
      "Avg loss: 0.01845\n",
      "Avg qvals: -1.64196\n",
      "===========================================\n",
      "Episode 628:\n",
      "Reward: -20.0\n",
      "Steps: 1170\n",
      "Avg loss: 0.01751\n",
      "Avg qvals: -1.71261\n",
      "===========================================\n",
      "Episode 629:\n",
      "Reward: -20.0\n",
      "Steps: 1171\n",
      "Avg loss: 0.01852\n",
      "Avg qvals: -1.75835\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 630:\n",
      "Reward: -21.0\n",
      "Steps: 1102\n",
      "Avg loss: 0.01807\n",
      "Avg qvals: -1.60749\n",
      "===========================================\n",
      "Episode 631:\n",
      "Reward: -19.0\n",
      "Steps: 1516\n",
      "Avg loss: 0.01664\n",
      "Avg qvals: -1.56126\n",
      "===========================================\n",
      "Episode 632:\n",
      "Reward: -20.0\n",
      "Steps: 1209\n",
      "Avg loss: 0.01766\n",
      "Avg qvals: -1.58876\n",
      "===========================================\n",
      "Episode 633:\n",
      "Reward: -21.0\n",
      "Steps: 1105\n",
      "Avg loss: 0.01736\n",
      "Avg qvals: -1.64811\n",
      "===========================================\n",
      "Episode 634:\n",
      "Reward: -20.0\n",
      "Steps: 1234\n",
      "Avg loss: 0.01662\n",
      "Avg qvals: -1.61789\n",
      "===========================================\n",
      "Episode 635:\n",
      "Reward: -21.0\n",
      "Steps: 1062\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.50047\n",
      "===========================================\n",
      "Episode 636:\n",
      "Reward: -19.0\n",
      "Steps: 1363\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.52040\n",
      "===========================================\n",
      "Episode 637:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01728\n",
      "Avg qvals: -1.48237\n",
      "===========================================\n",
      "Episode 638:\n",
      "Reward: -19.0\n",
      "Steps: 1323\n",
      "Avg loss: 0.01743\n",
      "Avg qvals: -1.51511\n",
      "===========================================\n",
      "Episode 639:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01804\n",
      "Avg qvals: -1.63991\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 640:\n",
      "Reward: -20.0\n",
      "Steps: 1118\n",
      "Avg loss: 0.01836\n",
      "Avg qvals: -1.81023\n",
      "===========================================\n",
      "Episode 641:\n",
      "Reward: -18.0\n",
      "Steps: 1444\n",
      "Avg loss: 0.01696\n",
      "Avg qvals: -1.54143\n",
      "===========================================\n",
      "Episode 642:\n",
      "Reward: -21.0\n",
      "Steps: 1103\n",
      "Avg loss: 0.01635\n",
      "Avg qvals: -1.44048\n",
      "===========================================\n",
      "Episode 643:\n",
      "Reward: -20.0\n",
      "Steps: 1192\n",
      "Avg loss: 0.01852\n",
      "Avg qvals: -1.68590\n",
      "===========================================\n",
      "Episode 644:\n",
      "Reward: -20.0\n",
      "Steps: 1153\n",
      "Avg loss: 0.01911\n",
      "Avg qvals: -1.71944\n",
      "===========================================\n",
      "Episode 645:\n",
      "Reward: -20.0\n",
      "Steps: 1192\n",
      "Avg loss: 0.01672\n",
      "Avg qvals: -1.62079\n",
      "===========================================\n",
      "Episode 646:\n",
      "Reward: -20.0\n",
      "Steps: 1209\n",
      "Avg loss: 0.01730\n",
      "Avg qvals: -1.79436\n",
      "===========================================\n",
      "Episode 647:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.48593\n",
      "===========================================\n",
      "Episode 648:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01701\n",
      "Avg qvals: -1.51037\n",
      "===========================================\n",
      "Episode 649:\n",
      "Reward: -21.0\n",
      "Steps: 1099\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.59661\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 650:\n",
      "Reward: -21.0\n",
      "Steps: 1055\n",
      "Avg loss: 0.01860\n",
      "Avg qvals: -1.71670\n",
      "===========================================\n",
      "Episode 651:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01732\n",
      "Avg qvals: -1.70478\n",
      "===========================================\n",
      "Episode 652:\n",
      "Reward: -20.0\n",
      "Steps: 1182\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.56864\n",
      "===========================================\n",
      "Episode 653:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.69307\n",
      "===========================================\n",
      "Episode 654:\n",
      "Reward: -21.0\n",
      "Steps: 1052\n",
      "Avg loss: 0.01700\n",
      "Avg qvals: -1.72019\n",
      "===========================================\n",
      "Episode 655:\n",
      "Reward: -21.0\n",
      "Steps: 1138\n",
      "Avg loss: 0.01748\n",
      "Avg qvals: -1.60314\n",
      "===========================================\n",
      "Episode 656:\n",
      "Reward: -21.0\n",
      "Steps: 1144\n",
      "Avg loss: 0.01757\n",
      "Avg qvals: -1.68014\n",
      "===========================================\n",
      "Episode 657:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.52571\n",
      "===========================================\n",
      "Episode 658:\n",
      "Reward: -21.0\n",
      "Steps: 1135\n",
      "Avg loss: 0.01837\n",
      "Avg qvals: -1.83621\n",
      "===========================================\n",
      "Episode 659:\n",
      "Reward: -19.0\n",
      "Steps: 1237\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.51352\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 660:\n",
      "Reward: -21.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01866\n",
      "Avg qvals: -1.61127\n",
      "===========================================\n",
      "Episode 661:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01690\n",
      "Avg qvals: -1.53208\n",
      "===========================================\n",
      "Episode 662:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01572\n",
      "Avg qvals: -1.35687\n",
      "===========================================\n",
      "Episode 663:\n",
      "Reward: -21.0\n",
      "Steps: 1069\n",
      "Avg loss: 0.01810\n",
      "Avg qvals: -1.70889\n",
      "===========================================\n",
      "Episode 664:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01646\n",
      "Avg qvals: -1.40336\n",
      "===========================================\n",
      "Episode 665:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01875\n",
      "Avg qvals: -1.82531\n",
      "===========================================\n",
      "Episode 666:\n",
      "Reward: -18.0\n",
      "Steps: 1323\n",
      "Avg loss: 0.01719\n",
      "Avg qvals: -1.68190\n",
      "===========================================\n",
      "Episode 667:\n",
      "Reward: -20.0\n",
      "Steps: 1109\n",
      "Avg loss: 0.01842\n",
      "Avg qvals: -1.56570\n",
      "===========================================\n",
      "Episode 668:\n",
      "Reward: -21.0\n",
      "Steps: 1067\n",
      "Avg loss: 0.01838\n",
      "Avg qvals: -1.70287\n",
      "===========================================\n",
      "Episode 669:\n",
      "Reward: -21.0\n",
      "Steps: 1085\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.42782\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 670:\n",
      "Reward: -21.0\n",
      "Steps: 1180\n",
      "Avg loss: 0.01755\n",
      "Avg qvals: -1.56953\n",
      "===========================================\n",
      "Episode 671:\n",
      "Reward: -21.0\n",
      "Steps: 1141\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.59204\n",
      "===========================================\n",
      "Episode 672:\n",
      "Reward: -20.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.01759\n",
      "Avg qvals: -1.60141\n",
      "===========================================\n",
      "Episode 673:\n",
      "Reward: -21.0\n",
      "Steps: 1050\n",
      "Avg loss: 0.01673\n",
      "Avg qvals: -1.54583\n",
      "===========================================\n",
      "Episode 674:\n",
      "Reward: -20.0\n",
      "Steps: 1238\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.62901\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 675:\n",
      "Reward: -21.0\n",
      "Steps: 1070\n",
      "Avg loss: 0.01798\n",
      "Avg qvals: -1.47466\n",
      "===========================================\n",
      "Episode 676:\n",
      "Reward: -21.0\n",
      "Steps: 1201\n",
      "Avg loss: 0.01786\n",
      "Avg qvals: -1.44616\n",
      "===========================================\n",
      "Episode 677:\n",
      "Reward: -20.0\n",
      "Steps: 1161\n",
      "Avg loss: 0.01703\n",
      "Avg qvals: -1.40467\n",
      "===========================================\n",
      "Episode 678:\n",
      "Reward: -20.0\n",
      "Steps: 1201\n",
      "Avg loss: 0.01719\n",
      "Avg qvals: -1.49762\n",
      "===========================================\n",
      "Episode 679:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01848\n",
      "Avg qvals: -1.54907\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 680:\n",
      "Reward: -21.0\n",
      "Steps: 1072\n",
      "Avg loss: 0.01615\n",
      "Avg qvals: -1.46126\n",
      "===========================================\n",
      "Episode 681:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.78459\n",
      "===========================================\n",
      "Episode 682:\n",
      "Reward: -20.0\n",
      "Steps: 1273\n",
      "Avg loss: 0.01855\n",
      "Avg qvals: -1.71539\n",
      "===========================================\n",
      "Episode 683:\n",
      "Reward: -19.0\n",
      "Steps: 1428\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.72647\n",
      "===========================================\n",
      "Episode 684:\n",
      "Reward: -20.0\n",
      "Steps: 1120\n",
      "Avg loss: 0.01831\n",
      "Avg qvals: -1.90290\n",
      "===========================================\n",
      "Episode 685:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.53448\n",
      "===========================================\n",
      "Episode 686:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.55146\n",
      "===========================================\n",
      "Episode 687:\n",
      "Reward: -19.0\n",
      "Steps: 1488\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.58125\n",
      "===========================================\n",
      "Episode 688:\n",
      "Reward: -21.0\n",
      "Steps: 1138\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.58008\n",
      "===========================================\n",
      "Episode 689:\n",
      "Reward: -21.0\n",
      "Steps: 1103\n",
      "Avg loss: 0.01662\n",
      "Avg qvals: -1.56844\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 690:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01639\n",
      "Avg qvals: -1.34651\n",
      "===========================================\n",
      "Episode 691:\n",
      "Reward: -20.0\n",
      "Steps: 1194\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.67552\n",
      "===========================================\n",
      "Episode 692:\n",
      "Reward: -17.0\n",
      "Steps: 1485\n",
      "Avg loss: 0.01641\n",
      "Avg qvals: -1.43241\n",
      "===========================================\n",
      "Episode 693:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01830\n",
      "Avg qvals: -1.66729\n",
      "===========================================\n",
      "Episode 694:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01791\n",
      "Avg qvals: -1.75213\n",
      "===========================================\n",
      "Episode 695:\n",
      "Reward: -19.0\n",
      "Steps: 1322\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.51361\n",
      "===========================================\n",
      "Episode 696:\n",
      "Reward: -19.0\n",
      "Steps: 1265\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.56711\n",
      "===========================================\n",
      "Episode 697:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01636\n",
      "Avg qvals: -1.43775\n",
      "===========================================\n",
      "Episode 698:\n",
      "Reward: -20.0\n",
      "Steps: 1120\n",
      "Avg loss: 0.01695\n",
      "Avg qvals: -1.44776\n",
      "===========================================\n",
      "Episode 699:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01781\n",
      "Avg qvals: -1.57102\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 700:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01815\n",
      "Avg qvals: -1.62100\n",
      "===========================================\n",
      "Episode 701:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.57360\n",
      "===========================================\n",
      "Episode 702:\n",
      "Reward: -21.0\n",
      "Steps: 1162\n",
      "Avg loss: 0.01757\n",
      "Avg qvals: -1.75193\n",
      "===========================================\n",
      "Episode 703:\n",
      "Reward: -20.0\n",
      "Steps: 1184\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.54975\n",
      "===========================================\n",
      "Episode 704:\n",
      "Reward: -21.0\n",
      "Steps: 1057\n",
      "Avg loss: 0.01849\n",
      "Avg qvals: -1.62861\n",
      "===========================================\n",
      "Episode 705:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.59451\n",
      "===========================================\n",
      "Episode 706:\n",
      "Reward: -21.0\n",
      "Steps: 1084\n",
      "Avg loss: 0.01703\n",
      "Avg qvals: -1.56381\n",
      "===========================================\n",
      "Episode 707:\n",
      "Reward: -21.0\n",
      "Steps: 1175\n",
      "Avg loss: 0.01651\n",
      "Avg qvals: -1.50910\n",
      "===========================================\n",
      "Episode 708:\n",
      "Reward: -20.0\n",
      "Steps: 1157\n",
      "Avg loss: 0.01953\n",
      "Avg qvals: -1.93685\n",
      "===========================================\n",
      "Episode 709:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01882\n",
      "Avg qvals: -1.73739\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 710:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01869\n",
      "Avg qvals: -1.69930\n",
      "===========================================\n",
      "Episode 711:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01629\n",
      "Avg qvals: -1.41769\n",
      "===========================================\n",
      "Episode 712:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01824\n",
      "Avg qvals: -1.56422\n",
      "===========================================\n",
      "Episode 713:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01715\n",
      "Avg qvals: -1.66850\n",
      "===========================================\n",
      "Episode 714:\n",
      "Reward: -21.0\n",
      "Steps: 1032\n",
      "Avg loss: 0.01672\n",
      "Avg qvals: -1.46511\n",
      "===========================================\n",
      "Episode 715:\n",
      "Reward: -21.0\n",
      "Steps: 1003\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -1.45634\n",
      "===========================================\n",
      "Episode 716:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01833\n",
      "Avg qvals: -1.65413\n",
      "===========================================\n",
      "Episode 717:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01714\n",
      "Avg qvals: -1.47346\n",
      "===========================================\n",
      "Episode 718:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01843\n",
      "Avg qvals: -1.65360\n",
      "===========================================\n",
      "Episode 719:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01776\n",
      "Avg qvals: -1.57766\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 720:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01765\n",
      "Avg qvals: -1.43060\n",
      "===========================================\n",
      "Episode 721:\n",
      "Reward: -21.0\n",
      "Steps: 1006\n",
      "Avg loss: 0.01688\n",
      "Avg qvals: -1.55422\n",
      "===========================================\n",
      "Episode 722:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.59793\n",
      "===========================================\n",
      "Episode 723:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01678\n",
      "Avg qvals: -1.58763\n",
      "===========================================\n",
      "Episode 724:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.55570\n",
      "===========================================\n",
      "Episode 725:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.47235\n",
      "===========================================\n",
      "Episode 726:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01643\n",
      "Avg qvals: -1.58522\n",
      "===========================================\n",
      "Episode 727:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.60935\n",
      "===========================================\n",
      "Episode 728:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01724\n",
      "Avg qvals: -1.44824\n",
      "===========================================\n",
      "Episode 729:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01762\n",
      "Avg qvals: -1.78309\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 730:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01809\n",
      "Avg qvals: -1.56241\n",
      "===========================================\n",
      "Episode 731:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.64196\n",
      "===========================================\n",
      "Episode 732:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01726\n",
      "Avg qvals: -1.66709\n",
      "===========================================\n",
      "Episode 733:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01758\n",
      "Avg qvals: -1.56359\n",
      "===========================================\n",
      "Episode 734:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.77985\n",
      "===========================================\n",
      "Episode 735:\n",
      "Reward: -21.0\n",
      "Steps: 1035\n",
      "Avg loss: 0.01800\n",
      "Avg qvals: -1.61950\n",
      "===========================================\n",
      "Episode 736:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01717\n",
      "Avg qvals: -1.50992\n",
      "===========================================\n",
      "Episode 737:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01601\n",
      "Avg qvals: -1.39756\n",
      "===========================================\n",
      "Episode 738:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01651\n",
      "Avg qvals: -1.45542\n",
      "===========================================\n",
      "Episode 739:\n",
      "Reward: -21.0\n",
      "Steps: 1032\n",
      "Avg loss: 0.01868\n",
      "Avg qvals: -1.72607\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 740:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.55114\n",
      "===========================================\n",
      "Episode 741:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01754\n",
      "Avg qvals: -1.47396\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 742:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01616\n",
      "Avg qvals: -1.59388\n",
      "===========================================\n",
      "Episode 743:\n",
      "Reward: -21.0\n",
      "Steps: 1006\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.71668\n",
      "===========================================\n",
      "Episode 744:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01855\n",
      "Avg qvals: -1.70285\n",
      "===========================================\n",
      "Episode 745:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01739\n",
      "Avg qvals: -1.61068\n",
      "===========================================\n",
      "Episode 746:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01808\n",
      "Avg qvals: -1.72059\n",
      "===========================================\n",
      "Episode 747:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01651\n",
      "Avg qvals: -1.47273\n",
      "===========================================\n",
      "Episode 748:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01678\n",
      "Avg qvals: -1.42543\n",
      "===========================================\n",
      "Episode 749:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01659\n",
      "Avg qvals: -1.63931\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 750:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01875\n",
      "Avg qvals: -1.54414\n",
      "===========================================\n",
      "Episode 751:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01814\n",
      "Avg qvals: -1.54810\n",
      "===========================================\n",
      "Episode 752:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01806\n",
      "Avg qvals: -1.52662\n",
      "===========================================\n",
      "Episode 753:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01698\n",
      "Avg qvals: -1.65775\n",
      "===========================================\n",
      "Episode 754:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01614\n",
      "Avg qvals: -1.56811\n",
      "===========================================\n",
      "Episode 755:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01866\n",
      "Avg qvals: -1.63715\n",
      "===========================================\n",
      "Episode 756:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01815\n",
      "Avg qvals: -1.57950\n",
      "===========================================\n",
      "Episode 757:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01807\n",
      "Avg qvals: -1.51850\n",
      "===========================================\n",
      "Episode 758:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01699\n",
      "Avg qvals: -1.73473\n",
      "===========================================\n",
      "Episode 759:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01778\n",
      "Avg qvals: -1.52352\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 760:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.57220\n",
      "===========================================\n",
      "Episode 761:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01857\n",
      "Avg qvals: -1.65770\n",
      "===========================================\n",
      "Episode 762:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.42444\n",
      "===========================================\n",
      "Episode 763:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01637\n",
      "Avg qvals: -1.55737\n",
      "===========================================\n",
      "Episode 764:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01859\n",
      "Avg qvals: -1.57118\n",
      "===========================================\n",
      "Episode 765:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01820\n",
      "Avg qvals: -1.62978\n",
      "===========================================\n",
      "Episode 766:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01932\n",
      "Avg qvals: -1.58261\n",
      "===========================================\n",
      "Episode 767:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01876\n",
      "Avg qvals: -1.76593\n",
      "===========================================\n",
      "Episode 768:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01797\n",
      "Avg qvals: -1.73270\n",
      "===========================================\n",
      "Episode 769:\n",
      "Reward: -21.0\n",
      "Steps: 1091\n",
      "Avg loss: 0.01687\n",
      "Avg qvals: -1.55610\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 770:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01722\n",
      "Avg qvals: -1.50648\n",
      "===========================================\n",
      "Episode 771:\n",
      "Reward: -21.0\n",
      "Steps: 1066\n",
      "Avg loss: 0.01870\n",
      "Avg qvals: -1.83320\n",
      "===========================================\n",
      "Episode 772:\n",
      "Reward: -19.0\n",
      "Steps: 1317\n",
      "Avg loss: 0.01732\n",
      "Avg qvals: -1.59566\n",
      "===========================================\n",
      "Episode 773:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01690\n",
      "Avg qvals: -1.64027\n",
      "===========================================\n",
      "Episode 774:\n",
      "Reward: -20.0\n",
      "Steps: 1168\n",
      "Avg loss: 0.01869\n",
      "Avg qvals: -1.80724\n",
      "===========================================\n",
      "Episode 775:\n",
      "Reward: -20.0\n",
      "Steps: 1162\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.47959\n",
      "===========================================\n",
      "Episode 776:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01770\n",
      "Avg qvals: -1.50635\n",
      "===========================================\n",
      "Episode 777:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.67890\n",
      "===========================================\n",
      "Episode 778:\n",
      "Reward: -20.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.75879\n",
      "===========================================\n",
      "Episode 779:\n",
      "Reward: -21.0\n",
      "Steps: 1108\n",
      "Avg loss: 0.01689\n",
      "Avg qvals: -1.58117\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 780:\n",
      "Reward: -19.0\n",
      "Steps: 1249\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.51706\n",
      "===========================================\n",
      "Episode 781:\n",
      "Reward: -20.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01781\n",
      "Avg qvals: -1.75386\n",
      "===========================================\n",
      "Episode 782:\n",
      "Reward: -19.0\n",
      "Steps: 1231\n",
      "Avg loss: 0.01836\n",
      "Avg qvals: -1.68253\n",
      "===========================================\n",
      "Episode 783:\n",
      "Reward: -20.0\n",
      "Steps: 1167\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.78861\n",
      "===========================================\n",
      "Episode 784:\n",
      "Reward: -21.0\n",
      "Steps: 1142\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.79296\n",
      "===========================================\n",
      "Episode 785:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.69479\n",
      "===========================================\n",
      "Episode 786:\n",
      "Reward: -20.0\n",
      "Steps: 1222\n",
      "Avg loss: 0.01778\n",
      "Avg qvals: -1.59369\n",
      "===========================================\n",
      "Episode 787:\n",
      "Reward: -21.0\n",
      "Steps: 1047\n",
      "Avg loss: 0.01754\n",
      "Avg qvals: -1.56584\n",
      "===========================================\n",
      "Episode 788:\n",
      "Reward: -21.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.52781\n",
      "===========================================\n",
      "Episode 789:\n",
      "Reward: -21.0\n",
      "Steps: 1037\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.68818\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 790:\n",
      "Reward: -21.0\n",
      "Steps: 1109\n",
      "Avg loss: 0.01679\n",
      "Avg qvals: -1.51920\n",
      "===========================================\n",
      "Episode 791:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01849\n",
      "Avg qvals: -1.60761\n",
      "===========================================\n",
      "Episode 792:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01735\n",
      "Avg qvals: -1.71702\n",
      "===========================================\n",
      "Episode 793:\n",
      "Reward: -20.0\n",
      "Steps: 1197\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.59394\n",
      "===========================================\n",
      "Episode 794:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01791\n",
      "Avg qvals: -1.69394\n",
      "===========================================\n",
      "Episode 795:\n",
      "Reward: -20.0\n",
      "Steps: 1142\n",
      "Avg loss: 0.01669\n",
      "Avg qvals: -1.48356\n",
      "===========================================\n",
      "Episode 796:\n",
      "Reward: -20.0\n",
      "Steps: 1131\n",
      "Avg loss: 0.01800\n",
      "Avg qvals: -1.53585\n",
      "===========================================\n",
      "Episode 797:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.68372\n",
      "===========================================\n",
      "Episode 798:\n",
      "Reward: -21.0\n",
      "Steps: 1160\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.85626\n",
      "===========================================\n",
      "Episode 799:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01746\n",
      "Avg qvals: -1.63511\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 800:\n",
      "Reward: -21.0\n",
      "Steps: 1041\n",
      "Avg loss: 0.01831\n",
      "Avg qvals: -1.64481\n",
      "===========================================\n",
      "Episode 801:\n",
      "Reward: -21.0\n",
      "Steps: 1034\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.54933\n",
      "===========================================\n",
      "Episode 802:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.71445\n",
      "===========================================\n",
      "Episode 803:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01736\n",
      "Avg qvals: -1.53096\n",
      "===========================================\n",
      "Episode 804:\n",
      "Reward: -21.0\n",
      "Steps: 1173\n",
      "Avg loss: 0.01785\n",
      "Avg qvals: -1.67745\n",
      "===========================================\n",
      "Episode 805:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01890\n",
      "Avg qvals: -1.76004\n",
      "===========================================\n",
      "Episode 806:\n",
      "Reward: -21.0\n",
      "Steps: 1090\n",
      "Avg loss: 0.01853\n",
      "Avg qvals: -1.68712\n",
      "===========================================\n",
      "Episode 807:\n",
      "Reward: -20.0\n",
      "Steps: 1150\n",
      "Avg loss: 0.01825\n",
      "Avg qvals: -1.83341\n",
      "===========================================\n",
      "Episode 808:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01823\n",
      "Avg qvals: -1.58355\n",
      "===========================================\n",
      "Episode 809:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01840\n",
      "Avg qvals: -1.58367\n",
      "===========================================\n",
      "Model saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 810:\n",
      "Reward: -20.0\n",
      "Steps: 1143\n",
      "Avg loss: 0.01764\n",
      "Avg qvals: -1.52223\n",
      "===========================================\n",
      "Episode 811:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.61020\n",
      "===========================================\n",
      "Episode 812:\n",
      "Reward: -21.0\n",
      "Steps: 1058\n",
      "Avg loss: 0.01866\n",
      "Avg qvals: -1.82545\n",
      "===========================================\n",
      "Episode 813:\n",
      "Reward: -20.0\n",
      "Steps: 1281\n",
      "Avg loss: 0.01779\n",
      "Avg qvals: -1.59912\n",
      "===========================================\n",
      "Episode 814:\n",
      "Reward: -21.0\n",
      "Steps: 1047\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.60557\n",
      "===========================================\n",
      "Episode 815:\n",
      "Reward: -20.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01797\n",
      "Avg qvals: -1.73432\n",
      "===========================================\n",
      "Episode 816:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01795\n",
      "Avg qvals: -1.54169\n",
      "===========================================\n",
      "Episode 817:\n",
      "Reward: -21.0\n",
      "Steps: 1146\n",
      "Avg loss: 0.01742\n",
      "Avg qvals: -1.57579\n",
      "===========================================\n",
      "Episode 818:\n",
      "Reward: -21.0\n",
      "Steps: 1053\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.78967\n",
      "===========================================\n",
      "Episode 819:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01964\n",
      "Avg qvals: -1.71724\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 820:\n",
      "Reward: -20.0\n",
      "Steps: 1118\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.64526\n",
      "===========================================\n",
      "Episode 821:\n",
      "Reward: -20.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01863\n",
      "Avg qvals: -1.73861\n",
      "===========================================\n",
      "Episode 822:\n",
      "Reward: -20.0\n",
      "Steps: 1248\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.56251\n",
      "===========================================\n",
      "Episode 823:\n",
      "Reward: -20.0\n",
      "Steps: 1192\n",
      "Avg loss: 0.01869\n",
      "Avg qvals: -1.64853\n",
      "===========================================\n",
      "Episode 824:\n",
      "Reward: -21.0\n",
      "Steps: 1051\n",
      "Avg loss: 0.01850\n",
      "Avg qvals: -1.71738\n",
      "===========================================\n",
      "Episode 825:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01804\n",
      "Avg qvals: -1.46563\n",
      "===========================================\n",
      "Episode 826:\n",
      "Reward: -21.0\n",
      "Steps: 1078\n",
      "Avg loss: 0.01848\n",
      "Avg qvals: -1.74566\n",
      "===========================================\n",
      "Episode 827:\n",
      "Reward: -21.0\n",
      "Steps: 1094\n",
      "Avg loss: 0.01831\n",
      "Avg qvals: -1.68075\n",
      "===========================================\n",
      "Episode 828:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01874\n",
      "Avg qvals: -1.60663\n",
      "===========================================\n",
      "Episode 829:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01641\n",
      "Avg qvals: -1.58673\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 830:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01864\n",
      "Avg qvals: -1.68255\n",
      "===========================================\n",
      "Episode 831:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01808\n",
      "Avg qvals: -1.59795\n",
      "===========================================\n",
      "Episode 832:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01741\n",
      "Avg qvals: -1.48010\n",
      "===========================================\n",
      "Episode 833:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01965\n",
      "Avg qvals: -1.82746\n",
      "===========================================\n",
      "Episode 834:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.73876\n",
      "===========================================\n",
      "Episode 835:\n",
      "Reward: -21.0\n",
      "Steps: 1033\n",
      "Avg loss: 0.01853\n",
      "Avg qvals: -1.52589\n",
      "===========================================\n",
      "Episode 836:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01753\n",
      "Avg qvals: -1.58013\n",
      "===========================================\n",
      "Episode 837:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.69807\n",
      "===========================================\n",
      "Episode 838:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01660\n",
      "Avg qvals: -1.60144\n",
      "===========================================\n",
      "Episode 839:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.67265\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 840:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.49288\n",
      "===========================================\n",
      "Episode 841:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -1.55532\n",
      "===========================================\n",
      "Episode 842:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01825\n",
      "Avg qvals: -1.54860\n",
      "===========================================\n",
      "Episode 843:\n",
      "Reward: -21.0\n",
      "Steps: 1032\n",
      "Avg loss: 0.01864\n",
      "Avg qvals: -1.74366\n",
      "===========================================\n",
      "Episode 844:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01716\n",
      "Avg qvals: -1.58071\n",
      "===========================================\n",
      "Episode 845:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01708\n",
      "Avg qvals: -1.66051\n",
      "===========================================\n",
      "Episode 846:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.63672\n",
      "===========================================\n",
      "Episode 847:\n",
      "Reward: -21.0\n",
      "Steps: 1038\n",
      "Avg loss: 0.01791\n",
      "Avg qvals: -1.70009\n",
      "===========================================\n",
      "Episode 848:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01891\n",
      "Avg qvals: -1.78413\n",
      "===========================================\n",
      "Episode 849:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01684\n",
      "Avg qvals: -1.67748\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 850:\n",
      "Reward: -21.0\n",
      "Steps: 1033\n",
      "Avg loss: 0.01809\n",
      "Avg qvals: -1.69366\n",
      "===========================================\n",
      "Episode 851:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01861\n",
      "Avg qvals: -1.65205\n",
      "===========================================\n",
      "Episode 852:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01864\n",
      "Avg qvals: -1.64087\n",
      "===========================================\n",
      "Episode 853:\n",
      "Reward: -21.0\n",
      "Steps: 1035\n",
      "Avg loss: 0.01767\n",
      "Avg qvals: -1.60046\n",
      "===========================================\n",
      "Episode 854:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01840\n",
      "Avg qvals: -1.55987\n",
      "===========================================\n",
      "Episode 855:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01836\n",
      "Avg qvals: -1.71273\n",
      "===========================================\n",
      "Episode 856:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01720\n",
      "Avg qvals: -1.69710\n",
      "===========================================\n",
      "Episode 857:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.66823\n",
      "===========================================\n",
      "Episode 858:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01892\n",
      "Avg qvals: -1.76008\n",
      "===========================================\n",
      "Episode 859:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01758\n",
      "Avg qvals: -1.68792\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 860:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01820\n",
      "Avg qvals: -1.59224\n",
      "===========================================\n",
      "Episode 861:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01770\n",
      "Avg qvals: -1.56445\n",
      "===========================================\n",
      "Episode 862:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.70061\n",
      "===========================================\n",
      "Episode 863:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.58270\n",
      "===========================================\n",
      "Episode 864:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01764\n",
      "Avg qvals: -1.64413\n",
      "===========================================\n",
      "Episode 865:\n",
      "Reward: -21.0\n",
      "Steps: 1033\n",
      "Avg loss: 0.01703\n",
      "Avg qvals: -1.58961\n",
      "===========================================\n",
      "Episode 866:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.65971\n",
      "===========================================\n",
      "Episode 867:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01695\n",
      "Avg qvals: -1.54529\n",
      "===========================================\n",
      "Episode 868:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01908\n",
      "Avg qvals: -1.60491\n",
      "===========================================\n",
      "Episode 869:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01740\n",
      "Avg qvals: -1.63977\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 870:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01864\n",
      "Avg qvals: -1.70103\n",
      "===========================================\n",
      "Episode 871:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.56835\n",
      "===========================================\n",
      "Episode 872:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.61751\n",
      "===========================================\n",
      "Episode 873:\n",
      "Reward: -21.0\n",
      "Steps: 1006\n",
      "Avg loss: 0.01828\n",
      "Avg qvals: -1.72152\n",
      "===========================================\n",
      "Episode 874:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.89638\n",
      "===========================================\n",
      "Episode 875:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01880\n",
      "Avg qvals: -1.79601\n",
      "===========================================\n",
      "Episode 876:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01791\n",
      "Avg qvals: -1.61266\n",
      "===========================================\n",
      "Episode 877:\n",
      "Reward: -21.0\n",
      "Steps: 1032\n",
      "Avg loss: 0.01775\n",
      "Avg qvals: -1.57800\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 878:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.59725\n",
      "===========================================\n",
      "Episode 879:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01857\n",
      "Avg qvals: -1.50607\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 880:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01614\n",
      "Avg qvals: -1.44113\n",
      "===========================================\n",
      "Episode 881:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.76491\n",
      "===========================================\n",
      "Episode 882:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01816\n",
      "Avg qvals: -1.69848\n",
      "===========================================\n",
      "Episode 883:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01649\n",
      "Avg qvals: -1.55783\n",
      "===========================================\n",
      "Episode 884:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.50333\n",
      "===========================================\n",
      "Episode 885:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01826\n",
      "Avg qvals: -1.81065\n",
      "===========================================\n",
      "Episode 886:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01657\n",
      "Avg qvals: -1.51084\n",
      "===========================================\n",
      "Episode 887:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01947\n",
      "Avg qvals: -1.73527\n",
      "===========================================\n",
      "Episode 888:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01992\n",
      "Avg qvals: -1.91400\n",
      "===========================================\n",
      "Episode 889:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.02000\n",
      "Avg qvals: -1.74036\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 890:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01900\n",
      "Avg qvals: -1.57959\n",
      "===========================================\n",
      "Episode 891:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01910\n",
      "Avg qvals: -1.94842\n",
      "===========================================\n",
      "Episode 892:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01725\n",
      "Avg qvals: -1.56268\n",
      "===========================================\n",
      "Episode 893:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01965\n",
      "Avg qvals: -1.71982\n",
      "===========================================\n",
      "Episode 894:\n",
      "Reward: -20.0\n",
      "Steps: 1163\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.78968\n",
      "===========================================\n",
      "Episode 895:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01814\n",
      "Avg qvals: -1.54283\n",
      "===========================================\n",
      "Episode 896:\n",
      "Reward: -19.0\n",
      "Steps: 1216\n",
      "Avg loss: 0.01748\n",
      "Avg qvals: -1.71247\n",
      "===========================================\n",
      "Episode 897:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01778\n",
      "Avg qvals: -1.58701\n",
      "===========================================\n",
      "Episode 898:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01816\n",
      "Avg qvals: -1.60520\n",
      "===========================================\n",
      "Episode 899:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01760\n",
      "Avg qvals: -1.52443\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 900:\n",
      "Reward: -20.0\n",
      "Steps: 1131\n",
      "Avg loss: 0.01767\n",
      "Avg qvals: -1.55641\n",
      "===========================================\n",
      "Episode 901:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01901\n",
      "Avg qvals: -1.73685\n",
      "===========================================\n",
      "Episode 902:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01706\n",
      "Avg qvals: -1.42206\n",
      "===========================================\n",
      "Episode 903:\n",
      "Reward: -20.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.61794\n",
      "===========================================\n",
      "Episode 904:\n",
      "Reward: -21.0\n",
      "Steps: 1057\n",
      "Avg loss: 0.01704\n",
      "Avg qvals: -1.55126\n",
      "===========================================\n",
      "Episode 905:\n",
      "Reward: -20.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01751\n",
      "Avg qvals: -1.68474\n",
      "===========================================\n",
      "Episode 906:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01681\n",
      "Avg qvals: -1.55702\n",
      "===========================================\n",
      "Episode 907:\n",
      "Reward: -20.0\n",
      "Steps: 1188\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.68843\n",
      "===========================================\n",
      "Episode 908:\n",
      "Reward: -21.0\n",
      "Steps: 1033\n",
      "Avg loss: 0.01860\n",
      "Avg qvals: -1.73040\n",
      "===========================================\n",
      "Episode 909:\n",
      "Reward: -20.0\n",
      "Steps: 1175\n",
      "Avg loss: 0.01696\n",
      "Avg qvals: -1.47721\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 910:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01823\n",
      "Avg qvals: -1.76148\n",
      "===========================================\n",
      "Episode 911:\n",
      "Reward: -20.0\n",
      "Steps: 1162\n",
      "Avg loss: 0.01976\n",
      "Avg qvals: -1.74777\n",
      "===========================================\n",
      "Episode 912:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.66021\n",
      "===========================================\n",
      "Episode 913:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.72913\n",
      "===========================================\n",
      "Episode 914:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01624\n",
      "Avg qvals: -1.46286\n",
      "===========================================\n",
      "Episode 915:\n",
      "Reward: -21.0\n",
      "Steps: 1003\n",
      "Avg loss: 0.01885\n",
      "Avg qvals: -1.67422\n",
      "===========================================\n",
      "Episode 916:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.74522\n",
      "===========================================\n",
      "Episode 917:\n",
      "Reward: -21.0\n",
      "Steps: 1109\n",
      "Avg loss: 0.01722\n",
      "Avg qvals: -1.41128\n",
      "===========================================\n",
      "Episode 918:\n",
      "Reward: -20.0\n",
      "Steps: 1162\n",
      "Avg loss: 0.01726\n",
      "Avg qvals: -1.54557\n",
      "===========================================\n",
      "Episode 919:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01877\n",
      "Avg qvals: -1.70407\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 920:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01801\n",
      "Avg qvals: -1.58103\n",
      "===========================================\n",
      "Episode 921:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01927\n",
      "Avg qvals: -1.83525\n",
      "===========================================\n",
      "Episode 922:\n",
      "Reward: -21.0\n",
      "Steps: 1041\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.64005\n",
      "===========================================\n",
      "Episode 923:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01736\n",
      "Avg qvals: -1.61503\n",
      "===========================================\n",
      "Episode 924:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01884\n",
      "Avg qvals: -1.66412\n",
      "===========================================\n",
      "Episode 925:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01878\n",
      "Avg qvals: -1.62301\n",
      "===========================================\n",
      "Episode 926:\n",
      "Reward: -20.0\n",
      "Steps: 1156\n",
      "Avg loss: 0.01841\n",
      "Avg qvals: -1.66298\n",
      "===========================================\n",
      "Episode 927:\n",
      "Reward: -20.0\n",
      "Steps: 1155\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.63072\n",
      "===========================================\n",
      "Episode 928:\n",
      "Reward: -20.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01831\n",
      "Avg qvals: -1.62059\n",
      "===========================================\n",
      "Episode 929:\n",
      "Reward: -20.0\n",
      "Steps: 1163\n",
      "Avg loss: 0.01788\n",
      "Avg qvals: -1.49100\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 930:\n",
      "Reward: -20.0\n",
      "Steps: 1138\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.65991\n",
      "===========================================\n",
      "Episode 931:\n",
      "Reward: -20.0\n",
      "Steps: 1156\n",
      "Avg loss: 0.01731\n",
      "Avg qvals: -1.56045\n",
      "===========================================\n",
      "Episode 932:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01684\n",
      "Avg qvals: -1.51468\n",
      "===========================================\n",
      "Episode 933:\n",
      "Reward: -19.0\n",
      "Steps: 1229\n",
      "Avg loss: 0.01906\n",
      "Avg qvals: -1.75900\n",
      "===========================================\n",
      "Episode 934:\n",
      "Reward: -20.0\n",
      "Steps: 1169\n",
      "Avg loss: 0.01764\n",
      "Avg qvals: -1.59945\n",
      "===========================================\n",
      "Episode 935:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01773\n",
      "Avg qvals: -1.60489\n",
      "===========================================\n",
      "Episode 936:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01959\n",
      "Avg qvals: -1.72753\n",
      "===========================================\n",
      "Episode 937:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01867\n",
      "Avg qvals: -1.87688\n",
      "===========================================\n",
      "Episode 938:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01689\n",
      "Avg qvals: -1.61355\n",
      "===========================================\n",
      "Episode 939:\n",
      "Reward: -21.0\n",
      "Steps: 1222\n",
      "Avg loss: 0.01828\n",
      "Avg qvals: -1.61332\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 940:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01985\n",
      "Avg qvals: -1.92376\n",
      "===========================================\n",
      "Episode 941:\n",
      "Reward: -21.0\n",
      "Steps: 1048\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.66296\n",
      "===========================================\n",
      "Episode 942:\n",
      "Reward: -21.0\n",
      "Steps: 1035\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.59524\n",
      "===========================================\n",
      "Episode 943:\n",
      "Reward: -21.0\n",
      "Steps: 1048\n",
      "Avg loss: 0.01698\n",
      "Avg qvals: -1.65921\n",
      "===========================================\n",
      "Episode 944:\n",
      "Reward: -21.0\n",
      "Steps: 1055\n",
      "Avg loss: 0.01666\n",
      "Avg qvals: -1.48537\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 945:\n",
      "Reward: -21.0\n",
      "Steps: 1133\n",
      "Avg loss: 0.01795\n",
      "Avg qvals: -1.66337\n",
      "===========================================\n",
      "Episode 946:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.53986\n",
      "===========================================\n",
      "Episode 947:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.63663\n",
      "===========================================\n",
      "Episode 948:\n",
      "Reward: -20.0\n",
      "Steps: 1188\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.64623\n",
      "===========================================\n",
      "Episode 949:\n",
      "Reward: -21.0\n",
      "Steps: 1064\n",
      "Avg loss: 0.01726\n",
      "Avg qvals: -1.37411\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 950:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.66777\n",
      "===========================================\n",
      "Episode 951:\n",
      "Reward: -21.0\n",
      "Steps: 1050\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.63709\n",
      "===========================================\n",
      "Episode 952:\n",
      "Reward: -20.0\n",
      "Steps: 1123\n",
      "Avg loss: 0.01962\n",
      "Avg qvals: -1.70805\n",
      "===========================================\n",
      "Episode 953:\n",
      "Reward: -21.0\n",
      "Steps: 1058\n",
      "Avg loss: 0.01832\n",
      "Avg qvals: -1.71273\n",
      "===========================================\n",
      "Episode 954:\n",
      "Reward: -21.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01698\n",
      "Avg qvals: -1.51854\n",
      "===========================================\n",
      "Episode 955:\n",
      "Reward: -21.0\n",
      "Steps: 1052\n",
      "Avg loss: 0.01731\n",
      "Avg qvals: -1.67418\n",
      "===========================================\n",
      "Episode 956:\n",
      "Reward: -21.0\n",
      "Steps: 1056\n",
      "Avg loss: 0.01682\n",
      "Avg qvals: -1.52519\n",
      "===========================================\n",
      "Episode 957:\n",
      "Reward: -20.0\n",
      "Steps: 1178\n",
      "Avg loss: 0.01941\n",
      "Avg qvals: -1.91386\n",
      "===========================================\n",
      "Episode 958:\n",
      "Reward: -21.0\n",
      "Steps: 1072\n",
      "Avg loss: 0.01802\n",
      "Avg qvals: -1.71393\n",
      "===========================================\n",
      "Episode 959:\n",
      "Reward: -20.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.01863\n",
      "Avg qvals: -1.83888\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 960:\n",
      "Reward: -21.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01726\n",
      "Avg qvals: -1.51723\n",
      "===========================================\n",
      "Episode 961:\n",
      "Reward: -20.0\n",
      "Steps: 1171\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.57494\n",
      "===========================================\n",
      "Episode 962:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01700\n",
      "Avg qvals: -1.52582\n",
      "===========================================\n",
      "Episode 963:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.02041\n",
      "Avg qvals: -1.92554\n",
      "===========================================\n",
      "Episode 964:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01908\n",
      "Avg qvals: -1.61706\n",
      "===========================================\n",
      "Episode 965:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01823\n",
      "Avg qvals: -1.73716\n",
      "===========================================\n",
      "Episode 966:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.62874\n",
      "===========================================\n",
      "Episode 967:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01864\n",
      "Avg qvals: -1.67027\n",
      "===========================================\n",
      "Episode 968:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.53959\n",
      "===========================================\n",
      "Episode 969:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01832\n",
      "Avg qvals: -1.66101\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 970:\n",
      "Reward: -20.0\n",
      "Steps: 1165\n",
      "Avg loss: 0.01944\n",
      "Avg qvals: -1.57958\n",
      "===========================================\n",
      "Episode 971:\n",
      "Reward: -21.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.67712\n",
      "===========================================\n",
      "Episode 972:\n",
      "Reward: -21.0\n",
      "Steps: 1093\n",
      "Avg loss: 0.01733\n",
      "Avg qvals: -1.63626\n",
      "===========================================\n",
      "Episode 973:\n",
      "Reward: -20.0\n",
      "Steps: 1229\n",
      "Avg loss: 0.01801\n",
      "Avg qvals: -1.56320\n",
      "===========================================\n",
      "Episode 974:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01749\n",
      "Avg qvals: -1.54566\n",
      "===========================================\n",
      "Episode 975:\n",
      "Reward: -21.0\n",
      "Steps: 1052\n",
      "Avg loss: 0.01657\n",
      "Avg qvals: -1.55292\n",
      "===========================================\n",
      "Episode 976:\n",
      "Reward: -21.0\n",
      "Steps: 1036\n",
      "Avg loss: 0.01875\n",
      "Avg qvals: -1.76140\n",
      "===========================================\n",
      "Episode 977:\n",
      "Reward: -20.0\n",
      "Steps: 1302\n",
      "Avg loss: 0.01881\n",
      "Avg qvals: -1.74263\n",
      "===========================================\n",
      "Episode 978:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.69724\n",
      "===========================================\n",
      "Episode 979:\n",
      "Reward: -21.0\n",
      "Steps: 1061\n",
      "Avg loss: 0.01893\n",
      "Avg qvals: -1.69300\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 980:\n",
      "Reward: -21.0\n",
      "Steps: 1044\n",
      "Avg loss: 0.01916\n",
      "Avg qvals: -1.68514\n",
      "===========================================\n",
      "Episode 981:\n",
      "Reward: -20.0\n",
      "Steps: 1164\n",
      "Avg loss: 0.01752\n",
      "Avg qvals: -1.62152\n",
      "===========================================\n",
      "Episode 982:\n",
      "Reward: -20.0\n",
      "Steps: 1150\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.72966\n",
      "===========================================\n",
      "Episode 983:\n",
      "Reward: -21.0\n",
      "Steps: 1150\n",
      "Avg loss: 0.01716\n",
      "Avg qvals: -1.72135\n",
      "===========================================\n",
      "Episode 984:\n",
      "Reward: -20.0\n",
      "Steps: 1123\n",
      "Avg loss: 0.01812\n",
      "Avg qvals: -1.85244\n",
      "===========================================\n",
      "Episode 985:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01952\n",
      "Avg qvals: -1.65057\n",
      "===========================================\n",
      "Episode 986:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01840\n",
      "Avg qvals: -1.69864\n",
      "===========================================\n",
      "Episode 987:\n",
      "Reward: -20.0\n",
      "Steps: 1114\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.71667\n",
      "===========================================\n",
      "Episode 988:\n",
      "Reward: -20.0\n",
      "Steps: 1120\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.72734\n",
      "===========================================\n",
      "Episode 989:\n",
      "Reward: -20.0\n",
      "Steps: 1106\n",
      "Avg loss: 0.01843\n",
      "Avg qvals: -1.63066\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 990:\n",
      "Reward: -20.0\n",
      "Steps: 1112\n",
      "Avg loss: 0.01862\n",
      "Avg qvals: -1.68316\n",
      "===========================================\n",
      "Episode 991:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01740\n",
      "Avg qvals: -1.61933\n",
      "===========================================\n",
      "Episode 992:\n",
      "Reward: -21.0\n",
      "Steps: 1078\n",
      "Avg loss: 0.01738\n",
      "Avg qvals: -1.70537\n",
      "===========================================\n",
      "Episode 993:\n",
      "Reward: -20.0\n",
      "Steps: 1115\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.59636\n",
      "===========================================\n",
      "Episode 994:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01779\n",
      "Avg qvals: -1.85372\n",
      "===========================================\n",
      "Episode 995:\n",
      "Reward: -20.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.01849\n",
      "Avg qvals: -1.76396\n",
      "===========================================\n",
      "Episode 996:\n",
      "Reward: -21.0\n",
      "Steps: 1058\n",
      "Avg loss: 0.01949\n",
      "Avg qvals: -2.00169\n",
      "===========================================\n",
      "Episode 997:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01628\n",
      "Avg qvals: -1.47170\n",
      "===========================================\n",
      "Episode 998:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01792\n",
      "Avg qvals: -1.66542\n",
      "===========================================\n",
      "Episode 999:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01656\n",
      "Avg qvals: -1.55774\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1000:\n",
      "Reward: -21.0\n",
      "Steps: 1054\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.82382\n",
      "===========================================\n",
      "Episode 1001:\n",
      "Reward: -20.0\n",
      "Steps: 1135\n",
      "Avg loss: 0.01834\n",
      "Avg qvals: -1.66236\n",
      "===========================================\n",
      "Episode 1002:\n",
      "Reward: -20.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.77888\n",
      "===========================================\n",
      "Episode 1003:\n",
      "Reward: -21.0\n",
      "Steps: 1051\n",
      "Avg loss: 0.01868\n",
      "Avg qvals: -1.56389\n",
      "===========================================\n",
      "Episode 1004:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.82517\n",
      "===========================================\n",
      "Episode 1005:\n",
      "Reward: -20.0\n",
      "Steps: 1170\n",
      "Avg loss: 0.01932\n",
      "Avg qvals: -1.63631\n",
      "===========================================\n",
      "Episode 1006:\n",
      "Reward: -19.0\n",
      "Steps: 1275\n",
      "Avg loss: 0.01770\n",
      "Avg qvals: -1.80658\n",
      "===========================================\n",
      "Episode 1007:\n",
      "Reward: -20.0\n",
      "Steps: 1119\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.77606\n",
      "===========================================\n",
      "Episode 1008:\n",
      "Reward: -20.0\n",
      "Steps: 1156\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.63592\n",
      "===========================================\n",
      "Episode 1009:\n",
      "Reward: -21.0\n",
      "Steps: 1060\n",
      "Avg loss: 0.01773\n",
      "Avg qvals: -1.61799\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1010:\n",
      "Reward: -21.0\n",
      "Steps: 1094\n",
      "Avg loss: 0.01833\n",
      "Avg qvals: -1.69845\n",
      "===========================================\n",
      "Episode 1011:\n",
      "Reward: -20.0\n",
      "Steps: 1133\n",
      "Avg loss: 0.01894\n",
      "Avg qvals: -1.81323\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1012:\n",
      "Reward: -21.0\n",
      "Steps: 1042\n",
      "Avg loss: 0.01935\n",
      "Avg qvals: -1.75156\n",
      "===========================================\n",
      "Episode 1013:\n",
      "Reward: -20.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.02085\n",
      "Avg qvals: -1.91180\n",
      "===========================================\n",
      "Episode 1014:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.60124\n",
      "===========================================\n",
      "Episode 1015:\n",
      "Reward: -20.0\n",
      "Steps: 1203\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.71300\n",
      "===========================================\n",
      "Episode 1016:\n",
      "Reward: -21.0\n",
      "Steps: 1165\n",
      "Avg loss: 0.01783\n",
      "Avg qvals: -1.70365\n",
      "===========================================\n",
      "Episode 1017:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01842\n",
      "Avg qvals: -1.83917\n",
      "===========================================\n",
      "Episode 1018:\n",
      "Reward: -21.0\n",
      "Steps: 1130\n",
      "Avg loss: 0.01879\n",
      "Avg qvals: -1.72760\n",
      "===========================================\n",
      "Episode 1019:\n",
      "Reward: -21.0\n",
      "Steps: 1067\n",
      "Avg loss: 0.01823\n",
      "Avg qvals: -1.70728\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1020:\n",
      "Reward: -21.0\n",
      "Steps: 1172\n",
      "Avg loss: 0.01671\n",
      "Avg qvals: -1.56387\n",
      "===========================================\n",
      "Episode 1021:\n",
      "Reward: -21.0\n",
      "Steps: 1081\n",
      "Avg loss: 0.01783\n",
      "Avg qvals: -1.71465\n",
      "===========================================\n",
      "Episode 1022:\n",
      "Reward: -20.0\n",
      "Steps: 1296\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.65424\n",
      "===========================================\n",
      "Episode 1023:\n",
      "Reward: -20.0\n",
      "Steps: 1130\n",
      "Avg loss: 0.01751\n",
      "Avg qvals: -1.58262\n",
      "===========================================\n",
      "Episode 1024:\n",
      "Reward: -21.0\n",
      "Steps: 1103\n",
      "Avg loss: 0.01789\n",
      "Avg qvals: -1.64702\n",
      "===========================================\n",
      "Episode 1025:\n",
      "Reward: -20.0\n",
      "Steps: 1106\n",
      "Avg loss: 0.01887\n",
      "Avg qvals: -1.93352\n",
      "===========================================\n",
      "Episode 1026:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01870\n",
      "Avg qvals: -1.68193\n",
      "===========================================\n",
      "Episode 1027:\n",
      "Reward: -21.0\n",
      "Steps: 1066\n",
      "Avg loss: 0.01704\n",
      "Avg qvals: -1.68136\n",
      "===========================================\n",
      "Episode 1028:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01828\n",
      "Avg qvals: -1.71261\n",
      "===========================================\n",
      "Episode 1029:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01843\n",
      "Avg qvals: -1.72047\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1030:\n",
      "Reward: -21.0\n",
      "Steps: 1086\n",
      "Avg loss: 0.01892\n",
      "Avg qvals: -1.66081\n",
      "===========================================\n",
      "Episode 1031:\n",
      "Reward: -21.0\n",
      "Steps: 1147\n",
      "Avg loss: 0.01866\n",
      "Avg qvals: -1.83781\n",
      "===========================================\n",
      "Episode 1032:\n",
      "Reward: -20.0\n",
      "Steps: 1114\n",
      "Avg loss: 0.01881\n",
      "Avg qvals: -1.74775\n",
      "===========================================\n",
      "Episode 1033:\n",
      "Reward: -21.0\n",
      "Steps: 1066\n",
      "Avg loss: 0.01813\n",
      "Avg qvals: -1.68232\n",
      "===========================================\n",
      "Episode 1034:\n",
      "Reward: -20.0\n",
      "Steps: 1167\n",
      "Avg loss: 0.01877\n",
      "Avg qvals: -1.77433\n",
      "===========================================\n",
      "Episode 1035:\n",
      "Reward: -21.0\n",
      "Steps: 1089\n",
      "Avg loss: 0.01725\n",
      "Avg qvals: -1.68994\n",
      "===========================================\n",
      "Episode 1036:\n",
      "Reward: -20.0\n",
      "Steps: 1201\n",
      "Avg loss: 0.01957\n",
      "Avg qvals: -1.86220\n",
      "===========================================\n",
      "Episode 1037:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01919\n",
      "Avg qvals: -1.75868\n",
      "===========================================\n",
      "Episode 1038:\n",
      "Reward: -21.0\n",
      "Steps: 1079\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.58286\n",
      "===========================================\n",
      "Episode 1039:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.70277\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1040:\n",
      "Reward: -21.0\n",
      "Steps: 1071\n",
      "Avg loss: 0.01812\n",
      "Avg qvals: -1.58295\n",
      "===========================================\n",
      "Episode 1041:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.72770\n",
      "===========================================\n",
      "Episode 1042:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01879\n",
      "Avg qvals: -1.68890\n",
      "===========================================\n",
      "Episode 1043:\n",
      "Reward: -20.0\n",
      "Steps: 1197\n",
      "Avg loss: 0.01897\n",
      "Avg qvals: -1.62989\n",
      "===========================================\n",
      "Episode 1044:\n",
      "Reward: -21.0\n",
      "Steps: 1052\n",
      "Avg loss: 0.01765\n",
      "Avg qvals: -1.60278\n",
      "===========================================\n",
      "Episode 1045:\n",
      "Reward: -21.0\n",
      "Steps: 1084\n",
      "Avg loss: 0.01909\n",
      "Avg qvals: -1.81985\n",
      "===========================================\n",
      "Episode 1046:\n",
      "Reward: -19.0\n",
      "Steps: 1260\n",
      "Avg loss: 0.01905\n",
      "Avg qvals: -1.70832\n",
      "===========================================\n",
      "Episode 1047:\n",
      "Reward: -17.0\n",
      "Steps: 1446\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.80022\n",
      "===========================================\n",
      "Episode 1048:\n",
      "Reward: -20.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01789\n",
      "Avg qvals: -1.57048\n",
      "===========================================\n",
      "Episode 1049:\n",
      "Reward: -20.0\n",
      "Steps: 1162\n",
      "Avg loss: 0.01840\n",
      "Avg qvals: -1.62541\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1050:\n",
      "Reward: -20.0\n",
      "Steps: 1224\n",
      "Avg loss: 0.01823\n",
      "Avg qvals: -1.73367\n",
      "===========================================\n",
      "Episode 1051:\n",
      "Reward: -21.0\n",
      "Steps: 1130\n",
      "Avg loss: 0.01853\n",
      "Avg qvals: -1.67097\n",
      "===========================================\n",
      "Episode 1052:\n",
      "Reward: -21.0\n",
      "Steps: 1095\n",
      "Avg loss: 0.01909\n",
      "Avg qvals: -1.83905\n",
      "===========================================\n",
      "Episode 1053:\n",
      "Reward: -21.0\n",
      "Steps: 1068\n",
      "Avg loss: 0.01798\n",
      "Avg qvals: -1.49999\n",
      "===========================================\n",
      "Episode 1054:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.77569\n",
      "===========================================\n",
      "Episode 1055:\n",
      "Reward: -21.0\n",
      "Steps: 1053\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.67424\n",
      "===========================================\n",
      "Episode 1056:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01880\n",
      "Avg qvals: -1.71319\n",
      "===========================================\n",
      "Episode 1057:\n",
      "Reward: -21.0\n",
      "Steps: 1073\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.72888\n",
      "===========================================\n",
      "Episode 1058:\n",
      "Reward: -20.0\n",
      "Steps: 1118\n",
      "Avg loss: 0.01818\n",
      "Avg qvals: -1.80164\n",
      "===========================================\n",
      "Episode 1059:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01877\n",
      "Avg qvals: -1.78904\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1060:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.02043\n",
      "Avg qvals: -1.94790\n",
      "===========================================\n",
      "Episode 1061:\n",
      "Reward: -21.0\n",
      "Steps: 1079\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.52789\n",
      "===========================================\n",
      "Episode 1062:\n",
      "Reward: -20.0\n",
      "Steps: 1142\n",
      "Avg loss: 0.01852\n",
      "Avg qvals: -1.62995\n",
      "===========================================\n",
      "Episode 1063:\n",
      "Reward: -20.0\n",
      "Steps: 1141\n",
      "Avg loss: 0.01755\n",
      "Avg qvals: -1.66069\n",
      "===========================================\n",
      "Episode 1064:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01826\n",
      "Avg qvals: -1.75878\n",
      "===========================================\n",
      "Episode 1065:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01699\n",
      "Avg qvals: -1.74986\n",
      "===========================================\n",
      "Episode 1066:\n",
      "Reward: -21.0\n",
      "Steps: 1048\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.59424\n",
      "===========================================\n",
      "Episode 1067:\n",
      "Reward: -20.0\n",
      "Steps: 1133\n",
      "Avg loss: 0.01720\n",
      "Avg qvals: -1.47700\n",
      "===========================================\n",
      "Episode 1068:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01892\n",
      "Avg qvals: -1.70366\n",
      "===========================================\n",
      "Episode 1069:\n",
      "Reward: -20.0\n",
      "Steps: 1153\n",
      "Avg loss: 0.01796\n",
      "Avg qvals: -1.79664\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1070:\n",
      "Reward: -19.0\n",
      "Steps: 1301\n",
      "Avg loss: 0.01804\n",
      "Avg qvals: -1.68385\n",
      "===========================================\n",
      "Episode 1071:\n",
      "Reward: -20.0\n",
      "Steps: 1169\n",
      "Avg loss: 0.01777\n",
      "Avg qvals: -1.56675\n",
      "===========================================\n",
      "Episode 1072:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01841\n",
      "Avg qvals: -1.84774\n",
      "===========================================\n",
      "Episode 1073:\n",
      "Reward: -20.0\n",
      "Steps: 1213\n",
      "Avg loss: 0.01745\n",
      "Avg qvals: -1.58584\n",
      "===========================================\n",
      "Episode 1074:\n",
      "Reward: -21.0\n",
      "Steps: 1051\n",
      "Avg loss: 0.01946\n",
      "Avg qvals: -1.55720\n",
      "===========================================\n",
      "Episode 1075:\n",
      "Reward: -21.0\n",
      "Steps: 1038\n",
      "Avg loss: 0.01863\n",
      "Avg qvals: -1.73734\n",
      "===========================================\n",
      "Episode 1076:\n",
      "Reward: -21.0\n",
      "Steps: 1102\n",
      "Avg loss: 0.01873\n",
      "Avg qvals: -1.76438\n",
      "===========================================\n",
      "Episode 1077:\n",
      "Reward: -21.0\n",
      "Steps: 1051\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.62195\n",
      "===========================================\n",
      "Episode 1078:\n",
      "Reward: -21.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01884\n",
      "Avg qvals: -1.61986\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1079:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01699\n",
      "Avg qvals: -1.56555\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1080:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01830\n",
      "Avg qvals: -1.59929\n",
      "===========================================\n",
      "Episode 1081:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01726\n",
      "Avg qvals: -1.76158\n",
      "===========================================\n",
      "Episode 1082:\n",
      "Reward: -21.0\n",
      "Steps: 1174\n",
      "Avg loss: 0.01927\n",
      "Avg qvals: -1.60310\n",
      "===========================================\n",
      "Episode 1083:\n",
      "Reward: -20.0\n",
      "Steps: 1260\n",
      "Avg loss: 0.01793\n",
      "Avg qvals: -1.78146\n",
      "===========================================\n",
      "Episode 1084:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01909\n",
      "Avg qvals: -1.68068\n",
      "===========================================\n",
      "Episode 1085:\n",
      "Reward: -20.0\n",
      "Steps: 1235\n",
      "Avg loss: 0.01809\n",
      "Avg qvals: -1.67443\n",
      "===========================================\n",
      "Episode 1086:\n",
      "Reward: -20.0\n",
      "Steps: 1126\n",
      "Avg loss: 0.01715\n",
      "Avg qvals: -1.47094\n",
      "===========================================\n",
      "Episode 1087:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01795\n",
      "Avg qvals: -1.66529\n",
      "===========================================\n",
      "Episode 1088:\n",
      "Reward: -20.0\n",
      "Steps: 1122\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.67736\n",
      "===========================================\n",
      "Episode 1089:\n",
      "Reward: -21.0\n",
      "Steps: 1186\n",
      "Avg loss: 0.01855\n",
      "Avg qvals: -1.55053\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1090:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01610\n",
      "Avg qvals: -1.50710\n",
      "===========================================\n",
      "Episode 1091:\n",
      "Reward: -21.0\n",
      "Steps: 1038\n",
      "Avg loss: 0.01804\n",
      "Avg qvals: -1.58020\n",
      "===========================================\n",
      "Episode 1092:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01923\n",
      "Avg qvals: -1.66182\n",
      "===========================================\n",
      "Episode 1093:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01893\n",
      "Avg qvals: -1.66945\n",
      "===========================================\n",
      "Episode 1094:\n",
      "Reward: -21.0\n",
      "Steps: 1203\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.57008\n",
      "===========================================\n",
      "Episode 1095:\n",
      "Reward: -20.0\n",
      "Steps: 1297\n",
      "Avg loss: 0.01815\n",
      "Avg qvals: -1.54928\n",
      "===========================================\n",
      "Episode 1096:\n",
      "Reward: -21.0\n",
      "Steps: 1269\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.68161\n",
      "===========================================\n",
      "Episode 1097:\n",
      "Reward: -21.0\n",
      "Steps: 1339\n",
      "Avg loss: 0.01864\n",
      "Avg qvals: -1.74174\n",
      "===========================================\n",
      "Episode 1098:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01905\n",
      "Avg qvals: -1.68315\n",
      "===========================================\n",
      "Episode 1099:\n",
      "Reward: -20.0\n",
      "Steps: 1234\n",
      "Avg loss: 0.01778\n",
      "Avg qvals: -1.70857\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1100:\n",
      "Reward: -21.0\n",
      "Steps: 1328\n",
      "Avg loss: 0.01843\n",
      "Avg qvals: -1.58470\n",
      "===========================================\n",
      "Episode 1101:\n",
      "Reward: -20.0\n",
      "Steps: 1346\n",
      "Avg loss: 0.01745\n",
      "Avg qvals: -1.66188\n",
      "===========================================\n",
      "Episode 1102:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.67873\n",
      "===========================================\n",
      "Episode 1103:\n",
      "Reward: -21.0\n",
      "Steps: 1119\n",
      "Avg loss: 0.01903\n",
      "Avg qvals: -1.74296\n",
      "===========================================\n",
      "Episode 1104:\n",
      "Reward: -21.0\n",
      "Steps: 1193\n",
      "Avg loss: 0.01781\n",
      "Avg qvals: -1.57238\n",
      "===========================================\n",
      "Episode 1105:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.62304\n",
      "===========================================\n",
      "Episode 1106:\n",
      "Reward: -21.0\n",
      "Steps: 1349\n",
      "Avg loss: 0.01804\n",
      "Avg qvals: -1.75565\n",
      "===========================================\n",
      "Episode 1107:\n",
      "Reward: -21.0\n",
      "Steps: 1088\n",
      "Avg loss: 0.01791\n",
      "Avg qvals: -1.60105\n",
      "===========================================\n",
      "Episode 1108:\n",
      "Reward: -21.0\n",
      "Steps: 1177\n",
      "Avg loss: 0.01925\n",
      "Avg qvals: -1.61983\n",
      "===========================================\n",
      "Episode 1109:\n",
      "Reward: -20.0\n",
      "Steps: 1235\n",
      "Avg loss: 0.01852\n",
      "Avg qvals: -1.72499\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1110:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01954\n",
      "Avg qvals: -1.59716\n",
      "===========================================\n",
      "Episode 1111:\n",
      "Reward: -20.0\n",
      "Steps: 1141\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.60571\n",
      "===========================================\n",
      "Episode 1112:\n",
      "Reward: -19.0\n",
      "Steps: 1224\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.59356\n",
      "===========================================\n",
      "Episode 1113:\n",
      "Reward: -21.0\n",
      "Steps: 1082\n",
      "Avg loss: 0.01862\n",
      "Avg qvals: -1.67560\n",
      "===========================================\n",
      "Episode 1114:\n",
      "Reward: -21.0\n",
      "Steps: 1055\n",
      "Avg loss: 0.01895\n",
      "Avg qvals: -1.54199\n",
      "===========================================\n",
      "Episode 1115:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01789\n",
      "Avg qvals: -1.59706\n",
      "===========================================\n",
      "Episode 1116:\n",
      "Reward: -21.0\n",
      "Steps: 1142\n",
      "Avg loss: 0.01773\n",
      "Avg qvals: -1.61801\n",
      "===========================================\n",
      "Episode 1117:\n",
      "Reward: -21.0\n",
      "Steps: 1044\n",
      "Avg loss: 0.01795\n",
      "Avg qvals: -1.77505\n",
      "===========================================\n",
      "Episode 1118:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.71156\n",
      "===========================================\n",
      "Episode 1119:\n",
      "Reward: -20.0\n",
      "Steps: 1200\n",
      "Avg loss: 0.01813\n",
      "Avg qvals: -1.71539\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1120:\n",
      "Reward: -21.0\n",
      "Steps: 1058\n",
      "Avg loss: 0.01963\n",
      "Avg qvals: -1.70052\n",
      "===========================================\n",
      "Episode 1121:\n",
      "Reward: -20.0\n",
      "Steps: 1123\n",
      "Avg loss: 0.01897\n",
      "Avg qvals: -1.64530\n",
      "===========================================\n",
      "Episode 1122:\n",
      "Reward: -21.0\n",
      "Steps: 1044\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.64093\n",
      "===========================================\n",
      "Episode 1123:\n",
      "Reward: -19.0\n",
      "Steps: 1227\n",
      "Avg loss: 0.01860\n",
      "Avg qvals: -1.62078\n",
      "===========================================\n",
      "Episode 1124:\n",
      "Reward: -20.0\n",
      "Steps: 1113\n",
      "Avg loss: 0.01909\n",
      "Avg qvals: -1.76986\n",
      "===========================================\n",
      "Episode 1125:\n",
      "Reward: -20.0\n",
      "Steps: 1125\n",
      "Avg loss: 0.01857\n",
      "Avg qvals: -1.75835\n",
      "===========================================\n",
      "Episode 1126:\n",
      "Reward: -21.0\n",
      "Steps: 1056\n",
      "Avg loss: 0.01819\n",
      "Avg qvals: -1.67280\n",
      "===========================================\n",
      "Episode 1127:\n",
      "Reward: -20.0\n",
      "Steps: 1141\n",
      "Avg loss: 0.01707\n",
      "Avg qvals: -1.48256\n",
      "===========================================\n",
      "Episode 1128:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01879\n",
      "Avg qvals: -1.72492\n",
      "===========================================\n",
      "Episode 1129:\n",
      "Reward: -21.0\n",
      "Steps: 1045\n",
      "Avg loss: 0.01773\n",
      "Avg qvals: -1.78016\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1130:\n",
      "Reward: -19.0\n",
      "Steps: 1421\n",
      "Avg loss: 0.01850\n",
      "Avg qvals: -1.51150\n",
      "===========================================\n",
      "Episode 1131:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01850\n",
      "Avg qvals: -1.83179\n",
      "===========================================\n",
      "Episode 1132:\n",
      "Reward: -20.0\n",
      "Steps: 1130\n",
      "Avg loss: 0.01931\n",
      "Avg qvals: -1.76720\n",
      "===========================================\n",
      "Episode 1133:\n",
      "Reward: -21.0\n",
      "Steps: 1054\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.50475\n",
      "===========================================\n",
      "Episode 1134:\n",
      "Reward: -19.0\n",
      "Steps: 1308\n",
      "Avg loss: 0.01746\n",
      "Avg qvals: -1.68869\n",
      "===========================================\n",
      "Episode 1135:\n",
      "Reward: -21.0\n",
      "Steps: 1036\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.63202\n",
      "===========================================\n",
      "Episode 1136:\n",
      "Reward: -20.0\n",
      "Steps: 1146\n",
      "Avg loss: 0.01965\n",
      "Avg qvals: -1.69745\n",
      "===========================================\n",
      "Episode 1137:\n",
      "Reward: -20.0\n",
      "Steps: 1146\n",
      "Avg loss: 0.01795\n",
      "Avg qvals: -1.77223\n",
      "===========================================\n",
      "Episode 1138:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01938\n",
      "Avg qvals: -1.68102\n",
      "===========================================\n",
      "Episode 1139:\n",
      "Reward: -19.0\n",
      "Steps: 1226\n",
      "Avg loss: 0.01902\n",
      "Avg qvals: -1.61383\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1140:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01870\n",
      "Avg qvals: -1.86098\n",
      "===========================================\n",
      "Episode 1141:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01866\n",
      "Avg qvals: -1.66831\n",
      "===========================================\n",
      "Episode 1142:\n",
      "Reward: -21.0\n",
      "Steps: 1082\n",
      "Avg loss: 0.01854\n",
      "Avg qvals: -1.60803\n",
      "===========================================\n",
      "Episode 1143:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01848\n",
      "Avg qvals: -1.65834\n",
      "===========================================\n",
      "Episode 1144:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.64978\n",
      "===========================================\n",
      "Episode 1145:\n",
      "Reward: -20.0\n",
      "Steps: 1112\n",
      "Avg loss: 0.01867\n",
      "Avg qvals: -1.76265\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1146:\n",
      "Reward: -19.0\n",
      "Steps: 1286\n",
      "Avg loss: 0.01678\n",
      "Avg qvals: -1.62470\n",
      "===========================================\n",
      "Episode 1147:\n",
      "Reward: -21.0\n",
      "Steps: 1157\n",
      "Avg loss: 0.01873\n",
      "Avg qvals: -1.50555\n",
      "===========================================\n",
      "Episode 1148:\n",
      "Reward: -21.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01766\n",
      "Avg qvals: -1.65822\n",
      "===========================================\n",
      "Episode 1149:\n",
      "Reward: -21.0\n",
      "Steps: 1077\n",
      "Avg loss: 0.01892\n",
      "Avg qvals: -1.84310\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1150:\n",
      "Reward: -21.0\n",
      "Steps: 1186\n",
      "Avg loss: 0.01689\n",
      "Avg qvals: -1.48789\n",
      "===========================================\n",
      "Episode 1151:\n",
      "Reward: -21.0\n",
      "Steps: 1083\n",
      "Avg loss: 0.01942\n",
      "Avg qvals: -1.75080\n",
      "===========================================\n",
      "Episode 1152:\n",
      "Reward: -20.0\n",
      "Steps: 1163\n",
      "Avg loss: 0.01859\n",
      "Avg qvals: -1.75351\n",
      "===========================================\n",
      "Episode 1153:\n",
      "Reward: -20.0\n",
      "Steps: 1157\n",
      "Avg loss: 0.01832\n",
      "Avg qvals: -1.80610\n",
      "===========================================\n",
      "Episode 1154:\n",
      "Reward: -21.0\n",
      "Steps: 1101\n",
      "Avg loss: 0.01771\n",
      "Avg qvals: -1.54438\n",
      "===========================================\n",
      "Episode 1155:\n",
      "Reward: -21.0\n",
      "Steps: 1042\n",
      "Avg loss: 0.01875\n",
      "Avg qvals: -1.76561\n",
      "===========================================\n",
      "Episode 1156:\n",
      "Reward: -21.0\n",
      "Steps: 1038\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.59188\n",
      "===========================================\n",
      "Episode 1157:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01841\n",
      "Avg qvals: -1.80421\n",
      "===========================================\n",
      "Episode 1158:\n",
      "Reward: -20.0\n",
      "Steps: 1123\n",
      "Avg loss: 0.01867\n",
      "Avg qvals: -1.80707\n",
      "===========================================\n",
      "Episode 1159:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01840\n",
      "Avg qvals: -1.75727\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1160:\n",
      "Reward: -20.0\n",
      "Steps: 1206\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.66232\n",
      "===========================================\n",
      "Episode 1161:\n",
      "Reward: -20.0\n",
      "Steps: 1244\n",
      "Avg loss: 0.01807\n",
      "Avg qvals: -1.68959\n",
      "===========================================\n",
      "Episode 1162:\n",
      "Reward: -21.0\n",
      "Steps: 1135\n",
      "Avg loss: 0.01849\n",
      "Avg qvals: -1.85352\n",
      "===========================================\n",
      "Episode 1163:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.62970\n",
      "===========================================\n",
      "Episode 1164:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01793\n",
      "Avg qvals: -1.72469\n",
      "===========================================\n",
      "Episode 1165:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.66684\n",
      "===========================================\n",
      "Episode 1166:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01849\n",
      "Avg qvals: -1.74107\n",
      "===========================================\n",
      "Episode 1167:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01765\n",
      "Avg qvals: -1.72104\n",
      "===========================================\n",
      "Episode 1168:\n",
      "Reward: -21.0\n",
      "Steps: 1003\n",
      "Avg loss: 0.01838\n",
      "Avg qvals: -1.75780\n",
      "===========================================\n",
      "Episode 1169:\n",
      "Reward: -20.0\n",
      "Steps: 1162\n",
      "Avg loss: 0.01983\n",
      "Avg qvals: -1.78206\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1170:\n",
      "Reward: -20.0\n",
      "Steps: 1118\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.61491\n",
      "===========================================\n",
      "Episode 1171:\n",
      "Reward: -21.0\n",
      "Steps: 1119\n",
      "Avg loss: 0.01883\n",
      "Avg qvals: -1.72010\n",
      "===========================================\n",
      "Episode 1172:\n",
      "Reward: -20.0\n",
      "Steps: 1131\n",
      "Avg loss: 0.01979\n",
      "Avg qvals: -1.81011\n",
      "===========================================\n",
      "Episode 1173:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01959\n",
      "Avg qvals: -1.81305\n",
      "===========================================\n",
      "Episode 1174:\n",
      "Reward: -21.0\n",
      "Steps: 1070\n",
      "Avg loss: 0.01785\n",
      "Avg qvals: -1.59888\n",
      "===========================================\n",
      "Episode 1175:\n",
      "Reward: -20.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01959\n",
      "Avg qvals: -1.83438\n",
      "===========================================\n",
      "Episode 1176:\n",
      "Reward: -20.0\n",
      "Steps: 1122\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.59057\n",
      "===========================================\n",
      "Episode 1177:\n",
      "Reward: -20.0\n",
      "Steps: 1122\n",
      "Avg loss: 0.01826\n",
      "Avg qvals: -1.60807\n",
      "===========================================\n",
      "Episode 1178:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.72790\n",
      "===========================================\n",
      "Episode 1179:\n",
      "Reward: -21.0\n",
      "Steps: 1037\n",
      "Avg loss: 0.01629\n",
      "Avg qvals: -1.57747\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1180:\n",
      "Reward: -19.0\n",
      "Steps: 1300\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.78582\n",
      "===========================================\n",
      "Episode 1181:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01702\n",
      "Avg qvals: -1.58936\n",
      "===========================================\n",
      "Episode 1182:\n",
      "Reward: -20.0\n",
      "Steps: 1204\n",
      "Avg loss: 0.01842\n",
      "Avg qvals: -1.69359\n",
      "===========================================\n",
      "Episode 1183:\n",
      "Reward: -20.0\n",
      "Steps: 1219\n",
      "Avg loss: 0.01722\n",
      "Avg qvals: -1.55630\n",
      "===========================================\n",
      "Episode 1184:\n",
      "Reward: -21.0\n",
      "Steps: 1064\n",
      "Avg loss: 0.01841\n",
      "Avg qvals: -1.67094\n",
      "===========================================\n",
      "Episode 1185:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01884\n",
      "Avg qvals: -1.75321\n",
      "===========================================\n",
      "Episode 1186:\n",
      "Reward: -20.0\n",
      "Steps: 1131\n",
      "Avg loss: 0.01886\n",
      "Avg qvals: -1.99576\n",
      "===========================================\n",
      "Episode 1187:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01999\n",
      "Avg qvals: -1.89856\n",
      "===========================================\n",
      "Episode 1188:\n",
      "Reward: -21.0\n",
      "Steps: 1033\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.67392\n",
      "===========================================\n",
      "Episode 1189:\n",
      "Reward: -20.0\n",
      "Steps: 1177\n",
      "Avg loss: 0.01930\n",
      "Avg qvals: -1.67233\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1190:\n",
      "Reward: -21.0\n",
      "Steps: 1082\n",
      "Avg loss: 0.01757\n",
      "Avg qvals: -1.66710\n",
      "===========================================\n",
      "Episode 1191:\n",
      "Reward: -20.0\n",
      "Steps: 1157\n",
      "Avg loss: 0.01797\n",
      "Avg qvals: -1.61260\n",
      "===========================================\n",
      "Episode 1192:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01928\n",
      "Avg qvals: -1.81286\n",
      "===========================================\n",
      "Episode 1193:\n",
      "Reward: -19.0\n",
      "Steps: 1259\n",
      "Avg loss: 0.01880\n",
      "Avg qvals: -1.61325\n",
      "===========================================\n",
      "Episode 1194:\n",
      "Reward: -20.0\n",
      "Steps: 1263\n",
      "Avg loss: 0.01744\n",
      "Avg qvals: -1.57518\n",
      "===========================================\n",
      "Episode 1195:\n",
      "Reward: -20.0\n",
      "Steps: 1128\n",
      "Avg loss: 0.01786\n",
      "Avg qvals: -1.54402\n",
      "===========================================\n",
      "Episode 1196:\n",
      "Reward: -21.0\n",
      "Steps: 1054\n",
      "Avg loss: 0.01875\n",
      "Avg qvals: -1.65342\n",
      "===========================================\n",
      "Episode 1197:\n",
      "Reward: -20.0\n",
      "Steps: 1140\n",
      "Avg loss: 0.01899\n",
      "Avg qvals: -1.73320\n",
      "===========================================\n",
      "Episode 1198:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01967\n",
      "Avg qvals: -1.69388\n",
      "===========================================\n",
      "Episode 1199:\n",
      "Reward: -20.0\n",
      "Steps: 1146\n",
      "Avg loss: 0.01907\n",
      "Avg qvals: -1.82389\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1200:\n",
      "Reward: -20.0\n",
      "Steps: 1214\n",
      "Avg loss: 0.01636\n",
      "Avg qvals: -1.40909\n",
      "===========================================\n",
      "Episode 1201:\n",
      "Reward: -20.0\n",
      "Steps: 1117\n",
      "Avg loss: 0.01739\n",
      "Avg qvals: -1.56306\n",
      "===========================================\n",
      "Episode 1202:\n",
      "Reward: -20.0\n",
      "Steps: 1209\n",
      "Avg loss: 0.01813\n",
      "Avg qvals: -1.68950\n",
      "===========================================\n",
      "Episode 1203:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01731\n",
      "Avg qvals: -1.53441\n",
      "===========================================\n",
      "Episode 1204:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01789\n",
      "Avg qvals: -1.44422\n",
      "===========================================\n",
      "Episode 1205:\n",
      "Reward: -20.0\n",
      "Steps: 1123\n",
      "Avg loss: 0.01849\n",
      "Avg qvals: -1.76482\n",
      "===========================================\n",
      "Episode 1206:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01956\n",
      "Avg qvals: -1.70630\n",
      "===========================================\n",
      "Episode 1207:\n",
      "Reward: -21.0\n",
      "Steps: 1056\n",
      "Avg loss: 0.01861\n",
      "Avg qvals: -1.77140\n",
      "===========================================\n",
      "Episode 1208:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01810\n",
      "Avg qvals: -1.76936\n",
      "===========================================\n",
      "Episode 1209:\n",
      "Reward: -19.0\n",
      "Steps: 1239\n",
      "Avg loss: 0.01809\n",
      "Avg qvals: -1.65168\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1210:\n",
      "Reward: -20.0\n",
      "Steps: 1243\n",
      "Avg loss: 0.01882\n",
      "Avg qvals: -1.86905\n",
      "===========================================\n",
      "Episode 1211:\n",
      "Reward: -20.0\n",
      "Steps: 1107\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.71743\n",
      "===========================================\n",
      "Episode 1212:\n",
      "Reward: -21.0\n",
      "Steps: 1066\n",
      "Avg loss: 0.01812\n",
      "Avg qvals: -1.62403\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1213:\n",
      "Reward: -19.0\n",
      "Steps: 1274\n",
      "Avg loss: 0.01716\n",
      "Avg qvals: -1.67258\n",
      "===========================================\n",
      "Episode 1214:\n",
      "Reward: -21.0\n",
      "Steps: 1110\n",
      "Avg loss: 0.01785\n",
      "Avg qvals: -1.54365\n",
      "===========================================\n",
      "Episode 1215:\n",
      "Reward: -20.0\n",
      "Steps: 1237\n",
      "Avg loss: 0.01876\n",
      "Avg qvals: -1.69830\n",
      "===========================================\n",
      "Episode 1216:\n",
      "Reward: -20.0\n",
      "Steps: 1165\n",
      "Avg loss: 0.01876\n",
      "Avg qvals: -1.76362\n",
      "===========================================\n",
      "Episode 1217:\n",
      "Reward: -20.0\n",
      "Steps: 1202\n",
      "Avg loss: 0.01951\n",
      "Avg qvals: -1.86966\n",
      "===========================================\n",
      "Episode 1218:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01869\n",
      "Avg qvals: -1.74902\n",
      "===========================================\n",
      "Episode 1219:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01721\n",
      "Avg qvals: -1.68789\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1220:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01904\n",
      "Avg qvals: -1.80555\n",
      "===========================================\n",
      "Episode 1221:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01928\n",
      "Avg qvals: -1.68514\n",
      "===========================================\n",
      "Episode 1222:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01762\n",
      "Avg qvals: -1.56899\n",
      "===========================================\n",
      "Episode 1223:\n",
      "Reward: -21.0\n",
      "Steps: 1001\n",
      "Avg loss: 0.01931\n",
      "Avg qvals: -1.81585\n",
      "===========================================\n",
      "Episode 1224:\n",
      "Reward: -20.0\n",
      "Steps: 1197\n",
      "Avg loss: 0.01753\n",
      "Avg qvals: -1.71453\n",
      "===========================================\n",
      "Episode 1225:\n",
      "Reward: -21.0\n",
      "Steps: 1006\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.70915\n",
      "===========================================\n",
      "Episode 1226:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01826\n",
      "Avg qvals: -1.71189\n",
      "===========================================\n",
      "Episode 1227:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.61961\n",
      "===========================================\n",
      "Episode 1228:\n",
      "Reward: -20.0\n",
      "Steps: 1165\n",
      "Avg loss: 0.01813\n",
      "Avg qvals: -1.55664\n",
      "===========================================\n",
      "Episode 1229:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01880\n",
      "Avg qvals: -1.61883\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1230:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01723\n",
      "Avg qvals: -1.66805\n",
      "===========================================\n",
      "Episode 1231:\n",
      "Reward: -21.0\n",
      "Steps: 1043\n",
      "Avg loss: 0.01863\n",
      "Avg qvals: -1.61189\n",
      "===========================================\n",
      "Episode 1232:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01890\n",
      "Avg qvals: -1.73862\n",
      "===========================================\n",
      "Episode 1233:\n",
      "Reward: -21.0\n",
      "Steps: 1079\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.70335\n",
      "===========================================\n",
      "Episode 1234:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01761\n",
      "Avg qvals: -1.66931\n",
      "===========================================\n",
      "Episode 1235:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.81807\n",
      "===========================================\n",
      "Episode 1236:\n",
      "Reward: -21.0\n",
      "Steps: 1055\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.71269\n",
      "===========================================\n",
      "Episode 1237:\n",
      "Reward: -20.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01718\n",
      "Avg qvals: -1.65239\n",
      "===========================================\n",
      "Episode 1238:\n",
      "Reward: -21.0\n",
      "Steps: 1055\n",
      "Avg loss: 0.01992\n",
      "Avg qvals: -1.90648\n",
      "===========================================\n",
      "Episode 1239:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01755\n",
      "Avg qvals: -1.73210\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1240:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01974\n",
      "Avg qvals: -1.86370\n",
      "===========================================\n",
      "Episode 1241:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01776\n",
      "Avg qvals: -1.53817\n",
      "===========================================\n",
      "Episode 1242:\n",
      "Reward: -19.0\n",
      "Steps: 1258\n",
      "Avg loss: 0.01736\n",
      "Avg qvals: -1.59663\n",
      "===========================================\n",
      "Episode 1243:\n",
      "Reward: -20.0\n",
      "Steps: 1149\n",
      "Avg loss: 0.01861\n",
      "Avg qvals: -1.68524\n",
      "===========================================\n",
      "Episode 1244:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01884\n",
      "Avg qvals: -1.85472\n",
      "===========================================\n",
      "Episode 1245:\n",
      "Reward: -21.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01955\n",
      "Avg qvals: -1.69511\n",
      "===========================================\n",
      "Episode 1246:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01992\n",
      "Avg qvals: -1.91304\n",
      "===========================================\n",
      "Episode 1247:\n",
      "Reward: -21.0\n",
      "Steps: 1053\n",
      "Avg loss: 0.01966\n",
      "Avg qvals: -1.86827\n",
      "===========================================\n",
      "Episode 1248:\n",
      "Reward: -21.0\n",
      "Steps: 1058\n",
      "Avg loss: 0.01937\n",
      "Avg qvals: -1.83054\n",
      "===========================================\n",
      "Episode 1249:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01775\n",
      "Avg qvals: -1.71560\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1250:\n",
      "Reward: -21.0\n",
      "Steps: 1100\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.67515\n",
      "===========================================\n",
      "Episode 1251:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01928\n",
      "Avg qvals: -1.63587\n",
      "===========================================\n",
      "Episode 1252:\n",
      "Reward: -21.0\n",
      "Steps: 1053\n",
      "Avg loss: 0.01977\n",
      "Avg qvals: -1.95508\n",
      "===========================================\n",
      "Episode 1253:\n",
      "Reward: -20.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01908\n",
      "Avg qvals: -1.71030\n",
      "===========================================\n",
      "Episode 1254:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.57618\n",
      "===========================================\n",
      "Episode 1255:\n",
      "Reward: -21.0\n",
      "Steps: 1046\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.74305\n",
      "===========================================\n",
      "Episode 1256:\n",
      "Reward: -21.0\n",
      "Steps: 1047\n",
      "Avg loss: 0.01693\n",
      "Avg qvals: -1.47474\n",
      "===========================================\n",
      "Episode 1257:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01843\n",
      "Avg qvals: -1.54749\n",
      "===========================================\n",
      "Episode 1258:\n",
      "Reward: -20.0\n",
      "Steps: 1156\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.69599\n",
      "===========================================\n",
      "Episode 1259:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01829\n",
      "Avg qvals: -1.74893\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1260:\n",
      "Reward: -21.0\n",
      "Steps: 1002\n",
      "Avg loss: 0.01957\n",
      "Avg qvals: -1.75102\n",
      "===========================================\n",
      "Episode 1261:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01757\n",
      "Avg qvals: -1.58401\n",
      "===========================================\n",
      "Episode 1262:\n",
      "Reward: -19.0\n",
      "Steps: 1299\n",
      "Avg loss: 0.01894\n",
      "Avg qvals: -1.78110\n",
      "===========================================\n",
      "Episode 1263:\n",
      "Reward: -20.0\n",
      "Steps: 1194\n",
      "Avg loss: 0.01955\n",
      "Avg qvals: -1.78643\n",
      "===========================================\n",
      "Episode 1264:\n",
      "Reward: -18.0\n",
      "Steps: 1329\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.71264\n",
      "===========================================\n",
      "Episode 1265:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01738\n",
      "Avg qvals: -1.59735\n",
      "===========================================\n",
      "Episode 1266:\n",
      "Reward: -21.0\n",
      "Steps: 1101\n",
      "Avg loss: 0.01869\n",
      "Avg qvals: -1.58184\n",
      "===========================================\n",
      "Episode 1267:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01812\n",
      "Avg qvals: -1.77898\n",
      "===========================================\n",
      "Episode 1268:\n",
      "Reward: -21.0\n",
      "Steps: 1076\n",
      "Avg loss: 0.01894\n",
      "Avg qvals: -1.67277\n",
      "===========================================\n",
      "Episode 1269:\n",
      "Reward: -21.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01926\n",
      "Avg qvals: -1.69417\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1270:\n",
      "Reward: -19.0\n",
      "Steps: 1308\n",
      "Avg loss: 0.01867\n",
      "Avg qvals: -1.95363\n",
      "===========================================\n",
      "Episode 1271:\n",
      "Reward: -20.0\n",
      "Steps: 1112\n",
      "Avg loss: 0.01887\n",
      "Avg qvals: -1.70017\n",
      "===========================================\n",
      "Episode 1272:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.77703\n",
      "===========================================\n",
      "Episode 1273:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01814\n",
      "Avg qvals: -1.62409\n",
      "===========================================\n",
      "Episode 1274:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01976\n",
      "Avg qvals: -1.78883\n",
      "===========================================\n",
      "Episode 1275:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01828\n",
      "Avg qvals: -1.76702\n",
      "===========================================\n",
      "Episode 1276:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01875\n",
      "Avg qvals: -1.59593\n",
      "===========================================\n",
      "Episode 1277:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01735\n",
      "Avg qvals: -1.63177\n",
      "===========================================\n",
      "Episode 1278:\n",
      "Reward: -21.0\n",
      "Steps: 1050\n",
      "Avg loss: 0.01901\n",
      "Avg qvals: -1.76015\n",
      "===========================================\n",
      "Episode 1279:\n",
      "Reward: -20.0\n",
      "Steps: 1135\n",
      "Avg loss: 0.01747\n",
      "Avg qvals: -1.74684\n",
      "===========================================\n",
      "Model saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1280:\n",
      "Reward: -21.0\n",
      "Steps: 1145\n",
      "Avg loss: 0.01978\n",
      "Avg qvals: -1.78576\n",
      "===========================================\n",
      "Episode 1281:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01893\n",
      "Avg qvals: -1.64835\n",
      "===========================================\n",
      "Episode 1282:\n",
      "Reward: -21.0\n",
      "Steps: 1062\n",
      "Avg loss: 0.01806\n",
      "Avg qvals: -1.76483\n",
      "===========================================\n",
      "Episode 1283:\n",
      "Reward: -21.0\n",
      "Steps: 1049\n",
      "Avg loss: 0.01805\n",
      "Avg qvals: -1.50967\n",
      "===========================================\n",
      "Episode 1284:\n",
      "Reward: -18.0\n",
      "Steps: 1339\n",
      "Avg loss: 0.01904\n",
      "Avg qvals: -1.93343\n",
      "===========================================\n",
      "Episode 1285:\n",
      "Reward: -20.0\n",
      "Steps: 1161\n",
      "Avg loss: 0.01750\n",
      "Avg qvals: -1.54005\n",
      "===========================================\n",
      "Episode 1286:\n",
      "Reward: -21.0\n",
      "Steps: 1085\n",
      "Avg loss: 0.01711\n",
      "Avg qvals: -1.46661\n",
      "===========================================\n",
      "Episode 1287:\n",
      "Reward: -21.0\n",
      "Steps: 1094\n",
      "Avg loss: 0.02015\n",
      "Avg qvals: -1.85831\n",
      "===========================================\n",
      "Episode 1288:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01912\n",
      "Avg qvals: -1.62444\n",
      "===========================================\n",
      "Episode 1289:\n",
      "Reward: -18.0\n",
      "Steps: 1401\n",
      "Avg loss: 0.01786\n",
      "Avg qvals: -1.73574\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1290:\n",
      "Reward: -21.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.57248\n",
      "===========================================\n",
      "Episode 1291:\n",
      "Reward: -20.0\n",
      "Steps: 1187\n",
      "Avg loss: 0.01981\n",
      "Avg qvals: -1.80797\n",
      "===========================================\n",
      "Episode 1292:\n",
      "Reward: -21.0\n",
      "Steps: 1051\n",
      "Avg loss: 0.01694\n",
      "Avg qvals: -1.61364\n",
      "===========================================\n",
      "Episode 1293:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01611\n",
      "Avg qvals: -1.53160\n",
      "===========================================\n",
      "Episode 1294:\n",
      "Reward: -21.0\n",
      "Steps: 1034\n",
      "Avg loss: 0.01881\n",
      "Avg qvals: -1.66951\n",
      "===========================================\n",
      "Episode 1295:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01874\n",
      "Avg qvals: -1.68123\n",
      "===========================================\n",
      "Episode 1296:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01854\n",
      "Avg qvals: -1.64382\n",
      "===========================================\n",
      "Episode 1297:\n",
      "Reward: -21.0\n",
      "Steps: 1066\n",
      "Avg loss: 0.01811\n",
      "Avg qvals: -1.56973\n",
      "===========================================\n",
      "Episode 1298:\n",
      "Reward: -21.0\n",
      "Steps: 1002\n",
      "Avg loss: 0.01779\n",
      "Avg qvals: -1.60147\n",
      "===========================================\n",
      "Episode 1299:\n",
      "Reward: -21.0\n",
      "Steps: 1090\n",
      "Avg loss: 0.01921\n",
      "Avg qvals: -1.80310\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1300:\n",
      "Reward: -21.0\n",
      "Steps: 1102\n",
      "Avg loss: 0.01920\n",
      "Avg qvals: -1.90660\n",
      "===========================================\n",
      "Episode 1301:\n",
      "Reward: -21.0\n",
      "Steps: 1069\n",
      "Avg loss: 0.01957\n",
      "Avg qvals: -1.72530\n",
      "===========================================\n",
      "Episode 1302:\n",
      "Reward: -20.0\n",
      "Steps: 1151\n",
      "Avg loss: 0.01863\n",
      "Avg qvals: -1.84291\n",
      "===========================================\n",
      "Episode 1303:\n",
      "Reward: -21.0\n",
      "Steps: 1104\n",
      "Avg loss: 0.01730\n",
      "Avg qvals: -1.39410\n",
      "===========================================\n",
      "Episode 1304:\n",
      "Reward: -21.0\n",
      "Steps: 1083\n",
      "Avg loss: 0.01769\n",
      "Avg qvals: -1.56570\n",
      "===========================================\n",
      "Episode 1305:\n",
      "Reward: -21.0\n",
      "Steps: 1128\n",
      "Avg loss: 0.01768\n",
      "Avg qvals: -1.58672\n",
      "===========================================\n",
      "Episode 1306:\n",
      "Reward: -20.0\n",
      "Steps: 1237\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.77707\n",
      "===========================================\n",
      "Episode 1307:\n",
      "Reward: -20.0\n",
      "Steps: 1159\n",
      "Avg loss: 0.01901\n",
      "Avg qvals: -1.88273\n",
      "===========================================\n",
      "Episode 1308:\n",
      "Reward: -21.0\n",
      "Steps: 1065\n",
      "Avg loss: 0.01918\n",
      "Avg qvals: -1.80062\n",
      "===========================================\n",
      "Episode 1309:\n",
      "Reward: -21.0\n",
      "Steps: 1057\n",
      "Avg loss: 0.01862\n",
      "Avg qvals: -1.60568\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1310:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01911\n",
      "Avg qvals: -1.70587\n",
      "===========================================\n",
      "Episode 1311:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01861\n",
      "Avg qvals: -1.85207\n",
      "===========================================\n",
      "Episode 1312:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01859\n",
      "Avg qvals: -1.71629\n",
      "===========================================\n",
      "Episode 1313:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01924\n",
      "Avg qvals: -1.78928\n",
      "===========================================\n",
      "Episode 1314:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01965\n",
      "Avg qvals: -1.86087\n",
      "===========================================\n",
      "Episode 1315:\n",
      "Reward: -20.0\n",
      "Steps: 1165\n",
      "Avg loss: 0.01691\n",
      "Avg qvals: -1.60864\n",
      "===========================================\n",
      "Episode 1316:\n",
      "Reward: -21.0\n",
      "Steps: 1086\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.59123\n",
      "===========================================\n",
      "Episode 1317:\n",
      "Reward: -21.0\n",
      "Steps: 1048\n",
      "Avg loss: 0.01710\n",
      "Avg qvals: -1.70182\n",
      "===========================================\n",
      "Episode 1318:\n",
      "Reward: -20.0\n",
      "Steps: 1160\n",
      "Avg loss: 0.01709\n",
      "Avg qvals: -1.56514\n",
      "===========================================\n",
      "Episode 1319:\n",
      "Reward: -20.0\n",
      "Steps: 1119\n",
      "Avg loss: 0.01878\n",
      "Avg qvals: -1.78408\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1320:\n",
      "Reward: -21.0\n",
      "Steps: 1058\n",
      "Avg loss: 0.01804\n",
      "Avg qvals: -1.62800\n",
      "===========================================\n",
      "Episode 1321:\n",
      "Reward: -20.0\n",
      "Steps: 1178\n",
      "Avg loss: 0.01891\n",
      "Avg qvals: -1.80280\n",
      "===========================================\n",
      "Episode 1322:\n",
      "Reward: -21.0\n",
      "Steps: 1050\n",
      "Avg loss: 0.02061\n",
      "Avg qvals: -1.95771\n",
      "===========================================\n",
      "Episode 1323:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01932\n",
      "Avg qvals: -1.81361\n",
      "===========================================\n",
      "Episode 1324:\n",
      "Reward: -20.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01864\n",
      "Avg qvals: -1.68549\n",
      "===========================================\n",
      "Episode 1325:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01841\n",
      "Avg qvals: -1.69030\n",
      "===========================================\n",
      "Episode 1326:\n",
      "Reward: -21.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.01745\n",
      "Avg qvals: -1.61371\n",
      "===========================================\n",
      "Episode 1327:\n",
      "Reward: -20.0\n",
      "Steps: 1116\n",
      "Avg loss: 0.01782\n",
      "Avg qvals: -1.68385\n",
      "===========================================\n",
      "Episode 1328:\n",
      "Reward: -20.0\n",
      "Steps: 1160\n",
      "Avg loss: 0.01750\n",
      "Avg qvals: -1.73788\n",
      "===========================================\n",
      "Episode 1329:\n",
      "Reward: -21.0\n",
      "Steps: 1096\n",
      "Avg loss: 0.01969\n",
      "Avg qvals: -1.89103\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1330:\n",
      "Reward: -21.0\n",
      "Steps: 1045\n",
      "Avg loss: 0.01861\n",
      "Avg qvals: -1.75424\n",
      "===========================================\n",
      "Episode 1331:\n",
      "Reward: -21.0\n",
      "Steps: 996\n",
      "Avg loss: 0.01927\n",
      "Avg qvals: -1.70220\n",
      "===========================================\n",
      "Episode 1332:\n",
      "Reward: -20.0\n",
      "Steps: 1111\n",
      "Avg loss: 0.01902\n",
      "Avg qvals: -1.79395\n",
      "===========================================\n",
      "Episode 1333:\n",
      "Reward: -21.0\n",
      "Steps: 1152\n",
      "Avg loss: 0.01790\n",
      "Avg qvals: -1.65861\n",
      "===========================================\n",
      "Episode 1334:\n",
      "Reward: -20.0\n",
      "Steps: 1111\n",
      "Avg loss: 0.01891\n",
      "Avg qvals: -1.73660\n",
      "===========================================\n",
      "Episode 1335:\n",
      "Reward: -20.0\n",
      "Steps: 1174\n",
      "Avg loss: 0.01951\n",
      "Avg qvals: -1.71924\n",
      "===========================================\n",
      "Episode 1336:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01824\n",
      "Avg qvals: -1.72280\n",
      "===========================================\n",
      "Episode 1337:\n",
      "Reward: -20.0\n",
      "Steps: 1187\n",
      "Avg loss: 0.01916\n",
      "Avg qvals: -1.79974\n",
      "===========================================\n",
      "Episode 1338:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01745\n",
      "Avg qvals: -1.54709\n",
      "===========================================\n",
      "Episode 1339:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01902\n",
      "Avg qvals: -1.81586\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1340:\n",
      "Reward: -20.0\n",
      "Steps: 1181\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.77216\n",
      "===========================================\n",
      "Episode 1341:\n",
      "Reward: -21.0\n",
      "Steps: 1093\n",
      "Avg loss: 0.01808\n",
      "Avg qvals: -1.63007\n",
      "===========================================\n",
      "Episode 1342:\n",
      "Reward: -21.0\n",
      "Steps: 1056\n",
      "Avg loss: 0.01779\n",
      "Avg qvals: -1.70679\n",
      "===========================================\n",
      "Episode 1343:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.61558\n",
      "===========================================\n",
      "Episode 1344:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01900\n",
      "Avg qvals: -1.95669\n",
      "===========================================\n",
      "Episode 1345:\n",
      "Reward: -19.0\n",
      "Steps: 1329\n",
      "Avg loss: 0.01904\n",
      "Avg qvals: -1.62331\n",
      "===========================================\n",
      "Episode 1346:\n",
      "Reward: -20.0\n",
      "Steps: 1183\n",
      "Avg loss: 0.01928\n",
      "Avg qvals: -1.89068\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1347:\n",
      "Reward: -20.0\n",
      "Steps: 1164\n",
      "Avg loss: 0.01865\n",
      "Avg qvals: -1.68758\n",
      "===========================================\n",
      "Episode 1348:\n",
      "Reward: -20.0\n",
      "Steps: 1141\n",
      "Avg loss: 0.01820\n",
      "Avg qvals: -1.59451\n",
      "===========================================\n",
      "Episode 1349:\n",
      "Reward: -20.0\n",
      "Steps: 1150\n",
      "Avg loss: 0.01889\n",
      "Avg qvals: -1.83157\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1350:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01750\n",
      "Avg qvals: -1.51452\n",
      "===========================================\n",
      "Episode 1351:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01875\n",
      "Avg qvals: -1.73966\n",
      "===========================================\n",
      "Episode 1352:\n",
      "Reward: -21.0\n",
      "Steps: 1164\n",
      "Avg loss: 0.01827\n",
      "Avg qvals: -1.46176\n",
      "===========================================\n",
      "Episode 1353:\n",
      "Reward: -20.0\n",
      "Steps: 1107\n",
      "Avg loss: 0.01815\n",
      "Avg qvals: -1.65653\n",
      "===========================================\n",
      "Episode 1354:\n",
      "Reward: -21.0\n",
      "Steps: 1083\n",
      "Avg loss: 0.01901\n",
      "Avg qvals: -1.78708\n",
      "===========================================\n",
      "Episode 1355:\n",
      "Reward: -21.0\n",
      "Steps: 1060\n",
      "Avg loss: 0.01831\n",
      "Avg qvals: -1.82218\n",
      "===========================================\n",
      "Episode 1356:\n",
      "Reward: -20.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01969\n",
      "Avg qvals: -1.85580\n",
      "===========================================\n",
      "Episode 1357:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01909\n",
      "Avg qvals: -1.91006\n",
      "===========================================\n",
      "Episode 1358:\n",
      "Reward: -21.0\n",
      "Steps: 1043\n",
      "Avg loss: 0.01797\n",
      "Avg qvals: -1.80359\n",
      "===========================================\n",
      "Episode 1359:\n",
      "Reward: -21.0\n",
      "Steps: 1065\n",
      "Avg loss: 0.01956\n",
      "Avg qvals: -1.86899\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1360:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01929\n",
      "Avg qvals: -1.81811\n",
      "===========================================\n",
      "Episode 1361:\n",
      "Reward: -20.0\n",
      "Steps: 1128\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.73676\n",
      "===========================================\n",
      "Episode 1362:\n",
      "Reward: -20.0\n",
      "Steps: 1124\n",
      "Avg loss: 0.01901\n",
      "Avg qvals: -1.72590\n",
      "===========================================\n",
      "Episode 1363:\n",
      "Reward: -21.0\n",
      "Steps: 1091\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.73479\n",
      "===========================================\n",
      "Episode 1364:\n",
      "Reward: -20.0\n",
      "Steps: 1159\n",
      "Avg loss: 0.01872\n",
      "Avg qvals: -1.61117\n",
      "===========================================\n",
      "Episode 1365:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01874\n",
      "Avg qvals: -1.72662\n",
      "===========================================\n",
      "Episode 1366:\n",
      "Reward: -19.0\n",
      "Steps: 1266\n",
      "Avg loss: 0.01910\n",
      "Avg qvals: -1.76387\n",
      "===========================================\n",
      "Episode 1367:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.02031\n",
      "Avg qvals: -1.72053\n",
      "===========================================\n",
      "Episode 1368:\n",
      "Reward: -20.0\n",
      "Steps: 1130\n",
      "Avg loss: 0.01916\n",
      "Avg qvals: -1.81399\n",
      "===========================================\n",
      "Episode 1369:\n",
      "Reward: -19.0\n",
      "Steps: 1310\n",
      "Avg loss: 0.01808\n",
      "Avg qvals: -1.68949\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1370:\n",
      "Reward: -21.0\n",
      "Steps: 1042\n",
      "Avg loss: 0.01983\n",
      "Avg qvals: -1.81938\n",
      "===========================================\n",
      "Episode 1371:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01897\n",
      "Avg qvals: -1.72675\n",
      "===========================================\n",
      "Episode 1372:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01869\n",
      "Avg qvals: -1.82342\n",
      "===========================================\n",
      "Episode 1373:\n",
      "Reward: -20.0\n",
      "Steps: 1168\n",
      "Avg loss: 0.01796\n",
      "Avg qvals: -1.65431\n",
      "===========================================\n",
      "Episode 1374:\n",
      "Reward: -21.0\n",
      "Steps: 1069\n",
      "Avg loss: 0.01987\n",
      "Avg qvals: -1.74850\n",
      "===========================================\n",
      "Episode 1375:\n",
      "Reward: -20.0\n",
      "Steps: 1174\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.59920\n",
      "===========================================\n",
      "Episode 1376:\n",
      "Reward: -21.0\n",
      "Steps: 1035\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.60166\n",
      "===========================================\n",
      "Episode 1377:\n",
      "Reward: -21.0\n",
      "Steps: 1059\n",
      "Avg loss: 0.01857\n",
      "Avg qvals: -1.70888\n",
      "===========================================\n",
      "Episode 1378:\n",
      "Reward: -20.0\n",
      "Steps: 1168\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.81902\n",
      "===========================================\n",
      "Episode 1379:\n",
      "Reward: -21.0\n",
      "Steps: 1149\n",
      "Avg loss: 0.01804\n",
      "Avg qvals: -1.79527\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1380:\n",
      "Reward: -21.0\n",
      "Steps: 1123\n",
      "Avg loss: 0.01799\n",
      "Avg qvals: -1.69861\n",
      "===========================================\n",
      "Episode 1381:\n",
      "Reward: -21.0\n",
      "Steps: 1001\n",
      "Avg loss: 0.01886\n",
      "Avg qvals: -1.59341\n",
      "===========================================\n",
      "Episode 1382:\n",
      "Reward: -20.0\n",
      "Steps: 1129\n",
      "Avg loss: 0.01850\n",
      "Avg qvals: -1.64108\n",
      "===========================================\n",
      "Episode 1383:\n",
      "Reward: -21.0\n",
      "Steps: 1035\n",
      "Avg loss: 0.01981\n",
      "Avg qvals: -1.80182\n",
      "===========================================\n",
      "Episode 1384:\n",
      "Reward: -21.0\n",
      "Steps: 1063\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.55987\n",
      "===========================================\n",
      "Episode 1385:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.02046\n",
      "Avg qvals: -1.97706\n",
      "===========================================\n",
      "Episode 1386:\n",
      "Reward: -20.0\n",
      "Steps: 1120\n",
      "Avg loss: 0.01711\n",
      "Avg qvals: -1.58552\n",
      "===========================================\n",
      "Episode 1387:\n",
      "Reward: -21.0\n",
      "Steps: 1121\n",
      "Avg loss: 0.01913\n",
      "Avg qvals: -1.70530\n",
      "===========================================\n",
      "Episode 1388:\n",
      "Reward: -21.0\n",
      "Steps: 1073\n",
      "Avg loss: 0.01950\n",
      "Avg qvals: -1.53571\n",
      "===========================================\n",
      "Episode 1389:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.76629\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1390:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01803\n",
      "Avg qvals: -1.63601\n",
      "===========================================\n",
      "Episode 1391:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01916\n",
      "Avg qvals: -1.62642\n",
      "===========================================\n",
      "Episode 1392:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01856\n",
      "Avg qvals: -1.68400\n",
      "===========================================\n",
      "Episode 1393:\n",
      "Reward: -20.0\n",
      "Steps: 1139\n",
      "Avg loss: 0.01760\n",
      "Avg qvals: -1.51547\n",
      "===========================================\n",
      "Episode 1394:\n",
      "Reward: -21.0\n",
      "Steps: 1143\n",
      "Avg loss: 0.01857\n",
      "Avg qvals: -1.70094\n",
      "===========================================\n",
      "Episode 1395:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01832\n",
      "Avg qvals: -1.64212\n",
      "===========================================\n",
      "Episode 1396:\n",
      "Reward: -20.0\n",
      "Steps: 1209\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.71989\n",
      "===========================================\n",
      "Episode 1397:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01735\n",
      "Avg qvals: -1.75637\n",
      "===========================================\n",
      "Episode 1398:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01817\n",
      "Avg qvals: -1.67235\n",
      "===========================================\n",
      "Episode 1399:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01963\n",
      "Avg qvals: -1.70035\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1400:\n",
      "Reward: -20.0\n",
      "Steps: 1127\n",
      "Avg loss: 0.01812\n",
      "Avg qvals: -1.85113\n",
      "===========================================\n",
      "Episode 1401:\n",
      "Reward: -20.0\n",
      "Steps: 1118\n",
      "Avg loss: 0.01922\n",
      "Avg qvals: -1.80419\n",
      "===========================================\n",
      "Episode 1402:\n",
      "Reward: -21.0\n",
      "Steps: 1098\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.70864\n",
      "===========================================\n",
      "Episode 1403:\n",
      "Reward: -20.0\n",
      "Steps: 1157\n",
      "Avg loss: 0.01774\n",
      "Avg qvals: -1.62186\n",
      "===========================================\n",
      "Episode 1404:\n",
      "Reward: -21.0\n",
      "Steps: 1006\n",
      "Avg loss: 0.01741\n",
      "Avg qvals: -1.65769\n",
      "===========================================\n",
      "Episode 1405:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01800\n",
      "Avg qvals: -1.77754\n",
      "===========================================\n",
      "Episode 1406:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01886\n",
      "Avg qvals: -1.65571\n",
      "===========================================\n",
      "Episode 1407:\n",
      "Reward: -21.0\n",
      "Steps: 1022\n",
      "Avg loss: 0.01831\n",
      "Avg qvals: -1.64673\n",
      "===========================================\n",
      "Episode 1408:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01873\n",
      "Avg qvals: -1.77245\n",
      "===========================================\n",
      "Episode 1409:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.67635\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1410:\n",
      "Reward: -21.0\n",
      "Steps: 1044\n",
      "Avg loss: 0.01742\n",
      "Avg qvals: -1.57692\n",
      "===========================================\n",
      "Episode 1411:\n",
      "Reward: -20.0\n",
      "Steps: 1168\n",
      "Avg loss: 0.01961\n",
      "Avg qvals: -1.98099\n",
      "===========================================\n",
      "Episode 1412:\n",
      "Reward: -20.0\n",
      "Steps: 1185\n",
      "Avg loss: 0.01894\n",
      "Avg qvals: -1.79992\n",
      "===========================================\n",
      "Episode 1413:\n",
      "Reward: -21.0\n",
      "Steps: 1068\n",
      "Avg loss: 0.01794\n",
      "Avg qvals: -1.56288\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1414:\n",
      "Reward: -20.0\n",
      "Steps: 1143\n",
      "Avg loss: 0.01914\n",
      "Avg qvals: -1.75235\n",
      "===========================================\n",
      "Episode 1415:\n",
      "Reward: -20.0\n",
      "Steps: 1159\n",
      "Avg loss: 0.01798\n",
      "Avg qvals: -1.65576\n",
      "===========================================\n",
      "Episode 1416:\n",
      "Reward: -21.0\n",
      "Steps: 1092\n",
      "Avg loss: 0.01962\n",
      "Avg qvals: -1.87114\n",
      "===========================================\n",
      "Episode 1417:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.02019\n",
      "Avg qvals: -1.81749\n",
      "===========================================\n",
      "Episode 1418:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01809\n",
      "Avg qvals: -1.66692\n",
      "===========================================\n",
      "Episode 1419:\n",
      "Reward: -21.0\n",
      "Steps: 1136\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.62437\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1420:\n",
      "Reward: -21.0\n",
      "Steps: 1049\n",
      "Avg loss: 0.01997\n",
      "Avg qvals: -1.74695\n",
      "===========================================\n",
      "Episode 1421:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.02045\n",
      "Avg qvals: -1.83599\n",
      "===========================================\n",
      "Episode 1422:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01780\n",
      "Avg qvals: -1.55712\n",
      "===========================================\n",
      "Episode 1423:\n",
      "Reward: -21.0\n",
      "Steps: 1178\n",
      "Avg loss: 0.01861\n",
      "Avg qvals: -1.73912\n",
      "===========================================\n",
      "Episode 1424:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01852\n",
      "Avg qvals: -1.75277\n",
      "===========================================\n",
      "Episode 1425:\n",
      "Reward: -20.0\n",
      "Steps: 1135\n",
      "Avg loss: 0.01865\n",
      "Avg qvals: -1.89768\n",
      "===========================================\n",
      "Episode 1426:\n",
      "Reward: -20.0\n",
      "Steps: 1278\n",
      "Avg loss: 0.01908\n",
      "Avg qvals: -1.68353\n",
      "===========================================\n",
      "Episode 1427:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01847\n",
      "Avg qvals: -1.71091\n",
      "===========================================\n",
      "Episode 1428:\n",
      "Reward: -19.0\n",
      "Steps: 1259\n",
      "Avg loss: 0.01873\n",
      "Avg qvals: -1.78235\n",
      "===========================================\n",
      "Episode 1429:\n",
      "Reward: -21.0\n",
      "Steps: 1132\n",
      "Avg loss: 0.02083\n",
      "Avg qvals: -1.93587\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1430:\n",
      "Reward: -20.0\n",
      "Steps: 1117\n",
      "Avg loss: 0.01874\n",
      "Avg qvals: -1.63762\n",
      "===========================================\n",
      "Episode 1431:\n",
      "Reward: -21.0\n",
      "Steps: 1056\n",
      "Avg loss: 0.01888\n",
      "Avg qvals: -1.71881\n",
      "===========================================\n",
      "Episode 1432:\n",
      "Reward: -19.0\n",
      "Steps: 1291\n",
      "Avg loss: 0.01920\n",
      "Avg qvals: -1.87281\n",
      "===========================================\n",
      "Episode 1433:\n",
      "Reward: -21.0\n",
      "Steps: 1094\n",
      "Avg loss: 0.01785\n",
      "Avg qvals: -1.52929\n",
      "===========================================\n",
      "Episode 1434:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01832\n",
      "Avg qvals: -1.80935\n",
      "===========================================\n",
      "Episode 1435:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01946\n",
      "Avg qvals: -1.79743\n",
      "===========================================\n",
      "Episode 1436:\n",
      "Reward: -20.0\n",
      "Steps: 1237\n",
      "Avg loss: 0.01854\n",
      "Avg qvals: -1.81614\n",
      "===========================================\n",
      "Episode 1437:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01916\n",
      "Avg qvals: -1.82674\n",
      "===========================================\n",
      "Episode 1438:\n",
      "Reward: -21.0\n",
      "Steps: 1033\n",
      "Avg loss: 0.02025\n",
      "Avg qvals: -1.76597\n",
      "===========================================\n",
      "Episode 1439:\n",
      "Reward: -21.0\n",
      "Steps: 1026\n",
      "Avg loss: 0.01775\n",
      "Avg qvals: -1.70097\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1440:\n",
      "Reward: -20.0\n",
      "Steps: 1156\n",
      "Avg loss: 0.01784\n",
      "Avg qvals: -1.68320\n",
      "===========================================\n",
      "Episode 1441:\n",
      "Reward: -21.0\n",
      "Steps: 1138\n",
      "Avg loss: 0.01845\n",
      "Avg qvals: -1.77068\n",
      "===========================================\n",
      "Episode 1442:\n",
      "Reward: -21.0\n",
      "Steps: 1028\n",
      "Avg loss: 0.01942\n",
      "Avg qvals: -1.56368\n",
      "===========================================\n",
      "Episode 1443:\n",
      "Reward: -21.0\n",
      "Steps: 1070\n",
      "Avg loss: 0.01906\n",
      "Avg qvals: -1.85243\n",
      "===========================================\n",
      "Episode 1444:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01931\n",
      "Avg qvals: -1.92087\n",
      "===========================================\n",
      "Episode 1445:\n",
      "Reward: -21.0\n",
      "Steps: 1078\n",
      "Avg loss: 0.01731\n",
      "Avg qvals: -1.70148\n",
      "===========================================\n",
      "Episode 1446:\n",
      "Reward: -20.0\n",
      "Steps: 1185\n",
      "Avg loss: 0.01940\n",
      "Avg qvals: -1.77460\n",
      "===========================================\n",
      "Episode 1447:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01856\n",
      "Avg qvals: -1.57291\n",
      "===========================================\n",
      "Episode 1448:\n",
      "Reward: -21.0\n",
      "Steps: 1050\n",
      "Avg loss: 0.01994\n",
      "Avg qvals: -1.88321\n",
      "===========================================\n",
      "Episode 1449:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01911\n",
      "Avg qvals: -1.80551\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1450:\n",
      "Reward: -20.0\n",
      "Steps: 1281\n",
      "Avg loss: 0.01923\n",
      "Avg qvals: -1.72713\n",
      "===========================================\n",
      "Episode 1451:\n",
      "Reward: -21.0\n",
      "Steps: 1005\n",
      "Avg loss: 0.01767\n",
      "Avg qvals: -1.58613\n",
      "===========================================\n",
      "Episode 1452:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01894\n",
      "Avg qvals: -1.77087\n",
      "===========================================\n",
      "Episode 1453:\n",
      "Reward: -21.0\n",
      "Steps: 1097\n",
      "Avg loss: 0.01947\n",
      "Avg qvals: -1.76797\n",
      "===========================================\n",
      "Episode 1454:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01870\n",
      "Avg qvals: -1.81022\n",
      "===========================================\n",
      "Episode 1455:\n",
      "Reward: -21.0\n",
      "Steps: 1101\n",
      "Avg loss: 0.01903\n",
      "Avg qvals: -1.75212\n",
      "===========================================\n",
      "Episode 1456:\n",
      "Reward: -20.0\n",
      "Steps: 1182\n",
      "Avg loss: 0.01937\n",
      "Avg qvals: -1.76485\n",
      "===========================================\n",
      "Episode 1457:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01766\n",
      "Avg qvals: -1.68759\n",
      "===========================================\n",
      "Episode 1458:\n",
      "Reward: -20.0\n",
      "Steps: 1189\n",
      "Avg loss: 0.01922\n",
      "Avg qvals: -1.82840\n",
      "===========================================\n",
      "Episode 1459:\n",
      "Reward: -20.0\n",
      "Steps: 1158\n",
      "Avg loss: 0.01940\n",
      "Avg qvals: -1.82629\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1460:\n",
      "Reward: -21.0\n",
      "Steps: 1057\n",
      "Avg loss: 0.01786\n",
      "Avg qvals: -1.63119\n",
      "===========================================\n",
      "Episode 1461:\n",
      "Reward: -21.0\n",
      "Steps: 1000\n",
      "Avg loss: 0.01800\n",
      "Avg qvals: -1.61962\n",
      "===========================================\n",
      "Episode 1462:\n",
      "Reward: -20.0\n",
      "Steps: 1209\n",
      "Avg loss: 0.01885\n",
      "Avg qvals: -1.64296\n",
      "===========================================\n",
      "Episode 1463:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01850\n",
      "Avg qvals: -1.67620\n",
      "===========================================\n",
      "Episode 1464:\n",
      "Reward: -21.0\n",
      "Steps: 1084\n",
      "Avg loss: 0.02000\n",
      "Avg qvals: -1.74268\n",
      "===========================================\n",
      "Episode 1465:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01786\n",
      "Avg qvals: -1.66526\n",
      "===========================================\n",
      "Episode 1466:\n",
      "Reward: -21.0\n",
      "Steps: 1030\n",
      "Avg loss: 0.01810\n",
      "Avg qvals: -1.69085\n",
      "===========================================\n",
      "Episode 1467:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01869\n",
      "Avg qvals: -1.74914\n",
      "===========================================\n",
      "Episode 1468:\n",
      "Reward: -21.0\n",
      "Steps: 995\n",
      "Avg loss: 0.01781\n",
      "Avg qvals: -1.77461\n",
      "===========================================\n",
      "Episode 1469:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.02058\n",
      "Avg qvals: -1.93773\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1470:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01984\n",
      "Avg qvals: -1.82241\n",
      "===========================================\n",
      "Episode 1471:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01859\n",
      "Avg qvals: -1.72716\n",
      "===========================================\n",
      "Episode 1472:\n",
      "Reward: -21.0\n",
      "Steps: 1025\n",
      "Avg loss: 0.01873\n",
      "Avg qvals: -1.76240\n",
      "===========================================\n",
      "Episode 1473:\n",
      "Reward: -21.0\n",
      "Steps: 1010\n",
      "Avg loss: 0.02066\n",
      "Avg qvals: -1.93737\n",
      "===========================================\n",
      "Episode 1474:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01937\n",
      "Avg qvals: -1.86088\n",
      "===========================================\n",
      "Episode 1475:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01839\n",
      "Avg qvals: -1.72470\n",
      "===========================================\n",
      "Episode 1476:\n",
      "Reward: -21.0\n",
      "Steps: 1003\n",
      "Avg loss: 0.01907\n",
      "Avg qvals: -1.78012\n",
      "===========================================\n",
      "Episode 1477:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01821\n",
      "Avg qvals: -1.66503\n",
      "===========================================\n",
      "Episode 1478:\n",
      "Reward: -21.0\n",
      "Steps: 1042\n",
      "Avg loss: 0.01763\n",
      "Avg qvals: -1.63926\n",
      "===========================================\n",
      "Episode 1479:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01946\n",
      "Avg qvals: -1.83460\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1480:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01813\n",
      "Avg qvals: -1.55003\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1481:\n",
      "Reward: -21.0\n",
      "Steps: 1019\n",
      "Avg loss: 0.01914\n",
      "Avg qvals: -1.76436\n",
      "===========================================\n",
      "Episode 1482:\n",
      "Reward: -21.0\n",
      "Steps: 1041\n",
      "Avg loss: 0.01741\n",
      "Avg qvals: -1.53654\n",
      "===========================================\n",
      "Episode 1483:\n",
      "Reward: -21.0\n",
      "Steps: 1004\n",
      "Avg loss: 0.01851\n",
      "Avg qvals: -1.67582\n",
      "===========================================\n",
      "Episode 1484:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01854\n",
      "Avg qvals: -1.56474\n",
      "===========================================\n",
      "Episode 1485:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01874\n",
      "Avg qvals: -2.02387\n",
      "===========================================\n",
      "Episode 1486:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01871\n",
      "Avg qvals: -1.69595\n",
      "===========================================\n",
      "Episode 1487:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01778\n",
      "Avg qvals: -1.52573\n",
      "===========================================\n",
      "Episode 1488:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01822\n",
      "Avg qvals: -1.61536\n",
      "===========================================\n",
      "Episode 1489:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01770\n",
      "Avg qvals: -1.68665\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1490:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01911\n",
      "Avg qvals: -1.66508\n",
      "===========================================\n",
      "Episode 1491:\n",
      "Reward: -21.0\n",
      "Steps: 1024\n",
      "Avg loss: 0.01904\n",
      "Avg qvals: -1.75541\n",
      "===========================================\n",
      "Episode 1492:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01909\n",
      "Avg qvals: -1.54582\n",
      "===========================================\n",
      "Episode 1493:\n",
      "Reward: -21.0\n",
      "Steps: 1020\n",
      "Avg loss: 0.01918\n",
      "Avg qvals: -1.80235\n",
      "===========================================\n",
      "Episode 1494:\n",
      "Reward: -21.0\n",
      "Steps: 1002\n",
      "Avg loss: 0.01878\n",
      "Avg qvals: -1.81431\n",
      "===========================================\n",
      "Episode 1495:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.02008\n",
      "Avg qvals: -1.73869\n",
      "===========================================\n",
      "Episode 1496:\n",
      "Reward: -21.0\n",
      "Steps: 999\n",
      "Avg loss: 0.01923\n",
      "Avg qvals: -1.79115\n",
      "===========================================\n",
      "Episode 1497:\n",
      "Reward: -21.0\n",
      "Steps: 1017\n",
      "Avg loss: 0.01836\n",
      "Avg qvals: -1.65358\n",
      "===========================================\n",
      "Episode 1498:\n",
      "Reward: -21.0\n",
      "Steps: 1011\n",
      "Avg loss: 0.01856\n",
      "Avg qvals: -1.78122\n",
      "===========================================\n",
      "Episode 1499:\n",
      "Reward: -21.0\n",
      "Steps: 1015\n",
      "Avg loss: 0.01900\n",
      "Avg qvals: -1.66351\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1500:\n",
      "Reward: -21.0\n",
      "Steps: 1029\n",
      "Avg loss: 0.01719\n",
      "Avg qvals: -1.59103\n",
      "===========================================\n",
      "Episode 1501:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01856\n",
      "Avg qvals: -1.71642\n",
      "===========================================\n",
      "Episode 1502:\n",
      "Reward: -21.0\n",
      "Steps: 1009\n",
      "Avg loss: 0.01730\n",
      "Avg qvals: -1.72582\n",
      "===========================================\n",
      "Episode 1503:\n",
      "Reward: -21.0\n",
      "Steps: 1003\n",
      "Avg loss: 0.01737\n",
      "Avg qvals: -1.58406\n",
      "===========================================\n",
      "Episode 1504:\n",
      "Reward: -21.0\n",
      "Steps: 1032\n",
      "Avg loss: 0.01787\n",
      "Avg qvals: -1.67908\n",
      "===========================================\n",
      "Episode 1505:\n",
      "Reward: -21.0\n",
      "Steps: 1021\n",
      "Avg loss: 0.01815\n",
      "Avg qvals: -1.75512\n",
      "===========================================\n",
      "Episode 1506:\n",
      "Reward: -21.0\n",
      "Steps: 1018\n",
      "Avg loss: 0.01852\n",
      "Avg qvals: -1.62670\n",
      "===========================================\n",
      "Episode 1507:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01931\n",
      "Avg qvals: -1.81566\n",
      "===========================================\n",
      "Episode 1508:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01932\n",
      "Avg qvals: -1.86052\n",
      "===========================================\n",
      "Episode 1509:\n",
      "Reward: -21.0\n",
      "Steps: 1013\n",
      "Avg loss: 0.01858\n",
      "Avg qvals: -1.67306\n",
      "===========================================\n",
      "Model saved.\n",
      "Episode 1510:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01903\n",
      "Avg qvals: -1.79156\n",
      "===========================================\n",
      "Episode 1511:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01973\n",
      "Avg qvals: -1.85568\n",
      "===========================================\n",
      "Episode 1512:\n",
      "Reward: -21.0\n",
      "Steps: 1007\n",
      "Avg loss: 0.01953\n",
      "Avg qvals: -1.77024\n",
      "===========================================\n",
      "Episode 1513:\n",
      "Reward: -21.0\n",
      "Steps: 1027\n",
      "Avg loss: 0.01988\n",
      "Avg qvals: -1.85634\n",
      "===========================================\n",
      "Episode 1514:\n",
      "Reward: -21.0\n",
      "Steps: 1016\n",
      "Avg loss: 0.01800\n",
      "Avg qvals: -1.85194\n",
      "===========================================\n",
      "Episode 1515:\n",
      "Reward: -21.0\n",
      "Steps: 1023\n",
      "Avg loss: 0.01754\n",
      "Avg qvals: -1.66245\n",
      "===========================================\n",
      "Episode 1516:\n",
      "Reward: -21.0\n",
      "Steps: 1031\n",
      "Avg loss: 0.01854\n",
      "Avg qvals: -1.72514\n",
      "===========================================\n",
      "Episode 1517:\n",
      "Reward: -21.0\n",
      "Steps: 1012\n",
      "Avg loss: 0.01819\n",
      "Avg qvals: -1.77226\n",
      "===========================================\n",
      "Episode 1518:\n",
      "Reward: -21.0\n",
      "Steps: 1008\n",
      "Avg loss: 0.01926\n",
      "Avg qvals: -1.80434\n",
      "===========================================\n",
      "Episode 1519:\n",
      "Reward: -21.0\n",
      "Steps: 1014\n",
      "Avg loss: 0.01941\n",
      "Avg qvals: -1.66983\n",
      "===========================================\n",
      "Model saved.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b0c592b2dbae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_t1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mep_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a82e767d0093>\u001b[0m in \u001b[0;36mgradient_step\u001b[0;34m(replay_mem, agt)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0magt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmini_batch_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0magt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/882p/dqn_player/src/train.py\u001b[0m in \u001b[0;36mmini_batch_loss\u001b[0;34m(mini_batch, agt)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmini_batch_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mqmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_max_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/882p/dqn_player/src/train.py\u001b[0m in \u001b[0;36mget_max_vals\u001b[0;34m(transitions, agt)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0magt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/882p/dqn_player/src/agent.py\u001b[0m in \u001b[0;36mget_best_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_epsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agt, replay_mem, obs_history, env, train_stats = \\\n",
    "    initialize(replay_mem_size, batch_size)\n",
    "\n",
    "for episode in range(num_episodes):  # loop over episodes\n",
    "    s_t, done = reset_episode(env, obs_history)\n",
    "    \n",
    "    ep_reward = 0\n",
    "    ep_train_loss = 0\n",
    "    ep_steps = 0\n",
    "    \n",
    "    while not done:  # loop over steps in episode\n",
    "        a_t, s_t1, r_t, done = act_step(obs_history, agt, env)\n",
    "        store_step(s_t, a_t, r_t, done, s_t1, obs_history, replay_mem)\n",
    "        \n",
    "        s_t = s_t1\n",
    "        \n",
    "        loss_val = gradient_step(replay_mem, agt)\n",
    "        \n",
    "        ep_reward += r_t\n",
    "        ep_steps += 1\n",
    "        if loss_val is not None:\n",
    "            ep_train_loss += loss_val \n",
    "    \n",
    "    train_stats.store(agt, ep_reward, ep_steps, ep_train_loss, episode)\n",
    "    \n",
    "    if episode % 10 == 9:\n",
    "        checkpoint_name = 'dqn_agt_{}.pt'.format(episode)\n",
    "        save_params(agt, episode, checkpoint_name)\n",
    "        print('Model saved.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Go Through One Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import gym\n",
    "from src import agent, dqn, train, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.envs.make('Pong-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_obs = env.reset()\n",
    "\n",
    "for i in range(20000):\n",
    "    a = random.randrange(env.action_space.n)\n",
    "    _, _, done, _ = env.step(a)\n",
    "    time.sleep(.01)\n",
    "    env.render()\n",
    "    \n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_obs = env.reset()\n",
    "init_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1, r, done, _ = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize DQN objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_mem_size = int(1e6)\n",
    "mini_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agt = agent.DQNAgent()\n",
    "replay_memory = utils.ReplayMemory(replay_mem_size, mini_batch_size)\n",
    "obs_history = utils.ObsHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin new episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_init = env.reset()  # reset environment to start new episode\n",
    "obs_history.reset(obs_init)  # reset observations for new episode\n",
    "done = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = obs_history.phi\n",
    "a = agt.act(phi)\n",
    "obs, rew, done, _ = env.step(a)\n",
    "obs_history.store(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_1 = obs_history.phi\n",
    "replay_memory.store((phi, a, rew, phi_1, done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Step\n",
    "\n",
    "[x] Dummy transitions function for testing.\n",
    "\n",
    "[x] Make `r` reward vector from transitions.\n",
    "\n",
    "[x] Make $\\max_{a}Q(s', a')$ vector from transitions.\n",
    "\n",
    "[x] Make `y` target vector from transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "Transition = namedtuple('Transition', \n",
    "                        ['phi', 'a', 'r', 'phi_1', 'done'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_transitions(n):\n",
    "    transitions = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        phi = torch.empty(4, 84, 84).random_(0, 255)\n",
    "        phi_1 = torch.empty(4, 84, 84).random_(0, 255)\n",
    "        a = np.random.randint(0, 6)\n",
    "        r = np.random.randint(0, 2)\n",
    "        done = False if np.random.randint(0, 2) == 0 else True\n",
    "        \n",
    "        transitions.append(Transition(phi, a, r, phi_1, done))\n",
    "    \n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = dummy_transitions(3)\n",
    "    \n",
    "phi, a, r, phi_1, done = zip(*transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_y(transitions, agt):\n",
    "    y = []\n",
    "    \n",
    "    for tr in transitions:\n",
    "        if tr.done:\n",
    "            y.append(tr.r)\n",
    "        else:\n",
    "            x = tr.phi.unsqueeze(0)\n",
    "            y.append(tr.r + .99 * agt.get_best_values(x).item())\n",
    "            \n",
    "    return torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = make_y(transitions, agt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_vals(transitions, agt):\n",
    "    phis = []\n",
    "\n",
    "    for tr in transitions:\n",
    "        phis.append(tr.phi)\n",
    "\n",
    "    x = torch.stack(phis)\n",
    "    return agt.get_best_values(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmax = get_max_vals(transitions, agt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(y, qmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_loss(transitions, agt):\n",
    "    y = make_y(transitions, agt)\n",
    "    qmax = get_max_vals(transitions, agt)\n",
    "    \n",
    "    loss = nn.MSELoss(reduction='mean')\n",
    "    return loss(y, qmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_loss = mini_batch_loss(transitions, agt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer and gradient step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.RMSprop(agt.qnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_loss = mini_batch_loss(transitions, agt)\n",
    "mb_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test random agent on Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obss = []\n",
    "obss.append(env.reset())\n",
    "\n",
    "for _ in range(1000):\n",
    "    a = np.random.choice(env.action_space.n)\n",
    "    obs, rew, done, _ = env.step(a)\n",
    "    obss.append(obs)\n",
    "    \n",
    "    if done:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
